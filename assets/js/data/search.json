[ { "title": "Keyboard Controller Style (KCS) Interface", "url": "/posts/kcs/", "categories": "ipmi_spec", "tags": "ipmi", "date": "2024-05-06 15:40:00 +0800", "snippet": "abstractThis section describes the Keyboard Controller Style (KCS) Interface. The KCSinterface is one of the supported BMC to SMS interfaces. The KCS interface isspecified solely for SMS messages. ...", "content": "abstractThis section describes the Keyboard Controller Style (KCS) Interface. The KCSinterface is one of the supported BMC to SMS interfaces. The KCS interface isspecified solely for SMS messages. SMM messages between the BMC and an SMIHandler will typically require a separate interface, though the KCS interfaceis designed so that system software can detect if a transaction wasinterrupted. Any BMC-to-SMI Handler communication via the KCS interface isimplementation specific and is not covered by this specification. solely: 单独地; 本节介绍键盘控制器样式 (KCS) 接口。 KCS 接口是受支持的 BMC 到 SMS 接口之一。 KCS 接口专为 SMS 消息而指定。 BMC 和 SMI 处理程序之间的 SMM 消息通常需要单独的接口，尽管 KCS 接口的设计使得系统软件可以检测事务是否被中断。 任何通过 KCS 接口的 BMC 到 SMI 处理程序通信都是特定于实现的，并且不包含在本规范中。The KCS Interface is designed to support polled operation. Implementations canoptionally provide an interrupt driven from the OBF flag, but this must notprevent driver software from the using the interface in a polled manner. Thisallows software to default to polled operation. It also allows software to usethe KCS interface in a polled mode until it determines the type of interruptsupport. Methods for assigning and enabling such an interrupt are outside thescope of this specification. KCS 接口旨在支持轮询操作。 实现可以选择提供由 OBF flag 驱动的中断，但这不能阻止驱动程序软件以轮询方式使用接口。 这允许软件默认进行轮询操作。 它还允许软件以轮询模式使用 KCS 接口，直到确定中断支持的类型。 分配和启用此类中断的方法超出了本规范的范围.9.1 KCS Interface/BMC LUNsLUN 00b is typically used for all messages to the BMC through the KCSInterface. LUN 10b is reserved for Receive Message Queue use and should not beused for sending commands to the BMC. Note that messages encapsulated in a SendMessage command can use any LUN in the encapsulated portion. encapsulated [ɪnˈkæpsjuleɪtɪd] : v. 压缩;概括;简述; adj. 密封的;封装的 LUN 00b 通常用于通过 KCS 接口发送至 BMC 的所有消息。 LUN 10b 保留供Receive Message Queue 使用，不应用于向 BMC 发送命令。 请注意，Send Message command 中封装的消息可以使用封装部分中的任何 LUN。9.2 KCS Interface-BMC Request Message FormatRequest Messages are sent to the BMC from system software using a writetransfer through the KCS Interface. The message bytes are organized accordingto the following format specification: Request Messages 通过 KCS 接口使用写传输从系统软件发送到 BMC。 消息字节按照以下格式规范组织：Where: LUN Logical Unit Number. This is a sub-address that allows messages to be routedto different ‘logical units’ that reside behind the same physical interface.The LUN field occupies the least significant two bits of the first messagebyte. occupy [ˈɑːkjupaɪ]: 占据; 使用，占用 这是一个子地址，允许消息路由到驻留在同一物理接口后面的不同“逻辑单元”。 LUN 字段占据第一个消息字节的最低有效两位。 NetFn Network Function code. This provides the first level of functional routingfor messages received by the BMC via the KCS Interface. The NetFn fieldoccupies the most significant six bits of the first message byte. Even NetFnvalues are used for requests to the BMC, and odd NetFn values are returned inresponses from the BMC. even: 偶数odd /ɑːd/: 奇数 Network Function Code。 这为 BMC 通过 KCS 接口接收的消息提供第一级功能路由。 NetFn 字段占据第一个消息字节的最高有效六位。 偶数 NetFn 值用于向 BMC 发出请求，奇数 NetFn 值在 BMC 的响应中返回。 Cmd Command code. This message byte specifies the operation that is to beexecuted under the specified Network Function. Command code. 该消息字节指定要在指定Network Function 下执行的操作。 Data Zero or more bytes of data, as required by the given command. The generalconvention is to pass data LS-byte first, but check the individual commandspecifications to be sure. convention [kənˈvenʃn]: 协定,协议;约束,约定;惯例 根据给定命令的需要，零个或多个字节的数据。 一般约定是首先传递数据 LS-byte ，但请检查各个命令规范来确定。 9.3 BMC-KCS Interface Response Message FormatResponse Messages are read transfers from the BMC to system software via theKCS Interface. Note that the BMC only returns responses via the KCS Interfacewhen Data needs to be returned. The message bytes are organized according tothe following format specification: Response Messages 是通过 KCS 接口从 BMC 到系统软件的读取传输。 请注意，BMC 仅在需要返回数据时才通过 KCS 接口返回响应。 消息字节按照以下格式规范组织：Where: LUN Logical Unit Number. This is a return of the LUN that was passed in theRequest Message. NetFn Network Function. This is a return of the NetFn code that was passed in theRequest Message. Except that an odd NetFn value is returned. 注意其返回的NetFn 是偶数. 而 Request Message 中是奇数. Cmd Command. This is a return of the Cmd code that was passed in the RequestMessage. Completion Code The Completion Code indicates whether the request completed successfully ornot. Completion Code 指示请求是否成功完成。 Data Zero or more bytes of data. The BMC always returns a response toacknowledge the request, regardless of whether data is returned or not. 零个或多个字节的数据。 无论是否返回数据，BMC 都会返回响应来确认请求。 9.4 Logging Events from System Software via KCS InterfaceThe KCS Interface can be used for sending Event Messages from system softwareto the BMC Event Receiver. The following figures show the format for KCSInterface Event Request and corresponding Event Response messages. Note thatonly Event Request Messages to the BMC via the KCS Interface have a Software IDfield. This is so the Software ID can be saved in the logged event. KCS 接口可用于将Event Message 从系统软件发送到 BMC Event Receiver。 下图显示了KCS接口Event Request 和相应 Event Response 消息的格式。 请注意，只有通过 KCS 接口发送至 BMC 的事件请求消息才具有软件 ID 字段。 这样软件 ID 就可以保存在记录的事件中。 designates /ˈdezɪɡneɪts/ 指定；命名；选定，指派，委任9.5 KCS Interface RegistersThe KCS Interface defines a set of I/O mapped communication registers. The bitdefinitions, and operation of these registers follows that used in the Intel8742 Universal Peripheral Interface microcontroller. The term ‘KeyboardController Style’ reflects the fact that the 8742 interface is used as thesystem keyboard controller interface in PC architecture computer systems. KCS 接口定义了一组 I/O 映射通信寄存器。 这些寄存器的位定义和操作遵循 Intel 8742 Universal Peripheral 微控制器中使用的定义和操作。 术语“Keyboard ControllerStyle” 反映了 8742 接口在 PC 架构计算机系统中用作系统键盘控制器接口.The specification of the KCS Interface registers is given solely with respectto the ‘system software side’ view of the interface in system I/O space. Thefunctional behavior of the management controller to support the KCS Interfaceregisters is specified, but the physical implementation of the interface andthe organization of the interface from the management controller side isimplementation dependent and is beyond the scope of this specification. KCS 接口寄存器的规范仅针对系统 I/O 空间中接口的“系统软件端”视图给出。 管理控制器支持 KCS 接口寄存器的功能行为已被指定，但管理控制器侧接口的物理实现和接口的组织取决于实现，并且超出了本规范的范围。On the system side, the registers are mapped to system I/O space and consistsof four byte-wide registers. 在系统方面，寄存器映射到系统I/O空间并由四个byte-wide的寄存器组成。 Status Register - provides flags and status bits for use in variousdefined operations. 提供了在各种定义的操作中使用的标志和状态位。 Command Register - provides port into which ‘Write Control Codes’ may bewritten. 提供可以写入“Write Control Codes”的端口。 Data_In - provides a port into which data bytes and ‘Read Control Codes’may be written. 提供一个可以写入数据字节和“Read Control Codes”的端口。 Data_Out - provides a port from which data bytes may be read. 提供可以读取数据字节的端口。 The default system base address for an I/O mapped KCS SMS Interface is CA2h.Refer to Appendix C1 - Locating IPMI System Interfaces via SM BIOS Tables forinformation on using SM BIOS tables for describing optional interrupt usage,memory mapped registers, 32-bit and 16-byte aligned registers, and alternativeKCS interface addresses. Software can assume the KCS interface registers areI/O mapped and byte aligned at the default address unless other information isprovided. Appendix [əˈpendɪks]: 附录 I/O 映射的 KCS SMS 接口的默认系统基地址是 CA2h。 请参阅附录 C1 - 通过 SM BIOS表定位 IPMI 系统接口，了解有关使用 SM BIOS 表描述可选中断使用、内存映射寄存器、32 位和 16 字节对齐寄存器以及备用 KCS 接口地址的信息。 软件可以假定 KCS 接口寄存器已进行 I/O 映射并在默认地址处进行字节对齐，除非提供其他信息9.6 KCS Interface Control CodesControl codes are used for ‘framing’ message data transferred across the KCSInterface. Control Codes are used to: frame: n. 框架 v. 表达,指定,拟定 Control Code 用于“构建”通过 KCS 接口传输的消息数据。 控制代码用于： Identify the first and last bytes of a packet. Identify when an error/abort has occurred. Request additional data bytes.9.7 Status RegisterSystem software always initiates a transfer. If the BMC has a message for SMS,it can request attention by setting the SMS_ATN bit in the status register.System software then detects the flag and initiates the transfer. initiates [ɪˈnɪʃieɪts] 系统软件总是发起传输。 如果 BMC 有 SMS 消息，则可以通过设置状态寄存器中的 SMS_ATN 位来请求关注。 然后系统软件检测该标志并启动传输。Other bits in the status register are used to arbitrate access to the commandand data registers between the BMC and system software and to indicate the“state” (write, read, error, or idle) of the current transaction. The followingtables summarize the functions of the Status Register bits. arbitrate [ˈɑːrbɪtreɪt]: v. 仲裁,中断 状态寄存器中的其他位用于仲裁 BMC 和系统软件之间对命令和数据寄存器的访问，并指示当前事务的“状态”（写入、读取、错误或空闲）。 下表总结了状态寄存器位的功能。 C/D#: Specifies whether the last write was to the Command register or the Data_Inregister (1=command, 0=data). Set by hardware to indicate whether last writefrom the system software side was to Command or Data_In register. 指定最后一次写入是写入命令寄存器还是 Data_In 寄存器（1=命令，0=数据）。 由硬件设置以指示系统软件端的最后一次写入是对 Command 还是 Data_In 寄存器。 IBF Automatically set to 1 when either the associated Command or Data_In registerhas been written by system-side software. 当系统端软件写入关联的 Command 或 Data_In 寄存器时，自动设置为 1。 OBF Set to 1 when the associated Data_Out register has been written by the BMC. 当系统端软件写入关联的 Command 或 Data_In 寄存器时，自动设置为 1。 Bits 7:6 are state bits that provide information that is used to ensure thatthe BMC and system software remain in sync with one another. Following are thepossible states and their meaning: 位 7:6 是状态位，提供用于确保 BMC 和系统软件保持彼此同步的信息。 以下是可能的状态及其含义： IDLE_STATE. Interface is idle. System software should not be expecting nor sending any data. 接口空闲。 系统软件不应期待也不发送任何数据。 READ_STATE. BMC is transferring a packet to system software. System software should be in the “Read Message” state. BMC 正在向系统软件传输数据包。 系统软件应处于“Read Message”状态。 WRITE_STATE. BMC is receiving a packet from system software. System software should bewriting a command to the BMC. BMC正在接收来自系统软件的数据包。 系统软件应该向 BMC 写入命令。 ERROR_STATE. BMC has detected a protocol violation at the interface level, or the transfer has been aborted. System software can either use the “Get_Status’ control code to request the nature of the error, or it can just retry the command. nature : n. 自然; 性质 BMC 检测到接口级别的协议违规，或者传输已中止。 系统软件可以使用“Get_Status” controlcode 来请求错误的性质，也可以仅重试该命令。 9.7.1 SMS_ATN Flag UsageThe SMS_ATN flag is used to indicate that the BMC requires attention fromsystem software. This could either be because a message was received into theReceive Message Queue and ready for delivery to system software, the EventMessage Buffer is full (if the Event Message Buffer is configured to generatean interrupt to system management software), a watchdog pre-timeout occurred,or because of an OEM event. Flags in the BMC identify which conditions arecausing the SMS_ATN flag to be set. All conditions must be cleared (i.e. allmessages must be flushed) in order for the SMS_ATN bit to be cleared. SMS_ATN 标志用于指示 BMC 需要系统软件的关注。 这可能是因为消息已接收到接收消息队列并准备好传送到系统软件、事件消息缓冲区已满（如果事件消息缓冲区配置为向系统管理软件生成中断）、看门狗预置 发生超时，或由于 OEM 事件。 BMC 中的标志标识哪些条件导致 SMS_ATN 标志被设置。 必须清除所有条件（即必须刷新所有消息）才能清除 SMS_ATN 位。The SMS_ATN bit is also used when the KCS interface is interrupt driven, orwhen OEM events or watchdog pre-timeouts generate a system interrupt. Refer tosections 9.12, KCS Communication and Non-communication Interrupts, 9.13,Physical Interrupt Line Sharing, and 9.14, Additional Specifications for theKCS interface for additional information on the use and requirements for theSMS_ATN bit. 当 KCS 接口是中断驱动时，或者当 OEM 事件或看门狗预超时生成系统中断时，也会使用 SMS_ATN 位。 有关 SMS_ATN 位的使用和要求的附加信息，请参阅第 9.12 节“KCS 通信和非通信中断”、第 9.13 节“物理中断线路共享”和 9.14 节“KCS 接口的附加规范”。9.8 Command RegisterThe Command register must only be written from the system side when the IBFflag is clear. Only WRITE_START, WRITE_END, or GET_STATUS/ABORT Control Codesare written to the command register. 仅当 IBF 标志清零时，才必须从系统侧写入命令寄存器。 仅 WRITE_START、WRITE_END 或 GET_STATUS/ABORT Control Codes 会写入Control Register。9.9 Data RegistersPackets to and from the BMC are passed through the data registers. These bytescontain all the fields of a message, such as the Network Function code, CommandByte, and any additional data required for the Request or Response message. 进出 BMC 的数据包通过Data Register 传递。 这些字节包含消息的所有字段，例如NetFn、Command Byte 以及Request 或 Response 消息所需的任何附加数据。The Data_In register must only be written from the system side when the IBFflag is clear. The OBF flag must be set (1) before the Data_Out register can beread (see status register). 仅当 IBF 标志清零时，才必须从系统侧写入 Data_In 寄存器。 在读取 Data_Out 寄存器之前，必须将 OBF 标志设置为 (1)（请参阅状态寄存器）。9.10 KCS Control CodesThe following table details the usage of ‘Control Codes’ by the KCS interface.9.11 Performing KCS Interface Message TransfersSystem Management Software that uses the KCS Interface will typically berunning under a multi-tasking operating system. This means transfers with theBMC may be interrupted by higher priority tasks or delayed by other SystemManagement Software processing. The SMS channel handshake is optimized to allowthe BMC to continue to perform tasks between data byte transfers with SystemManagement Software. The BMC does not time out data byte transfers on the SMSinterface. 使用 KCS 接口的系统管理软件通常在多任务操作系统下运行。 这意味着与 BMC 的传输可能会被更高优先级的任务中断或被其他系统管理软件处理延迟。SMS 通道握手经过优化，允许 BMC 通过系统管理软件在数据字节传输之间继续执行任务。BMC 不会使 SMS 接口上的数据字节传输超时。Request and Response Messages are paired together as a Write Transfer to theBMC to send the request followed by a Read Transfer from the BMC to get theresponse. Request 和 Response 消息配对在一起，作为向 BMC 的Write Transfer 以发送请求，然后从 BMC 进行Read Transfer 以获取响应。The process, as seen from the system perspective is depicted in Figure 9-6, KCSInterface SMS to BMC Write Transfer Flow Chart, and Figure 9-7, KCS InterfaceBMC to SMS Read Transfer Flow Chart, below. 从系统角度来看，该过程如图 9-6（KCS 接口 SMS 到 BMC 写入传输流程图）和图 9-7（KCS 接口 BMC 到 SMS 读取传输流程图）所示。During the write transfer each write of a Control Code to the command registerand each write of a data byte to Data_In will cause IBF to become set,triggering the BMC to read in the corresponding Control Code or data byte. 在写传输期间，每次向命令寄存器写入Control Code 以及每次向 Data_In 写入数据字节都会导致 IBF 置位，从而触发 BMC 读入相应的 Control Code 或数据字节。If the KCS interface uses an interrupt, the BMC will write a dummy value of 00hto the output data register after it has updated the status register and readthe input buffer. This generates an ‘OBF’ interrupt. The points at which thiswould occur are shown as “OBF” in Figure 9-6, KCS Interface SMS to BMC WriteTransfer Flow Chart, below. 如果KCS接口使用中断，则BMC在更新状态寄存器并读取输入缓冲区后将向输出数据寄存器写入虚拟值00h。 这会生成“OBF”中断。 发生这种情况的点在下面的图 9-6 KCS 接口 SMS 到 BMC 写入传输流程图中显示为“OBF”。During the read phase, each write of a READ Control Code to Data_In will causeIBF to become set, causing the BMC to read in the Control Code and write a databyte to Data_Out in response. If the KCS interface uses an interrupt, the writeof the data byte to Data_Out will also generate an interrupt. The point atwhich this would occur during the READ_STATE is shown as “OBF” in Figure 9-7,KCS Interface BMC to SMS Read Transfer Flow Chart, below. 在读取阶段，每次向 Data_In 写入 READ 控制代码都会导致 IBF 置位，从而导致 BMC 读取控制代码并将数据字节写入 Data_Out 作为响应。 如果KCS接口使用中断，则将数据字节写入Data_Out也会产生中断。 在 READ_STATE 期间发生这种情况的点在下面的图9-7 KCS 接口 BMC 到 SMS 读取传输流程图中显示为“OBF”。Note that software does not need to use the Get Status/Abort transaction toreturn the interface to the IDLE_STATE or handle an error condition. Theinterface should return to IDLE_STATE on successful completion of any fullcommand/response transaction with the BMC. Thus, since the interface will allowa command transfer to be started or restarted at any time when the input bufferis empty, software could elect to simply retry the command upon detecting anerror condition, or issue a ‘known good’ command in order to clear ERROR_STATE. 请注意，软件不需要使用Get Status/Abort translation 来将接口返回到 IDLE_STATE 或处理错误情况。成功完成与 BMC 的任何完整命令/响应事务后，接口应返回 IDLE_STATE。因此，由于接口将允许在输入缓冲区为空时随时启动或重新启动命令传输，因此软件可以选择在检测到错误情况时简单地重试该命令，或者发出“known good”命令，以便 清除 ERROR_STATE。9.12 KCS Communication and Non-communication InterruptsThe following lists some general requirements and clarifications to supportboth KCS communication and KCS non-communication interrupts on the sameinterrupt line using the OBF signal. A KCS communications interrupt is definedas an OBF-generated interrupt that occurs during the process of sending arequest message to the BMC and receiving the corresponding response. Thisoccurs from the start of the write (request) phase of the message (issuingWRITE_START to the command register) through to the normal conclusion of thecorresponding read (response) phase of the message. (The conclusion of thecommunications interval is normally identified by the interface going toIDLE_STATE). KCS communications interrupts are also encountered during thecourse of processing a GET_STATUS/ABORT control code. clarifications [ˌklɛrɪfɪˈkeɪʃənz]: 澄清（法）；净（纯）化；清化（理）；说（阐）明；解释conclusion [kənˈkluːʒn] 结论; 结果; 结束; 缔结; 达成; 签订; 结局; 推论; 结尾interval: /ˈɪntərvl/: 间隔；(时间上的)间隙；间歇; 下面列出了使用 OBF 信号在同一中断线上支持 KCS 通信和 KCS 非通信中断的一些一般要求和说明。 KCS通信中断被定义为OBF-generated 的中断，该中断发生在向BMC发送请求消息并接收相应响应的过程中。 这发生在从消息的写入（请求）阶段（向命令寄存器发出 WRITE_START）开始到消息的相应读取（响应）阶段正常结束之间。 （通信间隔的结束通常由接口进入 IDLE_STATE 来标识）。 在处理 GET_STATUS/ABORT 控制代码的过程中也会遇到 KCS 通信中断。A KCS non-communication interrupt is defined as an OBF-generated interrupt thatoccurs when the BMC is not in the process of transferring message data orgetting error status. This will typically be an interrupt that occurs while theinterface is in the IDLE_STATE. KCS非通信中断被定义为OBF-generated 的中断，当BMC不在传输消息数据或获取错误状态的过程中时发生。 这通常是接口处于 IDLE_STATE 时发生的中断。There are several options in the BMC that can be enabled to cause KCSnon-communication interrupts as described in the Set BMC Global Enablescommand, and Get Message Flags commands. These are the watchdog timerpre-timeout interrupt, event message buffer interrupt, receive message queueinterrupt, and the OEM interrupts. Software can detect which of the standardinterrupts are supported by attempting to enable them using the Set BMC GlobalEnables command and checking for an error completion code. BMC 中有多个选项可以启用以导致 KCS 非通信中断，如 Set BMC Global Enables Command,和Get Message Flags commands中所述。 它们是看门狗定时器预超时中断、事件消息缓冲区中断、接收消息队列中断和 OEM 中断。 软件可以通过尝试使用 Set BMC Global Enables 命令启用标准中断并检查错误完成代码来检测支持哪些标准中断。9.13 Physical Interrupt Line SharingA typical interrupt-driven implementation will assert a physical interrupt linewhen OBF is asserted. In order to allow a single interrupt line to serve forboth communication and non-communication interrupts, the physical interruptline must be automatically deasserted by the BMC whenever a communication phasebegins, even if there is a pending non-communications interrupt to be serviced.This is necessary so the interrupt line can be used for signaling communicationinterrupts . Once the communication operations have completed (return to idlephase) the controller must re-assert the interrupt line if thenon-communications interrupt is still pending. 典型的中断驱动实现将在 OBF 置位时置位物理中断线。 为了允许单个中断线同时服务于通信和非通信中断，无论何时通信阶段开始，物理中断线都必须由 BMC 自动取消置位，即使有待处理的非通信中断需要服务。 这是必要的，因此中断线可用于发出通信中断信号。一旦通信操作完成（返回空闲阶段），如果非通信中断仍待处理，控制器必须重新断言中断线。9.14 Additional Specifications for the KCS interfaceThis section lists additional specifications for the KCS interface. The BMC must generate an OBF whenever it changes the status to ERROR_STATE.This will ensure that any transition to ERROR_STATE will cause the interrupthandler to run and catch the state. 每当 BMC 将状态更改为 ERROR_STATE 时，都必须生成 OBF。 这将确保任何到 ERROR_STATE 的转换都会导致中断处理程序运行并捕获状态。 The BMC generates an OBF upon changing the status to IDLE_STATE. An IPMI 1.5implementation is allowed to share this interrupt with a pending KCSnon-communication interrupt, or it elect to always generate a separate OBFinterrupt for non-communications interrupts. BMC 在状态更改为 IDLE_STATE 时生成 OBF。 IPMI 1.5 实现允许与待处理的 KCS 非通信中断共享此中断，或者选择始终为非通信中断生成单独的 OBF 中断。 A BMC implementation that elects to always generate a separatenon-communications interrupt must wait for the OBF interrupt that signalsentering the IDLE_STATE to be cleared before it asserts an OBF interrupt forthe non-communications interrupt. elects /ɪˈlekts/: 选举; 选择; 决定 选择始终生成单独的非通信中断的 BMC 实现必须等待信号进入 IDLE_STATE 的 OBF中断被清除，然后才能为非通信中断断言 OBF 中断。 IPMI v1.5 systems are allowed to generate a single OBF that covers both thelast communications interrupt (when the BMC status goes to IDLE_STATE) and apending non-communications interrupt. I.e. it is not required to generate aseparate OBF interrupt for the non-communications interrupt if anon-communications interrupt was pending at the time the BMC status goes toIDLE_STATE. In order to support this, an IPMI v1.5 KCS interfaceimplementation must set SMS_ATN for all standard (IPMI defined)non-communication interrupt sources. IPMI v1.5 系统允许生成单个 OBF，该 OBF 涵盖最后的通信中断（当 BMC 状态进入 IDLE_STATE 时）和待处理的非通信中断。 IE。 如果 BMC 状态进入 IDLE_STATE 时非通信中断处于待处理状态，则不需要为非通信中断生成单独的 OBF 中断。 为了支持这一点，IPMI v1.5 KCS 接口实现必须为所有标准（IPMI 定义）非通信中断源设置 SMS_ATN。 For IPMI v1.5, the BMC must set the SMS_ATN flag if any of the standardmessage flags become set. This includes Receive Message Available, EventMessage Buffer Full (if the Event Message Buffer Full condition is intendedto be handled by System Management Software), and Watchdog Timer pre-timeoutflags, as listed in the Get Message Flags command. This is independent ofwhether the corresponding interrupt is enabled or not. 对于 IPMI v1.5，如果设置了任何标准消息标志，BMC 必须设置 SMS_ATN 标志。 这包括接收消息可用、事件消息缓冲区已满（如果事件消息缓冲区已满条件旨在由系统管理软件处理）和看门狗定时器预超时标志，如获取消息标志命令中列出的。 这与相应的中断是否启用无关。 The BMC must change the status to ERROR_STATE on any condition where itaborts a command transfer in progress. For example, if the BMC had an OEMcommand that allowed the KCS interface to be asynchronously reset via IPMB,the KCS interface status should be put into the ERROR_STATE and OBF set, notIDLE_STATE, in order for software to be notified of the change. However, theBMC does not change the status to the ERROR_STATE, but to the IDLE_STATE,when the BMC executes the Get Status/Abort control code from SMS I/F, even ifthe Get Status/Abort control code is used to abort a transfer. 在任何中止正在进行的命令传输的情况下，BMC 都必须将状态更改为 ERROR_STATE。 例如，如果 BMC 有一个 OEM 命令允许通过 IPMB 异步重置 KCS 接口，则应将 KCS 接口状态设置为 ERROR_STATE 和 set OBF， 而不是 IDLE_STATE ，以便向软件通知更改。 然而，当 BMC 从 SMS I/F 执行 Get Status/Abort 控制代码时，BMC 不会将状态更改为 ERROR_STATE，而是更改为 IDLE_STATE，即使 Get Status/Abort控制代码用于中止传输 。 A cross-platform driver must be able to function without handling any of theOEM bits. Therefore, enabling SMS_ATN on OEM interrupts/states must not beenabled by default, but must be explicitly enabled either by the Set BMCGlobal Enables command or by an OEM-defined command. 跨平台驱动程序必须能够在不处理任何 OEM 位的情况下运行。 因此，默认情况下不得启用 OEM 中断/状态上的 SMS_ATN，而必须通过 Set BMC Global Enables 命令或 OEM 定义的命令显式启用。 The SMS_ATN bit will remain set until all standard interrupt sources in theBMC have been cleared by the Clear Message Flags command, or by acorresponding command. For example, the Read Message command canautomatically clear the Receive Message Queue interrupt if the commandempties the queue. SMS_ATN 位将保持设置状态，直到 BMC 中的所有标准中断源已被Clear Message Flag command 或相应的命令清除。 例如，如果读取消息命令清空队列，则该命令可以自动清除接收消息队列中断。 A KCS interface implementation that allows its interrupt to be shared withother hardware must set SMS_ATN whenever it generates a KCS interrupt. Asystem will typically report whether it allows an interrupt to be shared ornot via resource usage configuration reporting structures such as those inACPI. 允许与其他硬件共享其中断的 KCS 接口实现必须在生成 KCS 中断时设置 SMS_ATN。 系统通常会通过资源使用配置报告结构（例如 ACPI 中的报告结构）来报告是否允许共享中断。 OEM non-communications interrupts should be disabled by default. They must bereturned to the disabled state whenever the controller or the system ispowered up or reset. This is necessary to allow a generic driver to be usedwith the controller. A driver or system software must be explicitly requiredto enable vendor-specific non- communications interrupt sources in order forthem to be used. OEM non-communications interrupt sources must not contributeto SMS_ATN when they are disabled. The OEM 0, 1, and 2 flags that are returned by the Get Message Flags commandmay also cause the SMS_ATN flag to be set. A platform or system software mustnot enable these interrupts/flags unless there is a corresponding driver thatcan handle them. Otherwise, a generic cross-platform driver could get into asituation where it would never be able to clear SMS_ATN. It is recommended that any OEM generated non-communications interrupts causeat least one of the OEM flags in the Get Message Flags to become set. Thiswill enable improving system efficiency by allowing a cross- platform driverto pass the value of the Get Message Flags to an OEM extension, saving theOEM extension software from having to issue an additional command todetermine whether it has an anything to process. It is recommended that an OEM that uses the OEM flags sets the SMS_ATN flagif one or more of the OEM flags (OEM 0, OEM 1, or OEM 2) becomes set,especially if those flags can be the source of a KCS non- communicationsinterrupt. The driver can use SMS_ATN as the clue to execute the Get MessageFlags command and pass the data along to an OEM extension routine. OEM non-communications interrupts may elect to either share the IDLE_STATEOBF interrupt with the non- communications interrupt OBF, or generate aseparate non-communications OBF interrupt. If the OEM non- communicationsinterrupt implementation shares the IDLE_STATE OBF interrupt, the OEM non-communications interrupt must also set SMS_ATN. OEM 非通信中断可以选择与非通信中断 OBF 共享 IDLE_STATE OBF 中断，或者生成单独的非通信 OBF 中断。 如果 OEM 非通信中断实现共享 IDLE_STATE OBF 中断，则 OEM 非通信中断还必须设置 SMS_ATN。 9.15 KCS Flow DiagramsThe following flow diagrams have been updated from corresponding diagrams inthe original IPMI v1.0, rev. 1.1 specification. This information applies to thefollowing flow diagrams: 以下流程图已根据原始 IPMI v1.0 修订版中的相应图表进行了更新。 1.1 规范。 此信息适用于以下流程图： All system software wait loops should include error timeouts. For simplicity,such timeouts are not shown explicitly in the flow diagrams. A five-secondtimeout or greater is recommended. 所有系统软件等待循环都应包括错误超时。 为简单起见，流程图中未明确显示此类超时。 建议设置五秒或更长的超时时间。 The phase values represent state information that could be kept acrossdifferent activations of an interrupt handler, and corresponding entrypoints. Based on the ‘phase’ the interrupt handler would branch to thecorresponding point when an OBF interrupt occurred. The information may alsobe useful for error reporting and handling for both polled- andinterrupt-driven drivers. Note that other state may need to be kept as well.For example, during the ‘wr_data’ phase, the handler may also need topreserve a byte counter in order to track when the last byte of the write wasto be sent. phase 值表示可以在中断处理程序的不同activations 和相应的入口点之间保存的状态信息。当 OBF 中断发生时，中断处理程序将根据“phase”分支到相应的点。 该信息对于轮询驱动驱动程序和中断驱动驱动程序的错误报告和处理也可能有用。 请注意，可能还需要保留其他状态。 例如，在“wr_data” phase ，处理程序可能还需要保留字节计数器，以便跟踪写入的最后一个字节何时发送。 The symbol of a circle with an arrow and the text ‘OBF’ inside the circlerepresents the points where the BMC would write a dummy data byte to theoutput buffer in order to create an OBF interrupt. The label above the circleindicates where an interrupt handler would branch to when the OBF interruptoccurs under in the corresponding phase. An interrupt handler would exit uponcompleting the step that occurs before where the OBF interrupt symbol points. 带箭头的圆圈符号和圆圈内的文本“OBF”代表 BMC 将dummy data byte 写入输出缓冲区以创建OBF 中断的点。圆圈上方的标签表示在相应阶段发生 OBF 中断时中断处理程序将分支到的位置。中断处理程序将在完成 OBF 中断符号指向之前发生的步骤后退出。 wr_start OBF BMC sets status to WRITE_STATE immediately after receiving any control code inthe command register unless it needs to force an ERROR_STATE. The status isset before reading the control code from the input buffer. In the unlikely event that an asynchronous interrupt occurs after clearing OBFthe interrupt handler may spin waiting for IBF=0. BMC 在接收到命令寄存器中的任何控制代码后立即将状态设置为 WRITE_STATE，除非需要强制 ERROR_STATE。 在从输入缓冲区读取Control Code 之前设置状态。 万一在清除 OBF 后发生异步中断，中断处理程序可能会旋转等待 IBF=0。 wr_data OBF BMC updates state after receiving data byte in DATA_IN, but before reading thebyte out of the input buffer. I.e. it changes state while IBF=1 BMC 在接收 DATA_IN 中的数据字节之后、从输入缓冲区读取该字节之前更新状态。 IE。 当 IBF=1 时它改变状态 before READ The BMC sets state to READ_STATE before reading data byte from data register.This ensures state change to READ_STATE occurs while IBF=1 在从data register 读取数据字节之前，BMC 将状态设置为 READ_STATE。 这确保在 IBF=1 时发生状态更改为 READ_STATE read OBF This OBF is normally caused by the BMC returning a data byte for the readoperation. After the last data byte, the BMC sets the state to IDLE_STATE whileIBF=1 and then reads the input buffer to check the control code = READ. Thestatus will be set to ERROR_STATE if the control code is not READ. The BMC thenwrites a dummy data byte to the output buffer to generate an interrupt so thedriver can see the status change. 此 OBF 通常是由 BMC 返回读操作的数据字节引起的。 在最后一个数据字节之后，当IBF=1 时，BMC 将状态设置为 IDLE_STATE，然后读取输入缓冲区以检查控制代码 = READ。 如果控制代码未读取，状态将设置为 ERROR_STATE。 然后，BMC 将虚拟数据字节写入输出缓冲区以生成中断，以便驱动程序可以看到状态更改。 Note that software must track that it has received an interrupt from‘IDLE_STATE’ while it is still in the ‘read’ phase in order to differentiate itfrom a non-communication interrupt. If the BMC needs to set the status toERROR_STATE it will do so before writing a dummy 00h byte to the output buffer. (The BMC always places a dummy byte in the output buffer whenever it sets thestatus to ERROR_STATE.) 请注意，软件必须跟踪它在仍处于“read” phase 时已从“IDLE_STATE”接收到中断，以便将其与非通信中断区分开来。 如果 BMC 需要将状态设置为 ERROR_STATE，它将在将dummy 00h byte 写入输出缓冲区之前执行此操作。 （每当 BMC 将状态设置为 ERROR_STATE 时，BMC 总是在输出缓冲区中放置一个 dummy byte。） Read dummy data byte from DATA_OUT The BMC must wait for software to read the output buffer before writing OBF togenerate a non-communications interrupt. That is, if there are any pendinginterrupts while in IDLE_STATE, but OBF is already set, it must hold off theinterrupt until it sees OBF go clear. Softw are must be careful, since missingany read of the output buffer will effectively disable interrupt generation. Itmay be a prudent safeguard for a driver to poll for OBF occassionallyw henwaiting for an interrupt from the IDLE state. BMC 必须等待软件读取输出缓冲区后才能写入 OBF 以产生非通信中断。 也就是说，如果处于 IDLE_STATE 时有任何挂起的中断，但 OBF 已设置，则必须推迟中断，直到看到OBF 清除为止。 软件必须小心，因为错过任何输出缓冲区的读取将有效地禁用中断生成。 对于驱动程序来说，在等待来自 IDLE 状态的中断时偶尔轮询 OBF 可能是一种谨慎的保护措施。 Note that for IPMI v1.5, the last OBF interrupt is allowed to be shared with apending non-communications interrupt. See text. 请注意，对于 IPMI v1.5，允许最后一个 OBF 中断与待处理的非通信中断共享。 见正文。 9.16 Write Processing SummaryThe following summarizes the main steps write transfer from system software tothe BMC: Issue a ‘WRITE_START’ control code to the Command register to start thetransaction. Write data bytes (NetFn, Command, Data) to Data_In. Issue an ‘WRITE_END’ control code then the last data byte to conclude thewrite transaction.9.17 Read Processing SummaryThe following summarizes the main steps for a read transfer from the BMC tosystem software: Read Data_Out when OBF set Issue READ command to request additional bytes If READ_STATE (after IBF = 0), repeat previous two steps.9.18 Error Processing SummaryThe following summarizes the main steps by which system software processes KCSInterface errors: Issue a ‘GET_STATUS/ABORT’ control code to the Command register. Wait forIBF=0. State should be WRITE_STATE. If OBF=1, Clear OBF by reading Data_Out register. Write 00h to data register, wait for IBF=0. State should now be READ_STATE. Wait for OBF=1. Read status from Data_Out Conclude by writing READ to data register, wait for IBF=0. State should be IDLE.9.19 Interrupting Messages in ProgressIf, during a message transfer, the system software wants to abort a message itcan do so by the following methods: 如果在消息传输过程中，系统软件想要中止消息，可以通过以下方法来完成： Place another “WRITE_START” command into the Command Register (a WRITE_STARTControl Code is always legal). The BMC then sets the state flags to“WRITE_STATE” and sets its internal flags to indicate that the stream hasbeen aborted. 将另一个“WRITE_START”命令放入命令寄存器（WRITE_START 控制代码始终合法）。 然后，BMC 将状态标志设置为“WRITE_STATE”，并设置其内部标志以指示流已被中止。 Send a “GET_STATUS/ABORT” request. This is actually the same as #1 above butis explicitly stated to indicate that this command will cause the currentpacket to be aborted. This command allows a stream to be terminated and thestate to be returned to IDLE without requiring a complete BMC request andresponse transfer. 发送“GET_STATUS/ABORT”请求。 这实际上与上面的 #1 相同，但明确指出该命令将导致当前数据包中止。 该命令允许终止流并将状态返回到 IDLE，而不需要完整的BMC 请求和响应传输。 9.20 KCS Driver Design Recommendations A generic, cross-platform driver that supports the interrupt-driven KCSinterface is not required to handle interrupts other than the interruptsignal used for IPMI message communication with the BMC. The messageinterrupt may be shared with other BMC interrupt sources, such as thewatchdog timer pre-timeout interrupt, the event message buffer fullinterrupt, and OEM interrupts. A cross-platform driver should use the Get BMC Global Enables and Set BMCGlobal Enables commands in a ‘read-modify-write’ manner to avoid modifyingthe settings of any OEM interrupts or flags. It is recommended that cross-platform driver software provide a ‘hook’ thatallows OEM extension software to do additional processing of KCSnon-communication interrupts. It is highly recommended that the driverexecute the Get Message Flags command whenever SMS_ATN remains set afternormal processing and provide the results to the OEM extension software. The driver cannot know the whether the pre-existing state of any OEMinterrupts or flags is correct. Therefore, a driver that supports OEMextensions should allow for an OEM initialization routine that can configurethe OEM flags/interrupts before KCS OBF-generated interrupts are enabled. It is recommended that cross-platform drivers or software make provision forBMC implementations that may miss generating interrupts on a command errorcondition by having a timeout that will activate the driver or software incase an expected interrupt is not received. A driver should be designed to allow for the possibility that an earlier BMCimplementation does not set the SMS_ATN flag except when there is data in theReceive Message Queue. If the driver cannot determine whether SMS_ATN issupported for all enabled standard flags or not, it should issue a GetMessage Flags command whenever it gets a KCS non-communication interrupt. A driver or system software can test for whether the Watchdog Timerpre-timeout and/or Event Message Buffer Full flags will cause SMS_ATN tobecome set. This is accomplished by disabling the associated interrupts (ifenabled) and then causing a corresponding action that sets the flag. This isstraightforward by using the watchdog timer commands in conjunction with theSet BMC Global Enables and Get Message Flags commands. For example, to test for the Event Message Buffer Full flag setting SMS_ATN,first check to see if the Event Message Buffer feature is implemented byattempting to enable the event message buffer using the Set and Get BMCGlobal Enables command. If the feature is not implemented, an errorcompletion code will be returned. Next, disable event logging and use thewatchdog timer to generate an SMS/OS ‘no action’ timeout event, then see ifthe SMS_ATN becomes set. If so, use the Get Message Flags command to verifythat the Event Message Buffer Full flag is the only one set (in case anasynchronous message came in to the Receive Message Queue during the test.)The pre-timeout interrupt can be testing in a similar manner. It is possible (though not recommended) for a BMC implementation to includeproprietary non- communication interrupt sources that do not set SMS_ATN.These sources must not be enabled by default. It is recommended that ageneric cross-platform driver have provisions for OEM extensions that getcalled whenever a non-communication interrupt occurs. It is recommended thatthe extension interface provides the last reading of the KCS flags so that anOEM extension can see the state of SMS_ATN. Software should be aware that IPMI v1.0 implementations were not required toset SMS_ATN for all non- communication interrupts. If a BMC implementationdoes not set SMS_ATN for all non-communication interrupts, it must generate aseparate OBF interrupt for non-communication interrupts. A controller thatdoes not set SMS_ATN for all non-communication interrupts is not allowed touse the same OBF interrupt to signal the both completion of communicationsand a non-communications interrupt. Regardless of whether the IDLE_STATE OBF interrupt is shared with a pendingnon-communications interrupt, software drivers must examine SMS_ATN afterclearing OBF. If SMS_ATN is asserted the driver must process thenon-communications interrupt sources. " }, { "title": "unrestricted guests", "url": "/posts/unrestricted-guests/", "categories": "intel_sdm", "tags": "virt", "date": "2024-04-25 11:21:00 +0800", "snippet": " FROM intel sdm CHAPTER 26 VMX NON-ROOT OPERATION 26.6 UNRESTRICTED GUESTS The first processors to support VMX operation require CR0.PE and CR0.PG to be 1in VMX operation (see Section 24.8). Th...", "content": " FROM intel sdm CHAPTER 26 VMX NON-ROOT OPERATION 26.6 UNRESTRICTED GUESTS The first processors to support VMX operation require CR0.PE and CR0.PG to be 1in VMX operation (see Section 24.8). This restriction implies that guestsoftware cannot be run in unpaged protected mode or in real-address mode. Laterprocessors support a VM-execution control called “unrestrictedguest”.1If this control is 1, CR0.PE and CR0.PG may be 0 in VMXnon-root operation. Such processors allow guest software to run in unpagedprotected mode or in real-address mode. The following items describe thebehavior of such software: 第一个支持 VMX operation 的处理器要求 CR0.PE 和 CR0.PG 在 VMX operation中为 1（参见第 24.8 节）。 此限制意味着guest软件不能在未分页保护模式或实地址模式下运行。更高版本的处理器支持称为“unrestricted guest”的 VM-execution control。1如果此控制字段为 1，则在 VMX non-root operation中 CR0.PE 和 CR0.PG 可能为 0。此类处理器允许guest软件在未分页保护模式或实地址模式下运行。 以下各项描述了此类软件的行为： The MOV CR0 instructions does not cause a general-protection exception simplybecause it would set either CR0.PE and CR0.PG to 0. See Section 26.3 fordetails. MOV CR0 指令不会仅仅因为将 CR0.PE 和 CR0.PG 设置为 0 而导致一般保护异常。有关详细信息，请参见第 26.3 节。 A logical processor treats the values of CR0.PE and CR0.PG in VMX non-rootoperation just as it does outside VMX operation. Thus, if CR0.PE = 0, theprocessor operates as it does normally in real-address mode (for example, ituses the 16-bit interrupt table to deliver interrupts and exceptions). IfCR0.PG = 0, the processor operates as it does normally when paging isdisabled. 逻辑处理器在 VMX non-root operation中处理 CR0.PE 和 CR0.PG 的值，就像在 VMX operation 之外一样。 因此，如果 CR0.PE = 0，处理器将像正常在实地址模式下一样运行（例如，它使用 16 位中断表来传递中断和异常）。 如果 CR0.PG = 0，则处理器在禁用分页时将正常运行。 Processor operation is modified by the fact that the processor is in VMXnon-root operation and by the settings of the VM-execution controls just asit is in protected mode or when paging is enabled. Instructions, interrupts,and exceptions that cause VM exits in protected mode or when paging isenabled also do so in real-address mode or when paging is disabled. Thefollowing examples should be noted: the fact that: ...的事实, 确切的说, 事实上, 实际上 处理器 operation 是由处理器处于VMX non-root operation 以及 VM-executioni controls 的设置来修改的(这个翻译不通)，就像它处于保护模式或启用分页时一样。在保护模式下或启用分页时导致VM退出的指令、中断和异常在实际地址模式下或禁用分页时也会这样做。应注意以下示例： 这里实际上是想表明, 在VMX non-root operation 下的行为由 VM-execution controls 控制, 和guest处于什么mode无关(protect ? paging?) If CR0.PG = 0, page faults do not occur and thus cannot cause VM exits. 如果CR0.PG=0，则不会发生page fault，因此不会导致VM exit。 If CR0.PE = 0, invalid-TSS exceptions do not occur and thus cannot cause VMexits. 如果CR0.PE=0，则不会发生invalid-TSS exception，因此不会导致VM exits。 If CR0.PE = 0, the following instructions cause invalid-opcode exceptionsand do not cause VM exits: INVEPT, INVVPID, LLDT, LTR, SLDT, STR, VMCLEAR,VMLAUNCH, VMPTRLD, VMPTRST, VMREAD, VMRESUME, VMWRITE, VMXOFF, and VMXON. 如果CR0.PE=0，则以下指令会导致 invalid-opcode 异常，并且不会导致VM exit：… If CR0.PG = 0, each linear address is passed directly to the EPT mechanismfor translation to a physical address.2 The guest memory typepassed on to the EPT mechanism is WB (writeback). 如果CR0.PG=0，则每个线性地址都直接传递给EPT机制，用于转换为物理地址。2传递到EPT机制的guest memory type 为WB（写回）。 “Unrestricted guest” is a secondary processor-based VM-execution control. Ifbit 31 of the primary processor-based VM-execution controls is 0, VMXnon-root operation functions as if the “unrestricted guest” VM-executioncontrol were 0. See Section 25.6.2. “unrestricted guest” 是 secondary processor-based VM-execution 控制字段. 如果 primary processor-based VM-execution controls 的bit 31 为1. VMX non-rootoperation 的function 就像“unrestricted guests”VM-execution control 为0一样。请看Section 25.6.2. As noted in Section 27.2.1.1, the “enable EPT” VM-execution control must be1 if the “unrestricted guest” VM-execution control is 1. 如Section 27.2.1.1 提到的, 如果 “unrestricted guest” VM-execution 控制字段为1, “enable EPT” VM-execution 控制字段也必须是1. " }, { "title": "restrictions of VMX operation", "url": "/posts/vmx-operation-restrict/", "categories": "intel_sdm", "tags": "virt", "date": "2024-04-25 11:11:00 +0800", "snippet": " FROM intel sdm CHAPTER 24 INTRODUCTION TO VIRTUAL MACHINE EXTENSIONS 24.8 RESTRICTIONS ON VMX OPERATION VMX operation places restrictions on processor operation. These are detailedbelow: VMX...", "content": " FROM intel sdm CHAPTER 24 INTRODUCTION TO VIRTUAL MACHINE EXTENSIONS 24.8 RESTRICTIONS ON VMX OPERATION VMX operation places restrictions on processor operation. These are detailedbelow: VMX operation 对处理器操作施加限制。 这些详细信息如下： In VMX operation, processors may fix certain bits in CR0 and CR4 to specificvalues and not support other values. VMXON fails if any of these bitscontains an unsupported value (see “VMXON—Enter VMX Operation” in Chapter31). Any attempt to set one of these bits to an unsupported value while inVMX operation (including VMX root operation) using any of the CLTS, LMSW, orMOV CR instructions causes a general-protection exception. VM entry or VMexit cannot set any of these bits to an unsupported value. Software shouldconsult the VMX capability MSRs IA32_VMX_CR0_FIXED0 and IA32_VMX_CR0_FIXED1to determine how bits in CR0 are fixed (see Appendix A.7). For CR4, softwareshould consult the VMX capability MSRs IA32_VMX_CR4_FIXED0 andIA32_VMX_CR4_FIXED1 (see Appendix A.8). 在VMX operation中，处理器可以将CR0和CR4中的某些位fix(固定, 相当于不能修改)为特定值并且不支持其他值。 如果这些位中的任何一个包含不支持的值，则 VMXON 失败（请参阅第 31 章中的“VMXON — Enter VMX opeartion”）。 在 VMX operation（包括 VMX root opeartion）中使用任何 CLTS、LMSW 或 MOV CR 指令将这些位之一设置为不受支持的值的任何尝试都会导致一般保护异常。 VM entry 或 VM exit无法将这些位中的任何一个设置为不受支持的值。软件应参考 VMX 功能 MSR IA32_VMX_CR0_FIXED0 和 IA32_VMX_CR0_FIXED1 以确定如何fix CR0 中的位（请参阅附录 A.7）。 对于 CR4，软件应参考 VMX 功能 MSR IA32_VMX_CR4_FIXED0 和 IA32_VMX_CR4_FIXED1（请参阅附录 A.8）。 NOTES The first processors to support VMX operation require that the followingbits be 1 in VMX operation: CR0.PE, CR0.NE, CR0.PG, and CR4.VMXE. Therestrictions on CR0.PE and CR0.PG imply that VMX operation is supportedonly in paged protected mode (including IA-32e mode). Therefore, guestsoftware cannot be run in unpaged protected mode or in real-address mode. 第一批支持 VMX opeartion的处理器要求 VMX opeartion中以下位为 1：CR0.PE、CR0.NE、CR0.PG 和 CR4.VMXE。 对 CR0.PE 和 CR0.PG 的限制意味着仅在分页保护模式（包括 IA-32e 模式）下支持 VMX operation。 因此，guest软件不能在未分页保护模式或实地址模式下运行。 Later processors support a VM-execution control called “unrestricted guest”(see Section 25.6.2). If this control is 1, CR0.PE and CR0.PG may be 0 inVMX non-root operation (even if the capability MSR IA32_VMX_CR0_FIXED0reports otherwise).1 Such processors allow guest software to run in unpagedprotected mode or in real-address mode. 更高版本的处理器支持称为“unrestricted guest”的 VM-execution control（请参阅第 25.6.2 节）。 如果此控制字段为 1，则 CR0.PE 和 CR0.PG 在 VMX non-root operation中可能为 0（即使 MSR IA32_VMX_CR0_FIXED0 功能另有报告）1。此类处理器允许guest软件在未分页保护模式或实地址下运行 模式。 VMXON fails if a logical processor is in A20M mode (see “VMXON—Enter VMXOperation” in Chapter 31). Once the processor is in VMX operation, A20Minterrupts are blocked. Thus, it is impossible to be in A20M mode in VMXoperation. 如果逻辑处理器处于 A20M 模式，VMXON 将失败（请参阅第 31 章中的“VMXON—EnterVMX opeartion”）。 一旦处理器处于 VMX opeartion 中，A20M 中断就会被阻止。 因此，在 VMX opeartion中不可能处于 A20M 模式。 The INIT signal is blocked whenever a logical processor is in VMX rootoperation. It is not blocked in VMX non-root operation. Instead, INITs causeVM exits (see Section 26.2, “Other Causes of VM Exits”). 只要逻辑处理器处于 VMX root operation中，INIT signal 就会被blocked。 在 VMX non-root opeartion中不会被block。 相反，INIT 会导致 VM exit（请参见第 26.2 节“VM exit的其他原因”）。 Intel(R) Processor Trace (Intel PT) can be used in VMX operation only ifIA32_VMX_MISC[14] is read as 1 (see Appendix A.6). On processors that supportIntel PT but which do not allow it to be used in VMX operation, execution ofVMXON clears IA32_RTIT_CTL.TraceEn (see “VMXON—Enter VMX Operation” inChapter 31); any attempt to write IA32_RTIT_CTL while in VMX operation(including VMX root operation) causes a general- protection exception. 略(和 INTEL PT 技术相关) " }, { "title": "user-timer event and interrupt", "url": "/posts/user-timer/", "categories": "intel_sdm", "tags": "virt", "date": "2024-04-25 10:30:00 +0800", "snippet": " FROM Intel® Architecture Instruction Set Extensions and Future Features doc number 319433-052 CHAPTER 13 USER-TIMER EVENTS AND INTERRUPTSabstractThis chapter describes an architectural feature...", "content": " FROM Intel® Architecture Instruction Set Extensions and Future Features doc number 319433-052 CHAPTER 13 USER-TIMER EVENTS AND INTERRUPTSabstractThis chapter describes an architectural feature called user-timer events.The feature defines a new 64-bit value called the user deadline. Software mayread and write the user deadline. When the user deadline is not zero, auser-timer event becomes pending when the logical processor’s timestamp counter(TSC) is greater than or equal to the user deadline.A pending user-timer event is processed by the processor when CPL = 3 andcertain other conditions apply. When processed, the event results in a userinterrupt with the user-timer vector. (Software may read and write theuser-timer vector). Specifically, the processor sets the bit in the UIRR (userinterrupt request register) corre- sponding to the user timer vector. Theprocessing also clears the user deadline, ensuring that there will be nosubsequent user-timer events until software writes the user deadline again.Section 13.1 discusses the enabling and enumeration of the new feature. Section13.2 presents details of the user deadline, and Section 13.3 explains how it(together with the user-timer vector) is represented in a new MSR. Section 13.4explains when and how a logical processor processes a pending user-timer event.Section 13.5 pres- ents VMX support for virtualizing the new feature.13.1 ENABLING AND ENUMERATIONProcessor support for user-timer events is enumerated by CPUID.(EAX=07H,ECX=1H):EDX.UTMR[bit 13]. If this feature flag is set, the processor supportsuser-timer events, and software can access the IA32_UINTR_TIMER MSR (seeSection 13.3).13.2 USER DEADLINEA logical processor that supports user-timer events supports a 64-bit valuecalled the user deadline. If the user deadline is non-zero, the logicalprocessor pends a user-timer event when the timestamp counter (TSC) reaches orexceeds the user deadline.Software can write the user deadline using instructions specified later in thischapter (see Section 13.3). The processor enforces the following: Writing zero to the user deadline disables user-timer events and cancels anythat were pending. As a result, no user-timer event is pending after zero iswritten to the user deadline. If software writes the user deadline with a non-zero value that is less thanthe TSC, a user-timer event will be pending upon completion of that write. If software writes the user deadline with a non-zero value that is greaterthan that of the TSC, no user-timer event will be pending after the writeuntil the TSC reaches the new user deadline. A logical processor processes a pending user-timer event under certainconditions; see Section 13.4. The logical processor clears the user deadlineafter pending a user-timer event. Races may occur if software writes a new user deadline when the value of theTSC is close to that of the original user deadline. In such a case, either ofthe following may occur: The TSC may reach the original deadline before the write to the deadline,causing a user-timer event to be pended. Either of the following may occur: If the user-timer event is processed before the write to the deadline, thelogical processor will clear the deadline before the write. The write tothe deadline may cause a second user-timer event to occur later. If the write to the deadline occurs before the user-timer event isprocessed, the original user-timer event is canceled, and any subsequentuser-timer event will be based on the new value of the deadline. When writing to the deadline, it may not be possible for software to controlwith certainty which of these two situations occurs. The write to the deadline may occur before TSC reaches the original deadline.In this case, no user-timer event will occur based on the original deadline.Any subsequent user-timer event will be based on the new value of thedeadline. Software writes to the user deadline using a new MSR described in Section 13.3.13.3 USER TIMER: ARCHITECTURAL STATEThe user-timer architecture defines a new MSR, IA32_UINTR_TIMER. This MSR canbe accessed using MSR index 1B00H.The IA32_UINTR_TIMER MSR has the following format: Bits 5:0 are the user-timer vector. Processing of a user-timer event resultsin the pending of a user interrupt with this vector (see Section 13.4). Bits 63:6 are the upper 56 bits of the user deadline (see Section 13.2). Note that no bits are reserved in the MSR and that writes to the MSR will notfault due to the value of the instruc- tion’s source operand. TheIA32_UINTR_TIMER MSR can be accessed via the following instructions: RDMSR,RDMSRLIST, URDMSR, UWRMSR, WRMSR, WRMSRLIST, and WRMSRNS.If the IA32_UINTR_TIMER MSR is written with value X, the user-timer vector getsvalue X &amp; 3FH; the user deadline gets value X &amp; ~3FH.If the user-timer vector is V (0 ≤ V ≤ 63) and the user deadline is D, a readfrom the IA32_UINTR_TIMER MSR return value (D &amp; ~3FH) | V.13.4 PENDING AND PROCESSING OF USER-TIMER EVENTSThere is a user-timer event pending whenever the user deadline (Section 13.2)is non-zero and is less than or equal to the value of the timestamp counter(TSC).If CR4.UINTR = 1, a logical processor processes a pending user-timer event atan instruction boundary at which the following conditions all hold1: IA32_EFER.LMA = CS.L = 1 (the logical processor is in 64-bit mode); CPL =3; UIF = 1; and the logical processor is not in the shutdown state or in the wait-for-SIPIstate.2When the conditions just identified hold, the logical processor processes auser-timer event. User-timer events have priority just above that ofuser-interrupt delivery. If the logical processor was in a state entered usingthe TPAUSE and UMWAIT instructions, it first wakes up from that state andbecomes active. If the logical processor was in enclave mode, it exits theenclave (via AEX) before processing the user-timer event.The following pseudocode details the processing of a user-timer event:UIRR[UserTimerVector] := 1;recognize a pending user interrupt;// may be delivered immediately after processingIA32_UINTR_TIMER := 0;// clears the deadline and the vectorProcessing of a user-timer event aborts transactional execution and results ina transition to a non-transactional execution. The transactional abort loadsEAX as it would have had it been due to an ordinary interrupt.Processing of a user-timer event cannot cause a fault or a VM exit.13.5 VMX SUPPORTThe VMX architecture supports virtualization of the instruction set and itssystem architecture. Certain extensions are needed to support virtualization ofuser-timer events. This section describes these extensions.13.5.1 VMCS ChangesOne new 64-bit VM-execution control field is defined called the virtualuser-timer control. It can be accessed with the encoding pair 2050H/2051H. SeeSection 13.5.2 for its use in VMX non-root operation. This field exists only onprocessors that enumerate CPUID.(EAX=07H, ECX=1H):EDX[13] as 1 (see Section13.1).13.5.2 Changes to VMX Non-Root OperationThis section describes changes to VMX non-root operation for user-timer events.13.5.2.1 Treatment of Accesses to the IA32_UINTR_TIMER MSRAs noted in Section 13.3, software can read and write the IA32_UINTR_TIMER MSRusing certain instructions. The operation of those instructions is changed whenthey are executed in VMX non-root operation: Any read from the IA32_UINTR_TIMER MSR (e.g., by RDMSR) returns the value ofthe virtual user-timer control. Any write to the IA32_UINTR_TIMER MSR (e.g., by WRMSR) is treated as follows: The source operand is written to the virtual user-timer control (updatingthe VMCS). Bits 5:0 of the source operand are written to the user-timer vector. If bits 63:6 of the source operand are zero, the user deadline (the valuethat actually controls when hardware generates a user time event) iscleared to 0. Section 13.2 identifies the consequences of this clearing. If bits 63:6 of the source operand are not all zero, the user deadline iscomputed as follows. The source operand (with the low 6 bits cleared) isinterpreted as a virtual user deadline. The processor converts that valueto the actual user deadline based on the current configuration of TSCoffsetting and TSC scaling.1 Following such a write, the value of the IA32_UINTR_TIMER MSR (e.g., aswould be observed following a subsequent VM exit) is such that bits 63:6contain the actual user deadline (not the virtual user deadline), whilebits 5:0 contain the user-timer vector. 13.5.2.2 Treatment of User-Timer EventsThe processor’s treatment of user-timer events is described in Section 13.4.These events occur in VMX non-root operation under the same conditionsdescribed in that section.The processing of user-timer events differs in VMX non-root operation only inthat, in addition to clearing the IA32_UINTR_TIMER MSR, the processing alsoclears the virtual user-timer control (updating the VMCS).13.5.3 Changes to VM EntriesA VM entry results in a pending user-timer event if and only if the VM entrycompletes with the user deadline non- zero and less than or equal to the(non-virtualized) TSC. The processor will process such an event only ifindicated by the conditions identified in Section 13.4." }, { "title": "virtualization cr0", "url": "/posts/virtualization-cr0/", "categories": "intel_sdm", "tags": "virt", "date": "2024-04-24 18:30:00 +0800", "snippet": "Guest/Host Masks and Read Shadows for CR0 and CR4 FROM intel sdm CHAPTER 25 VIRTUAL MACHINE CONTROL STRUCTURES 25.6 VM-EXECUTION CONTROL FIELDS 25.6.6 VM-execution control fields include gue...", "content": "Guest/Host Masks and Read Shadows for CR0 and CR4 FROM intel sdm CHAPTER 25 VIRTUAL MACHINE CONTROL STRUCTURES 25.6 VM-EXECUTION CONTROL FIELDS 25.6.6 VM-execution control fields include guest/host masks and read shadows for theCR0 and CR4 registers. These fields control executions of instructions thataccess those registers (including CLTS, LMSW, MOV CR, and SMSW). They are 64bits on processors that support Intel 64 architecture and 32 bits on processorsthat do not. VM-execution control 字段包括对于CR0 和 CR4 寄存器的 guest/host masks 和 read shadows. 这些字段控制访问这些寄存器的指令的执行（包括 CLTS、LMSW、MOV CR 和 SMSW）。 它们在支持 Intel 64 架构的处理器上为 64 位，在不支持 Intel 64 架构的处理器上为 32 位。In general, bits set to 1 in a guest/host mask correspond to bits “owned” bythe host: 一般来说，guest/host mask中设置为 1 的位对应于host“owned(拥有)”的位： Guest attempts to set them (using CLTS, LMSW, or MOV to CR) to valuesdiffering from the corresponding bits in the corresponding read shadow causeVM exits. guest尝试将它们（使用 CLTS、LMSW 或 MOV 到 CR）设置为与read shadow中的相应位不同的值，导致 VM exit Guest reads (using MOV from CR or SMSW) return values for these bits from thecorresponding read shadow. Bits cleared to 0 correspond to bits “owned” bythe guest; guest attempts to modify them succeed and guest reads returnvalues for these bits from the control register itself. correspond [ˌkɔːrəˈspɑːnd]: : 相一致, 符合;相当于;类似于 guest读取（使用 CR 或 SMSW 中的 MOV）从相应的read shadow中返回这些位的值。cleared为 0 的位对应于guest “拥有”的位；guest尝试修改它们成功，并且guest从他们自己的控制寄存器读取这些位的值. See Chapter 28 for details regarding how these fields affect VMX non-rootoperation. 有关这些字段如何影响 VMX 非 root 操作的详细信息，请参阅第 26 章。 这里intel sdm 中写错了, 应该是26章 MOV to CR0 cause VM Exits Conditionally FROM intel sdm CHAPTER 26 VMX NON-ROOT OPERATION 26.1 INSTRUCTIONS THAT CAUSE VM EXITS 26.1.3 Instructions That Cause VM Exits Conditionally MOV to CR0. The MOV to CR0 instruction causes a VM exit unless the value of its sourceoperand matches, for the position of each bit set in the CR0 guest/host mask,the corresponding bit in the CR0 read shadow. (If every bit is clear in theCR0 guest/host mask, MOV to CR0 cannot cause a VM exit.) MOV 到 CR0 指令会导致 VM 退出，除非其源操作数的值与CR0guest/host mask中设置的每个位的位置对应的 CR0 read shadow中相应位的值匹配。 （如果 CR0 guest/host mask中的每一位都被清除，则 MOV 到 CR0 不会导致 VM 退出。） E.g. CR0 guest host mask : 0 0 0 0 1 0 1 0 1 0 1 | | | | | | | |CR0 read shadow : 1 1 1 1 1 1 1 1 1 1 1compare bit : ^ ^ ^ ^source operand : x x x x 1 x 1 x 1 x 1 ---&gt; NO vm exitsource operand : x x x x x x x x x x 0 ---&gt; need vm exit 会将设置的值和 compare bit进行比较, 如果两者一样, 则不需要vm exit, 如果不一样, 则需要VM exit, 下面会说明原因 CHANGES TO “MOV from/to CR0” BEHAVIOR IN VMX NON-ROOT OPERATION FROM intel sdm CHAPTER 26 VMX NON-ROOT OPERATION 26.3 CHANGES TO INSTRUCTION BEHAVIOR IN VMX NON-ROOT OPERATION MOV from CR0. The behavior of MOV from CR0 is determined by the CR0 guest/host mask andthe CR0 read shadow. For each position corresponding to a bit clear in theCR0 guest/host mask, the destination operand is loaded with the value ofthe corresponding bit in CR0. For each position corresponding to a bit setin the CR0 guest/host mask, the destination operand is loaded with thevalue of the corresponding bit in the CR0 read shadow. Thus, if every bitis cleared in the CR0 guest/host mask, MOV from CR0 reads normally fromCR0; if every bit is set in the CR0 guest/host mask, MOV from CR0 returnsthe value of the CR0 read shadow. Depending on the contents of the CR0guest/host mask and the CR0 read shadow, bits may be set in the destinationthat would never be set when reading directly from CR0. MOV from CR0 的行为由 CR0 guest/host mask和 CR0 read shadow决定。 对于与 CR0 guest/host mask中清零位相对应的每个位置，目标操作数将加载CR0 中相应位的值。 对于与 CR0 guest/host mask中设置的位相对应的每个位置，目标操作数将加载 CR0 read shadow中相应位的值。 因此，如果 CR0 guest/host mask中的每一位都被清除，则 MOV from CR0 会正常从 CR0 读取； 如果在 CR0 guest/host mask中设置了每个位，则MOV from CR0 将返回 CR0 read shadow的值。根据 CR0 guest/host mask和 CR0 read shadow的内容，可能会在destination设置一些 直接从 CR0 读取的永远不会设置的位。 MOV to CR0 An execution of MOV to CR0 that does not cause a VM exit (see Section 26.1.3)leaves unmodified any bit in CR0 corresponding to a bit set in the CR0guest/host mask. Treatment of attempts to modify other bits in CR0 depends onthe setting of the “unrestricted guest” VM-execution control: 执行 MOV to CR0 不会导致 VM 退出（请参阅第 26.1.3 节），从而使 CR0 中与 CR0guest/host mask中设置的位相对应的任何位保持不变。 对修改 CR0 中其他位的尝试的处理取决于“unrestricted guest”VM-execution control 的设置： If the control is 0, MOV to CR0 causes a general-protection exception if itattempts to set any bit in CR0 to a value not supported in VMX operation(see Section 24.8). 如果控制为 0，则 MOV to CR0 尝试将 CR0 中的任何位设置为 VMX operation不支持的值时会导致一般保护异常（请参见第 24.8 节）。 If the control is 1, MOV to CR0 causes a general-protection exception if itattempts to set any bit in CR0 other than bit 0 (PE) or bit 31 (PG) to avalue not supported in VMX operation. It remains the case, however, thatMOV to CR0 causes a general-protection exception if it would result in CR0. 如果控制为 1，则 MOV to CR0 尝试将 CR0 中除位 0 (PE) 或位 31 (PG) 之外的任何位设置为 VMX operation 不支持的值时，会导致一般保护异常。 然而，情况仍然如此，如果 MOV to CR0 会导致 CR0，则会导致一般保护异常。 MY note读取操作:graphviz-75150b4de17bd88865df62a6317d07dcdigraph G { subgraph cluster_cr0 { cr0_bitmap [ shape=&quot;record&quot; label=&quot;&lt;0&gt;0|&lt;1&gt;0|&lt;2&gt;0|&lt;3&gt;0&quot; ] label=&quot;cr0&quot; } subgraph cluster_cr0_host_guest_mask { cr0_host_guest_mask_bitmap [ shape=&quot;record&quot; label=&quot;&lt;0&gt;0|&lt;1&gt;1|&lt;2&gt;1|&lt;3&gt;1&quot; ] label=&quot;cr0 host/guest mask&quot; } subgraph cluster_cr0_read_shadow { cr0_read_shadow_bitmap [ shape=&quot;record&quot; label=&quot;&lt;0&gt;1|&lt;1&gt;1|&lt;2&gt;1|&lt;3&gt;1&quot; ] label=&quot;cr0 read shadow bitmap&quot; } subgraph cluster_destination_value { destination_value [ shape=&quot;record&quot; label=&quot;&lt;0&gt;0|&lt;1&gt;1|&lt;2&gt;1|&lt;3&gt;1&quot; ] label=&quot;destination value&quot; } cr0_host_guest_mask_bitmap:0-&gt;cr0_bitmap:0 cr0_host_guest_mask_bitmap:1-&gt;cr0_read_shadow_bitmap:1 cr0_host_guest_mask_bitmap:2-&gt;cr0_read_shadow_bitmap:2 cr0_host_guest_mask_bitmap:3-&gt;cr0_read_shadow_bitmap:3 cr0_bitmap:0-&gt;destination_value:0 cr0_read_shadow_bitmap:1-&gt;destination_value:1 cr0_read_shadow_bitmap:2-&gt;destination_value:2 cr0_read_shadow_bitmap:3-&gt;destination_value:3}Gcluster_cr0cr0cluster_cr0_host_guest_maskcr0 host/guest maskcluster_cr0_read_shadowcr0 read shadow bitmapcluster_destination_valuedestination valuecr0_bitmap0000destination_value0111cr0_bitmap:0&#45;&gt;destination_value:0cr0_host_guest_mask_bitmap0111cr0_host_guest_mask_bitmap:0&#45;&gt;cr0_bitmap:0cr0_read_shadow_bitmap1111cr0_host_guest_mask_bitmap:1&#45;&gt;cr0_read_shadow_bitmap:1cr0_host_guest_mask_bitmap:2&#45;&gt;cr0_read_shadow_bitmap:2cr0_host_guest_mask_bitmap:3&#45;&gt;cr0_read_shadow_bitmap:3cr0_read_shadow_bitmap:1&#45;&gt;destination_value:1cr0_read_shadow_bitmap:2&#45;&gt;destination_value:2cr0_read_shadow_bitmap:3&#45;&gt;destination_value:3write 操作 write to read shadowgraphviz-e91004f4e482ae0d030678a73454dad1digraph G { subgraph cluster_cr0_host_guest_mask { cr0_host_guest_mask_bitmap [ shape=&quot;record&quot; label=&quot;&lt;0&gt;0|&lt;1&gt;0|&lt;2&gt;0|&lt;3&gt;1&quot; ] label=&quot;cr0 host/guest mask&quot; } subgraph cluster_cr0_read_shadow { cr0_read_shadow_bitmap [ shape=&quot;record&quot; label=&quot;&lt;0&gt;0|&lt;1&gt;0|&lt;2&gt;0|&lt;3&gt;1&quot; ] label=&quot;cr0 read shadow bitmap&quot; } subgraph cluster_source_value { source_value [ shape=&quot;record&quot; label=&quot;&lt;0&gt;0|&lt;1&gt;0|&lt;2&gt;0|&lt;3&gt;0&quot; ] label=&quot;source value&quot; } subgraph cluster_source_value2 { source_value2 [ shape=&quot;record&quot; label=&quot;&lt;0&gt;0|&lt;1&gt;0|&lt;2&gt;0|&lt;3&gt;1&quot; ] label=&quot;source value2&quot; } cr0_host_guest_mask_bitmap:3-&gt;source_value:3 [ label=&quot;indicate compare bit&quot; color=&quot;red&quot; fontcolor=&quot;red&quot; ] cr0_host_guest_mask_bitmap:3-&gt;source_value2:3 [ label=&quot;indicate compare bit&quot; color=&quot;blue&quot; fontcolor=&quot;blue&quot; ] source_value2:3-&gt;cr0_read_shadow_bitmap:3 [ label=&quot;compare equal SKIP&quot; color=&quot;blue&quot; fontcolor=&quot;blue&quot; ] source_value:3-&gt;cr0_read_shadow_bitmap:3 [ label=&quot;compare NOT equal \\nvm EXIT, hypervisor \\nmay execute some emulations&quot; color=&quot;red&quot; fontcolor=&quot;red&quot; ]}Gcluster_cr0_host_guest_maskcr0 host/guest maskcluster_cr0_read_shadowcr0 read shadow bitmapcluster_source_valuesource valuecluster_source_value2source value2cr0_host_guest_mask_bitmap0001source_value0000cr0_host_guest_mask_bitmap:3&#45;&gt;source_value:3indicate compare bitsource_value20001cr0_host_guest_mask_bitmap:3&#45;&gt;source_value2:3indicate compare bitcr0_read_shadow_bitmap0001source_value:3&#45;&gt;cr0_read_shadow_bitmap:3compare NOT equal vm EXIT, hypervisor may execute some emulationssource_value2:3&#45;&gt;cr0_read_shadow_bitmap:3compare equal SKIP direct write to CR3graphviz-ce0fa82903fbaa57303151b692d88cc2digraph G { subgraph cluster_cr0_host_guest_mask { cr0_host_guest_mask_bitmap [ shape=&quot;record&quot; label=&quot;&lt;0&gt;0|&lt;1&gt;0|&lt;2&gt;0|&lt;3&gt;1&quot; ] label=&quot;cr0 host/guest mask&quot; } subgraph cluster_source_value { source_value [ shape=&quot;record&quot; label=&quot;&lt;0&gt;1|&lt;1&gt;0|&lt;2&gt;1|&lt;3&gt;0&quot; ] label=&quot;source value&quot; } subgraph cluster_beg_write_cr0 { cr0_beg_w [ shape=&quot;record&quot; label=&quot;&lt;0&gt;x|&lt;1&gt;x|&lt;2&gt;x|&lt;3&gt;x&quot; ] label=&quot;cr0 beg write&quot; } subgraph cluster_end_write_cr0 { cr0_end_w [ shape=&quot;record&quot; label=&quot;&lt;0&gt;1|&lt;1&gt;0|&lt;2&gt;1|&lt;3&gt;x&quot; ] label=&quot;cr0 : end write&quot; } cr0_host_guest_mask_bitmap:0-&gt;source_value:0 cr0_host_guest_mask_bitmap:1-&gt;source_value:1 cr0_host_guest_mask_bitmap:2-&gt;source_value:2 [ label=&quot;indicate write direct cr0 bit&quot; ] source_value:0-&gt;cr0_beg_w:0 source_value:1-&gt;cr0_beg_w:1 source_value:2-&gt;cr0_beg_w:2 [ label=&quot;write&quot; ] cr0_beg_w:0-&gt;cr0_end_w:0 cr0_beg_w:1-&gt;cr0_end_w:1 cr0_beg_w:2-&gt;cr0_end_w:2 [ label=&quot;write success&quot; ]}Gcluster_cr0_host_guest_maskcr0 host/guest maskcluster_source_valuesource valuecluster_beg_write_cr0cr0 beg writecluster_end_write_cr0cr0 : end writecr0_host_guest_mask_bitmap0001source_value1010cr0_host_guest_mask_bitmap:0&#45;&gt;source_value:0cr0_host_guest_mask_bitmap:1&#45;&gt;source_value:1cr0_host_guest_mask_bitmap:2&#45;&gt;source_value:2indicate write direct cr0 bitcr0_beg_wxxxxsource_value:0&#45;&gt;cr0_beg_w:0source_value:1&#45;&gt;cr0_beg_w:1source_value:2&#45;&gt;cr0_beg_w:2writecr0_end_w101xcr0_beg_w:0&#45;&gt;cr0_end_w:0cr0_beg_w:1&#45;&gt;cr0_end_w:1cr0_beg_w:2&#45;&gt;cr0_end_w:2write success 上面是 MOV from CR0的大概流程 这里需要注意的是, cr0 host/guest mask能决定的是 MOV from CR0 的这些bit 从哪个地方获取: CR0 CR0 read shadow MOV to CR0, 要不要VM exit. 如果修改了 cr0 host/guest mask中bit对应的 read shadow, 是一定要vm exit. 当然 在 VMX OPERATION中CR0还有一些限制, 不满足这些限制也会VM exit. 这里需要思考下 Q: 为什么要这样设计? A: 为的就是对CR0 的某些bit进行软件(hypervisor)上的虚拟化. Q: 怎么控制虚拟化哪些呢? A: 虚拟化 cr0 host/guest mask为1 的bit. read from read shadow write cause VM-exit other bit normal read/write to CR0 " }, { "title": "protected-mode memory management", "url": "/posts/proctected-mode/", "categories": "intel_sdm", "tags": "virt", "date": "2024-04-23 11:00:00 +0800", "snippet": " FROM intel sdm CHAPTER 3 PROTECTED-MODE MEMORY MANAGEMENTabstractThis chapter describes the Intel 64 and IA-32 architecture’s protected-modememory management facilities, including the physical m...", "content": " FROM intel sdm CHAPTER 3 PROTECTED-MODE MEMORY MANAGEMENTabstractThis chapter describes the Intel 64 and IA-32 architecture’s protected-modememory management facilities, including the physical memory requirements,segmentation mechanism, and paging mechanism. 本章介绍 Intel 64 和 IA-32 架构的保护模式内存管理 facilities ，包括物理内存要求、分段机制和分页机制。See also: Chapter 5, “Protection” (for a description of the processor’sprotection mechanism) and Chapter 21, “8086 Emulation” (for a description ofmemory addressing protection in real-address and virtual-8086 modes). 另请参见：第 5 章“保护”（有关处理器保护机制的说明）和第 21 章“8086 仿真”（有关实地址和虚拟 8086 模式下的内存寻址保护的说明）。3.1 MEMORY MANAGEMENT OVERVIEWThe memory management facilities of the IA-32 architecture are divided into twoparts: segmentation and paging. Segmentation provides a mechanism of isolatingindividual code, data, and stack modules so that multiple programs (or tasks)can run on the same processor without interfering with one another. Pagingprovides a mechanism for implementing a conventional demand-paged,virtual-memory system where sections of a program’s execution environment aremapped into physical memory as needed. Paging can also be used to provideisolation between multiple tasks. When operating in protected mode, some formof segmentation must be used. There is no mode bit to disable segmentation. Theuse of paging, however, is optional. conventional [kənˈvenʃənl] : 常规的; 传统的; 习惯的;demand [dɪˈmænd] : 需要, 要求 IA-32架构的内存管理 facilities 分为两部分：分段和分页。 分段提供了一种隔离各个代码、数据和堆栈模块的机制，以便多个程序（或任务）可以在同一处理器上运行而不会相互干扰。 分页提供了一种实现传统的按需分页虚拟内存系统的机制，其中程序执行环境的各个部分根据需要映射到物理内存中。 分页还可用于提供多个任务之间的隔离。 当在保护模式下运行时，必须使用某种形式的分段。 没有mode bit可以禁用分段。 然而，分页的使用是可选的。These two mechanisms (segmentation and paging) can be configured to supportsimple single-program (or single-task) systems, multitasking systems, ormultiple-processor systems that used shared memory. As shown in Figure 3-1,segmentation provides a mechanism for dividing the processor’s addressablememory space (called the linear address space) into smaller protected addressspaces called segments. Segments can be used to hold the code, data, and stackfor a program or to hold system data structures (such as a TSS or LDT). If morethan one program (or task) is running on a processor, each program can beassigned its own set of segments. The processor then enforces the boundariesbetween these segments and ensures that one program does not interfere with theexecution of another program by writing into the other program’s segments. Thesegmentation mechanism also allows typing of segments so that the operationsthat may be performed on a particular type of segment can be restricted. 这两种机制（分段和分页）可配置为支持简单的单程序（或单任务）系统、多任务系统或多处理器系统（使用共享内存）。 如图 3-1 所示，分段提供了一种将处理器的可寻址内存空间（称为线性地址空间）划分为更小的受保护地址空间（称为段）的机制。 段可用于保存程序的代码、数据和堆栈，或保存系统数据结构（例如 TSS或 LDT）。如果处理器上运行多个程序（或任务），则可以为每个程序分配其自己的一组段。 然后，处理器enforces(强制执行)这些段之间的边界，并确保一个程序不会通过写入另一个程序的段来干扰另一个程序的执行。 分段机制还允许对段进行类型化，以便可以限制对特定类型的段执行的操作。All the segments in a system are contained in the processor’s linear addressspace. To locate a byte in a particular segment, a logical address (also calleda far pointer) must be provided. A logical address consists of a segmentselector and an offset. The segment selector is a unique identifier for asegment. Among other things it provides an offset into a descriptor table (suchas the global descriptor table, GDT) to a data structure called a segmentdescriptor. Each segment has a segment descriptor, which specifies the size ofthe segment, the access rights and privilege level for the segment, the segmenttype, and the location of the first byte of the segment in the linear addressspace (called the base address of the segment). The offset part of the logicaladdress is added to the base address for the segment to locate a byte withinthe segment. The base address plus the offset thus forms a linear address inthe processor’s linear address space. among other things: 除此之外 系统中的所有段都包含在处理器的线性地址空间中。 要在特定段中定位字节，必须提供逻辑地址（也称为far pointer）。 逻辑地址由段选择器和偏移量组成。 段选择器是段的唯一标识符。 除此之外，它还提供描述符表（例如全局描述符表，GDT）到一个被称为段描述符的数据结构的偏移量(某个entry, 实际上就是在GDT中的偏移)。 每个段都有一个段描述符，它指定了段的大小、段的访问权限和特权级别、段类型以及该段的第一个字节在线性地址空间中的位置（称为段的基地址)。 逻辑地址的偏移部分被添加到段的基地址上来locate段内的某个byte。 因此，基地址加上偏移量就形成了处理器线性地址空间中的线性地址。If paging is not used, the linear address space of the processor is mappeddirectly into the physical address space of processor. The physical addressspace is defined as the range of addresses that the processor can generate onits address bus. 如果不使用分页，则处理器的线性地址空间直接映射到处理器的物理地址空间。 物理地址空间定义为处理器可以在其地址总线上产生的地址范围。Because multitasking computing systems commonly define a linear address spacemuch larger than it is economically feasible to contain all at once inphysical memory, some method of “virtualizing” the linear address space isneeded. This virtualization of the linear address space is handled through theprocessor’s paging mechanism. economically [ˌiːkəˈnɒmɪkli]: 经济地; 在经济学上; 节约地; 节俭地; 节省地; 实惠地feasible [ˈfiːzəbl] : 可行的, 行的通的all at once : 同时;突然;忽然;一起 由于多任务计算系统通常定义的线性地址空间比在 physical memory 上同时包含所有地址在 economically 要更feasible(经济上更合适). 因此需要某种“virtualizing”线性地址空间的方法。 线性地址空间的虚拟化是通过处理器的分页机制来处理的。Paging supports a “virtual memory” environment where a large linear addressspace is simulated with a small amount of physical memory (RAM and ROM) andsome disk storage. When using paging, each segment is divided into pages(typically 4 KBytes each in size), which are stored either in physical memoryor on the disk. The operating system or executive maintains a page directoryand a set of page tables to keep track of the pages. When a program (or task)attempts to access an address location in the linear address space, theprocessor uses the page directory and page tables to translate the linearaddress into a physical address and then performs the requested operation (reador write) on the memory location. 分页支持“虚拟内存”环境，在该环境上使用少量物理内存（RAM 和 ROM）和一些磁盘存储来模拟大型线性地址空间。使用分页时，每个段被分为一些pages（通常每个大小为 4 KB），这些页存储在物理内存或磁盘上。操作系统或执行程序维护一个页目录和一组页表来track页面。当程序（或任务）尝试访问线性地址空间中的地址位置时，处理器使用页目录和页表将线性地址转换为物理地址，然后在该内存位置上执行请求的操作（读或写)。If the page being accessed is not currently in physical memory, the processorinterrupts execution of the program (by generating a page-fault exception). Theoperating system or executive then reads the page into physical memory from thedisk and continues executing the program. 如果正在访问的页面当前不在物理内存中，则处理器会中断程序的执行（通过生成page-fault异常）。然后操作系统或执行程序将页面内容从磁盘读入物理内存并继续执行程序.When paging is implemented properly in the operating-system or executive, theswapping of pages between physical memory and the disk is transparent to thecorrect execution of a program. Even programs written for 16-bit IA-32processors can be paged (transparently) when they are run in virtual-8086 mode. 当操作系统或执行程序中正确实现分页时，物理内存和磁盘之间的页面交换对于程序的正确执行是透明的。 即使是为 16 位 IA-32 处理器编写的程序在virtual-8086 模式下运行时也可以进行分页（透明地）。3.2 USING SEGMENTSThe segmentation mechanism supported by the IA-32 architecture can be used toimplement a wide variety of system designs. These designs range from flatmodels that make only minimal use of segmentation to protect programs tomulti-segmented models that employ segmentation to create a robust operatingenvironment in which multiple programs and tasks can be executed reliably. robust [roʊˈbʌst]: 强健的; 坚固的 A-32架构支持的分段机制可用于实现多种系统设计。 这些设计的范围从仅使用最少的分段来保护程序的平面模型到使用分段来创建可以可靠地执行多个程序和任务的强健的操作环境的多分段模型。The following sections give several examples of how segmentation can beemployed in a system to improve memory management performance and reliability. 以下部分给出了几个示例，说明如何在系统中使用分段来提高内存管理性能和可靠性。3.2.1 Basic Flat ModelThe simplest memory model for a system is the basic “flat model,” in which theoperating system and application programs have access to a continuous,unsegmented address space. To the greatest extent possible, this basic flatmodel hides the segmentation mechanism of the architecture from both the systemdesigner and the application programmer. continuous [kənˈtɪnjuəs] : 连续的,持续的,不断的extent [ɪkˈstent] : 程度greatest extent possible: 最大程度的 系统最简单的内存模型是基本的“平面模型”，在该模型中，操作系统和应用程序可以访问连续的、未分段的地址空间。在最大程度上，这个基本的平面模型向系统设计者和应用程序程序员隐藏了体系结构的segmentation 机制。To implement a basic flat memory model with the IA-32 architecture, at leasttwo segment descriptors must be created, one for referencing a code segment andone for referencing a data segment (see Figure 3-2). Both of these segments,however, are mapped to the entire linear address space: that is, both segmentdescriptors have the same base address value of 0 and the same segment limit of4 GBytes. By setting the segment limit to 4 GBytes, the segmentation mechanismis kept from generating exceptions for out of limit memory references, even ifno physical memory resides at a particular address. ROM (EPROM) is generallylocated at the top of the physical address space, because the processor beginsexecution at FFFF_FFF0H. RAM (DRAM) is placed at the bottom of the addressspace because the initial base address for the DS data segment after resetinitialization is 0. keep from: 阻止,避免, 免于reside: 驻留 要使用 IA-32 架构实现基本平面内存模型，必须至少创建两个段描述符，一个用于引用代码段，另一个用于引用数据段（见图 3-2）。 然而，这两个段都映射到整个线性地址空间：也就是说，两个段描述符具有相同的基地址值 0 和相同的 4 GB 段限制。 通过将段限制设置为 4 GB，即使特定地址没有物理内存reside，分段机制也不会因超出限制的内存引用而生成异常。 ROM（EPROM）一般位于物理地址空间的顶部，因为处理器从FFFF_FFF0H开始执行。 RAM（DRAM）被放置在地址空间的底部，因为复位初始化后DS数据段的初始基地址为0。3.2.2 Protected Flat ModelThe protected flat model is similar to the basic flat model, except the segmentlimits are set to include only the range of addresses for which physical memoryactually exists (see Figure 3-3). A general-protection exception (#GP) is thengenerated on any attempt to access nonexistent memory. This model provides aminimum level of hardware protection against some kinds of program bugs. 受保护的平面模型与基本平面模型相似，只是段限制设置为仅包括物理内存实际存在的地址范围（见图3-3）。然后，在任何访问不存在的内存的尝试中都会生成一个通用保护异常（#GP）。该模型提供了针对某些程序错误的最低级别的硬件保护。More complexity can be added to this protected flat model to provide moreprotection. For example, for the paging mechanism to provide isolation betweenuser and supervisor code and data, four segments need to be defined: code anddata segments at privilege level 3 for the user, and code and data segments atprivilege level 0 for the supervisor. Usually these segments all overlay eachother and start at address 0 in the linear address space. This flatsegmentation model along with a simple paging structure can protect theoperating system from applications, and by adding a separate paging structurefor each task or process, it can also protect applications from each other.Similar designs are used by several popular multitasking operating systems. 这种受保护的平面模型可以增加更多的复杂性，以提供更多的保护。例如，对于在用户和supervisor 代码和数据之间提供隔离的分页机制，需要定义四个段：用户权限级别为3的代码和数据段，supervisor 权限级别为0的代码和资料段。通常，这些段都相互重叠，并从线性地址空间中的地址0开始。这种扁平的分段模型和简单的分页结构可以保护操作系统不受应用程序的影响，并且通过为每个任务或进程添加单独的分页结构，它还可以保护应用程序不受彼此的影响。几种流行的多任务操作系统也使用了类似的设计。 这块我持怀疑态度, 如果 offset, base 都设置成一样的, 那么该保护就不是使用 segment来保护的, 实际上还是使用的paging 但是实际上Linux kernel还真是这么做的, 还需要仔细思考下3.2.3 Multi-Segment ModelA multi-segment model (such as the one shown in Figure 3-4) uses the fullcapabilities of the segmentation mechanism to provide hardware enforcedprotection of code, data structures, and programs and tasks. Here, each program(or task) is given its own table of segment descriptors and its own segments.The segments can be completely private to their assigned programs or sharedamong programs. Access to all segments and to the execution environments ofindividual programs running on the system is controlled by hardware. 多段模型（如图 3-4 所示）使用分段机制的全部功能来提供对代码、数据结构以及程序和任务的硬件强制保护。 这里，每个程序（或任务）都有自己的段描述符表和自己的段。 这些段对于其分配的程序来说可以是完全私有的，也可以在程序之间共享。对系统上运行的各个程序的所有段和执行环境的访问均由硬件控制。Access checks can be used to protect not only against referencing an addressoutside the limit of a segment, but also against performing disallowedoperations in certain segments. For example, since code segments are desig-nated as read-only segments, hardware can be used to prevent writes into codesegments. The access rights information created for segments can also be usedto set up protection rings or levels. Protection levels can be used to protectoperating-system procedures from unauthorized access by application programs. 访问检查不仅可以用于防止引用段限制之外的地址，还可以防止在某些段中执行不允许的操作。 例如，由于代码段被指定为只读段，因此硬件可以使用其来防止写入代码段。 为段创建的访问权限信息也可用于设置protection rings 或levels。 protection levels可用于保护操作系统过程免遭应用程序未经授权的访问。3.2.4 Segmentation in IA-32e ModeIn IA-32e mode of Intel 64 architecture, the effects of segmentation depend onwhether the processor is running in compatibility mode or 64-bit mode. Incompatibility mode, segmentation functions just as it does using legacy 16-bitor 32-bit protected mode semantics. compatibility [kəmˌpætəˈbɪləti] : 兼容性 在Intel 64架构的IA-32e模式下，分段的效果取决于处理器是运行在兼容模式还是64位模式。 在兼容模式下，分段功能就像使用传统 16 位或 32 位保护模式semantics一样。In 64-bit mode, segmentation is generally (but not completely) disabled,creating a flat 64-bit linear-address space. The processor treats the segmentbase of CS, DS, ES, SS as zero, creating a linear address that is equal to theeffective address. The FS and GS segments are exceptions. These segmentregisters (which hold the segment base) can be used as additional baseregisters in linear address calculations. They facilitate addressing local dataand certain operating system data structures. 在 64 位模式下，通常（但不是完全）禁用分段，从而创建平坦的 64 位线性地址空间。处理器将 CS、DS、ES、SS 的段基数视为零，从而创建等于有效地址的线性地址。 FS 和 GS 段是例外。 这些段寄存器（保存段基址）可以用作线性地址计算中的附加基址寄存器。 它们有助于寻址本地数据和某些操作系统数据结构Note that the processor does not perform segment limit checks at runtime in64-bit mode. 请注意，处理器在64位模式下运行时不执行段限制检查。3.2.5 Paging and SegmentationPaging can be used with any of the segmentation models described in Figures3-2, 3-3, and 3-4. The processor’s paging mechanism divides the linear addressspace (into which segments are mapped) into pages (as shown in Figure 3-1).These linear-address-space pages are then mapped to pages in the physicaladdress space. The paging mechanism offers several page-level protectionfacilities that can be used with or instead of the segment-protectionfacilities. For example, it lets read-write protection be enforced on apage-by-page basis. The paging mechanism also provides two-leveluser-supervisor protection that can also be specified on a page-by-page basis. 分页可以与图 3-2、3-3 和 3-4 中描述的任何分段模型一起使用。 处理器的分页机制将线性地址空间（段被映射到其中(线性地址空间)）划分为页（如图 3-1 所示）。 然后，这些线性地址空间页被映射到物理地址空间中的页。 分页机制提供了多种页级保护设施，可以与段保护设施一起使用或代替段保护设施。 例如，它允许page-by-page页强制执行读写保护。 分页机制还提供两级 user-supervisor 保护，也可以page-by-page 指定。3.3 PHYSICAL ADDRESS SPACEIn protected mode, the IA-32 architecture provides a normal physical addressspace of 4 GBytes (232 bytes). This is the address space that the processor canaddress on its address bus. This address space is flat (unsegmented), withaddresses ranging continuously from 0 to FFFFFFFFH. This physical address spacecan be mapped to read-write memory, read-only memory, and memory mapped I/O.The memory mapping facilities described in this chapter can be used to dividethis physical memory up into segments and/or pages. 在保护模式下，IA-32 架构提供 4 GB（232 字节）的 normal 物理地址空间。 这是处理器可以在其地址总线上寻址的地址空间。 该地址空间是平坦的（未分段），地址范围从0 到 FFFFFFFFH 连续。 该物理地址空间可以映射到读写memory、只读memory和 mmeory mappedI/O(mmio)。 本章中描述的内存映射 facilities 可用于将该物理内存划分为段和/或页。Starting with the Pentium Pro processor, the IA-32 architecture also supportsan extension of the physical address space to 236 bytes (64 GBytes); with amaximum physical address of FFFFFFFFFH. This extension is invoked in either oftwo ways: 从奔腾Pro处理器开始，IA-32体系结构还支持将物理地址空间扩展到236字节（64GB）;最大物理地址为FFFFFFFFFH。此扩展可通过以下两种方式之一 invoke(引入)： Using the physical address extension (PAE) flag, located in bit 5 of controlregister CR4. 使用位于 CR4 [bit 5] 的 PAE flag Using the 36-bit page size extension (PSE-36) feature (introduced in thePentium III processors). 使用 PSE-36 feature (在奔腾 3 处理器引入) Physical address support has since been extended beyond 36 bits. See Chapter 4,“Paging” for more information about 36-bit physical addressing. 此后，物理地址支持已扩展到 36 位以上。 有关 36 位物理寻址的更多信息，请参见第 4 章“分页”。Intel® 64 Processors and Physical Address SpaceOn processors that support Intel 64 architecture (CPUID.80000001H:EDX[29] = 1),the size of the physical address range is implementation-specific and indicatedby CPUID.80000008H:EAX[bits 7-0]. 在支持 Intel 64 架构 (CPUID.80000001H:EDX[29] = 1) 的处理器上，物理地址范围的大小是 implementation-specific，并由 CPUID.80000008H:EAX[位 7-0] 指示。For the format of information returned in EAX, see “CPUID—CPU Identification”in Chapter 3 of the Intel® 64 and IA-32 Architectures Software Developer’sManual, Volume 2A. See also: Chapter 4, “Paging.” 有关 EAX 中返回信息的格式，intel sdm CPUID 指令介绍和 chapter 4 Paging 章节3.4 LOGICAL AND LINEAR ADDRESSESAt the system-architecture level in protected mode, the processor uses twostages of address translation to arrive at a physical address: logical-addresstranslation and linear address space paging. 在保护模式下的system-architecture level，处理器使用两个阶段的地址转换来获得物理地址：逻辑地址转换和线性地址空间分页。Even with the minimum use of segments, every byte in the processor’s addressspace is accessed with a logical address. A logical address consists of a16-bit segment selector and a 32-bit offset (see Figure 3-5). The segmentselector identifies the segment the byte is located in and the offset specifiesthe location of the byte in the segment relative to the base address of thesegment. 即使使用最少的段，处理器地址空间中的每个字节也可以通过逻辑地址进行访问。 逻辑地址由 16 位段选择器和 32 位偏移量组成（见图 3-5）。 段选择器标识该字节所在的段，偏移量指定字节在段中相对于段基地址的位置。The processor translates every logical address into a linear address. A linearaddress is a 32-bit address in the processor’s linear address space. Like thephysical address space, the linear address space is a flat (unsegmented),232-byte address space, with addresses ranging from 0 to FFFFFFFFH.The linear address space contains all the segments and system tables definedfor a system. 处理器将每个逻辑地址转换为线性地址。 线性地址是处理器线性地址空间中的 32 位地址。与物理地址空间一样，线性地址空间是平坦（不分段）的 2^32 字节地址空间，地址范围从0 到 FFFFFFFFH。 线性地址空间包含为系统定义的所有段和system table.To translate a logical address into a linear address, the processor does thefollowing: 为了将逻辑地址转换为线性地址，处理器执行以下操作： Uses the offset in the segment selector to locate the segment descriptor forthe segment in the GDT or LDT and reads it into the processor. (This step isneeded only when a new segment selector is loaded into a segment register.) 使用段选择器中的偏移量来定位 GDT 或 LDT 中该段的段描述符，并将其读入处理器.（只有当新的段选择器加载到段寄存器中时才需要执行此步骤。） Examines the segment descriptor to check the access rights and range of thesegment to ensure that the segment is accessible and that the offset iswithin the limits of the segment. Examines [ɪɡˈzæmɪnz]: 检查; 审查; 检查段描述符以检查该段的access rights和range，以确保该段是 accessible并且偏移量在该段的限制内。 Adds the base address of the segment from the segment descriptor to theoffset to form a linear address. 将段描述符中的段基地址与偏移量相加，形成线性地址。 If paging is not used, the processor maps the linear address directly to aphysical address (that is, the linear address goes out on the processor’saddress bus). If the linear address space is paged, a second level of addresstranslation is used to translate the linear address into a physical address. 如果不使用分页，处理器会将线性地址直接映射到物理地址（即，线性地址则输出在处理器地址总线上）。 如果线性地址空间被分页，则使用第二级地址转换来将线性地址转换为物理地址。See also: Chapter 4, “Paging.”3.4.1 Logical Address Translation in IA-32e ModeIn IA-32e mode, an Intel 64 processor uses the steps described above totranslate a logical address to a linear address. In 64-bit mode, the offset andbase address of the segment are 64-bits instead of 32 bits. The linear addressformat is also 64 bits wide and is subject to the canonical form requirement. be subject to :受支配，从属于; 有…倾向的 在 IA-32e 模式下，Intel 64 处理器使用上述步骤将逻辑地址转换为线性地址。 在64位模式下，段的偏移量和基地址都是64位而不是32位。 线性地址格式也是 64 位宽，并且符合规范形式要求。 之前调研AMD dma use-after-free的时候介绍过 Each code segment descriptor provides an L bit. This bit allows a code segmentto execute 64-bit code or legacy 32-bit code by code segment. 每个代码段描述符提供一个L位。 该位允许每个代码段指定执行 64 位代码或legacy 32 位代码。3.4.2 Segment SelectorsA segment selector is a 16-bit identifier for a segment (see Figure 3-6). Itdoes not point directly to the segment, but instead points to the segmentdescriptor that defines the segment. A segment selector contains the followingitems: 段选择器是段的 16 位标识符（见图 3-6）。 它并不直接指向段，而是指向定义该段的段描述符。 段选择器包含以下item: Index (Bits 3 through 15) Selects one of 8192 descriptors in the GDT or LDT. The processor multipliesthe index value by 8 (the number of bytes in a segment descriptor) and addsthe result to the base address of the GDT or LDT (from the GDTR or LDTRregister, respectively). 选择 GDT 或 LDT 中的 8192 个描述符之一。 处理器将索引值乘以 8（段描述符中的字节数），并将结果添加到 GDT 或 LDT 的基地址（分别来自 GDTR 或 LDTR 寄存器）。 TI (table indicator) flag (Bit 2) Specifies the descriptor table to use: clearing this flag selects the GDT;setting this flag selects the current LDT. 指定要使用的描述符表：清除该标志选择GDT； 设置此标志选择当前 LDT。 Requested Privilege Level (RPL) (Bits 0 and 1) Specifies the privilege level of the selector. The privilege level can rangefrom 0 to 3, with 0 being the most privileged level. See Section 5.5,“Privilege Levels,” for a description of the relationship of the RPL to theCPL of the executing program (or task) and the descriptor privilege level(DPL) of the descriptor the segment selector points to. 指定选择器的权限级别。 权限级别的范围为 0 到 3，其中 0 是最高权限级别。 请参阅第 5.5 节“Privilege levels”，了解 RPL 与执行程序（或任务）的 CPL 以及段选择器指向的描述符的描述符特权级别 (DPL) 之间的关系的描述。 The first entry of the GDT is not used by the processor. A segment selectorthat points to this entry of the GDT (that is, a segment selector with an indexof 0 and the TI flag set to 0) is used as a “null segment selector.” Theprocessor does not generate an exception when a segment register (other thanthe CS or SS registers) is loaded with a null selector. It does, however,generate an exception when a segment register holding a null selector is usedto access memory. A null selector can be used to initialize unused segmentregisters. Loading the CS or SS register with a null segment selector causes ageneral-protection exception (#GP) to be generated. initialize [ɪˈnɪʃəlaɪz] 处理器不使用 GDT 的第一个条目。 指向 GDT 的该条目的段选择器（即索引为 0 且 TI 标志设置为 0 的段选择器）被用作“null segment selector”。 当段寄存器（CS 或 SS 寄存器除外）加载了 null selector 时，处理器不会生成异常。 然而，当使用持有 null selector的段寄存器来访问内存时，它确实会生成异常。 null selector 可用于初始化未使用的段寄存器。 使用空段选择器加载 CS 或 SS 寄存器会导致生成一般保护异常 (#GP)。Segment selectors are visible to application programs as part of a pointervariable, but the values of selectors are usually assigned or modified by linkeditors or linking loaders, not application programs. 段选择器作为指针变量的一部分对应用程序可见，但选择器的值通常由link editors或ilinloader而不是应用程序分配或修改。3.4.3 Segment RegistersTo reduce address translation time and coding complexity, the processorprovides registers for holding up to 6 segment selectors (see Figure 3-7). Eachof these segment registers support a specific kind of memory reference (code,stack, or data). For virtually any kind of program execution to take place, atleast the code-segment (CS), data-segment (DS), and stack-segment (SS)registers must be loaded with valid segment selectors. The processor alsoprovides three additional data-segment registers (ES, FS, and GS), which can beused to make additional data segments available to the currently executingprogram (or task). 为了减少地址转换时间和编码复杂性，处理器提供了用于保存最多 6 个段选择器的寄存器（见图 3-7）。 每个段寄存器都支持特定类型的内存引用（代码、堆栈或数据）。 实际上，要执行任何类型的程序，至少必须向代码段 (CS)、数据段 (DS) 和堆栈段 (SS) 寄存器加载有效的段选择器。 该处理器还提供三个附加数据段寄存器（ES、FS 和 GS），可用于为当前正在执行的程序（或任务）提供附加数据段。For a program to access a segment, the segment selector for the segment musthave been loaded in one of the segment registers. So, although a system candefine thousands of segments, only 6 can be available for immediate use. Othersegments can be made available by loading their segment selectors into theseregisters during program execution. 对于要访问段的程序，该段的段选择器必须已加载到段寄存器之一中。 因此，尽管系统可以定义数千个段，但只有 6 个可以立即使用。 通过在程序执行期间将其段选择器加载到这些寄存器中，可以使其他段可用。Every segment register has a “visible” part and a “hidden” part. (The hiddenpart is sometimes referred to as a “descriptor cache” or a “shadow register.”)When a segment selector is loaded into the visible part of a segment register,the processor also loads the hidden part of the segment register with the baseaddress, segment limit, and access control information from the segmentdescriptor pointed to by the segment selector. The information cached in thesegment register (visible and hidden) allows the processor to translateaddresses without taking extra bus cycles to read the base address and limitfrom the segment descriptor. In systems in which multiple processors haveaccess to the same descriptor tables, it is the responsibility of software toreload the segment registers when the descriptor tables are modified. If thisis not done, an old segment descriptor cached in a segment register might beused after its memory-resident version has been modified. reside [rɪˈzaɪd] vi: 居住在; 定居于resident [ˈrezɪdənt] n: 居民; 住户; adj.(在某地)居住的 每个段寄存器都有一个“可见”部分和一个“隐藏”部分。 （隐藏部分有时称为“描述符缓存”或“影子寄存器”。）当将段选择器加载到段寄存器的可见部分时，处理器还会将段选择器的隐藏部分加载到段寄存器中。 段选择器指向的段描述符中的基地址、段限制和访问控制信息。 缓存在段寄存器（可见和隐藏）中的信息允许处理器转换地址，而无需花费额外的总线周期来从段描述符中读取基地址和限制。 在多个处理器可以访问相同描述符表的系统中，当描述符表被修改时，软件负责重新加载段寄存器。 如果不这样做，则在修改其 memory-resident version后，可能会使用缓存在段寄存器中的旧段描述符。Two kinds of load instructions are provided for loading the segment registers: 提供两种加载指令用于加载段寄存器： Direct load instructions such as the MOV, POP, LDS, LES, LSS, LGS, and LFSinstructions. These instructions explicitly reference the segment registers. 直接加载指令，例如 MOV、POP、LDS、LES、LSS、LGS 和 LFS 指令。 这些指令显式引用段寄存器。 Implied load instructions such as the far pointer versions of the CALL, JMP,and RET instructions, the SYSENTER and SYSEXIT instructions, and the IRET,INT n, INTO, INT3, and INT1 instructions. These instructions change thecontents of the CS register (and sometimes other segment registers) as anincidental part of their operation. incidental [ˌɪnsɪˈdentl] : 次要的; 附带发生的; 伴随而来的; 非有意的; 隐式加载指令，例如 CALL、JMP 和 RET 指令的far pointer version、SYSENTER 和 SYSEXIT 指令以及 IRET、INT n、INTO、INT3 和 INT1 指令。 这些指令更改CS 寄存器（有时还更改其他段寄存器）的内容，作为其操作的附带部分。 The MOV instruction can also be used to store the visible part of a segmentregister in a general-purpose register. MOV指令还可用于将段寄存器的可见部分 store 在通用寄存器中。3.4.4 Segment Loading Instructions in IA-32e ModeBecause ES, DS, and SS segment registers are not used in 64-bit mode, theirfields (base, limit, and attribute) in segment descriptor registers areignored. Some forms of segment load instructions are also invalid (for example,LDS, POP ES). Address calculations that reference the ES, DS, or SS segmentsare treated as if the segment base is zero. 由于 ES、DS 和 SS 段寄存器在 64 位模式下不使用，因此它们在段描述符寄存器中的字段（基址、限制和属性）将被忽略。 某些形式的段加载指令也是无效的（例如LDS、POP ES）。引用 ES、DS 或 SS 段的地址计算被视为段基址为零。The processor checks that all linear-address references are in canonical forminstead of performing limit checks. Mode switching does not change the contentsof the segment registers or the associated descriptor registers. Theseregisters are also not changed during 64-bit mode execution, unless explicitsegment loads are performed. 处理器检查所有线性地址引用是否采用规范形式，而不是执行limit check。 模式切换不会更改段寄存器或相关描述符寄存器的内容。 这些寄存器在 64 位模式执行期间也不会更改，除非执行显式段加载。In order to set up compatibility mode for an application, segment-loadinstructions (MOV to Sreg, POP Sreg) work normally in 64-bit mode. An entry isread from the system descriptor table (GDT or LDT) and is loaded in the hiddenportion of the segment register. The descriptor-register base, limit, andattribute fields are all loaded. However, the contents of the data and stacksegment selector and the descriptor registers are ignored. 为了为应用程序设置兼容模式，段加载指令（MOV 到 Sreg、POP Sreg）在 64 位模式下正常工作。 从系统描述符表（GDT 或 LDT）中读取一个条目，并将其加载到段寄存器的隐藏部分中。 描述符寄存器基址、限制和属性字段均已加载。 但是，数据和堆栈段选择器以及描述符寄存器的内容将被忽略。When FS and GS segment overrides are used in 64-bit mode, their respective baseaddresses are used in the linear address calculation: (FS or GS).base + index +displacement. FS.base and GS.base are then expanded to the full linear-addresssize supported by the implementation. The resulting effective addresscalculation can wrap across positive and negative addresses; the resultinglinear address must be canonical. displacement [dɪsˈpleɪsmənt] : 移位; 取代; 替代; 当在 64 位模式下使用 FS 和 GS 段 overrides(相当于指定特定的该段)时，它们各自的基地址用于线性地址计算：（FS 或 GS).base + index + displacement。 然后 FS.base 和 GS.base 扩展到implemention支持的完整线性地址大小。 由此产生的有效地址计算可以跨越 positive和 negative 地址； 生成的线性地址必须是规范的。In 64-bit mode, memory accesses using FS-segment and GS-segment overrides arenot checked for a runtime limit nor subjected to attribute-checking. Normalsegment loads (MOV to Sreg and POP Sreg) into FS and GS load a standard 32-bitbase value in the hidden portion of the segment register. The base address bitsabove the standard 32 bits are cleared to 0 to allow consistency forimplementations that use less than 64 bits. 在 64 位模式下，使用 FS 段和 GS 段覆盖的内存访问不会检查 runtime limit,也不会进行属性检查。 正常段加载（MOV 到 Sreg 和 POP Sreg）到 FS 中，GS 加载段寄存器隐藏部分中的标准 32 位基值。 标准 32 位以上的基地址位被清除为0，以保证使用少于 64 位的实现的一致性。The hidden descriptor register fields for FS.base and GS.base are physicallymapped to MSRs in order to load all address bits supported by a 64-bitimplementation. Software with CPL = 0 (privileged software) can load allsupported linear-address bits into FS.base or GS.base using WRMSR. Addresseswritten into the 64-bit FS.base and GS.base registers must be in canonicalform. A WRMSR instruction that attempts to write a non-canonical address tothose registers causes a #GP fault. FS.base 和 GS.base 的隐藏描述符寄存器字段物理映射到 MSR，以便加载 64 位实现支持的所有地址位。 CPL = 0 的软件（特权软件）可以使用 WRMSR 将所有支持的线性地址位加载到 FS.base 或 GS.base 中。 写入 64 位 FS.base 和 GS.base 寄存器的地址必须采用规范形式。 尝试将非规范地址写入这些寄存器的 WRMSR 指令会导致 #GP 错误。When in compatibility mode, FS and GS overrides operate as defined by 32-bitmode behavior regardless of the value loaded into the upper 32 linear-addressbits of the hidden descriptor register base field. Compatibility mode ignoresthe upper 32 bits when calculating an effective address. 在兼容模式下，FS 和 GS 覆盖按照 32 位模式行为定义进行操作，无论加载到隐藏描述符寄存器基字段的高 32 个线性地址位中的值如何。 兼容模式在计算有效地址时忽略高 32 位。A new 64-bit mode instruction, SWAPGS, can be used to load GS base. SWAPGSexchanges the kernel data structure pointer from the IA32_KERNEL_GS_BASE MSRwith the GS base register. The kernel can then use the GS prefix on normalmemory references to access the kernel data structures. An attempt to write anon-canonical value (using WRMSR) to the IA32_KERNEL_GS_BASE MSR causes a #GPfault. 新的 64 位模式指令 SWAPGS 可用于加载 GS 基址。 SWAPGS 将 IA32_KERNEL_GS_BASEMSR 中的内核数据结构指针与 GS 基址寄存器进行交换。 然后，内核可以在普通内存引用上使用 GS 前缀来访问内核数据结构。 尝试将非规范值（使用 WRMSR）写入 IA32_KERNEL_GS_BASE MSR 会导致 #GP 错误。3.4.5 Segment DescriptorsA segment descriptor is a data structure in a GDT or LDT that provides theprocessor with the size and location of a segment, as well as access controland status information. Segment descriptors are typically created by compilers,linkers, loaders, or the operating system or executive, but not applicationprograms. Figure 3-8 illustrates the general descriptor format for all typesof segment descriptors. 段描述符是 GDT 或 LDT 中的一种数据结构，它为处理器提供段的大小和位置，以及访问控制和状态信息。 段描述符通常由编译器、链接器、加载器或操作系统或executive创建，但不是应用程序。图 3-8 说明了所有类型的段描述符的通用描述符格式。The flags and fields in a segment descriptor are as follows: Segment limit field Specifies the size of the segment. The processor puts together the twosegment limit fields to form a 20-bit value. The processor interprets thesegment limit in one of two ways, depending on the setting of the G(granularity) flag: granularity [grænju'læriti]: 颗粒,粒度 指定段的大小。 处理器将两个段限制字段放在一起形成一个 20 位值。 处理器以两种方式之一解释段限制，具体取决于 G（粒度）标志的设置： If the granularity flag is clear, the segment size can range from 1 byte to1 MByte, in byte increments. 如果粒度标志被清除，则段大小的范围可以从 1 byte到 1 MByte，以byte为增量。 If the granularity flag is set, the segment size can range from 4 KBytes to4 GBytes, in 4-KByte increments. 如果设置了粒度标志，则段大小的范围可以从 4 KB 到 4 GB，以 4 KB 为增量。 The processor uses the segment limit in two different ways, depending onwhether the segment is an expand-up or an expand-down segment. See Section3.4.5.1, “Code- and Data-Segment Descriptor Types,” for more informationabout segment types. For expand-up segments, the offset in a logical addresscan range from 0 to the segment limit. Offsets greater than the segment limitgenerate general-protection exceptions (#GP, for all segments other than SS)or stack-fault exceptions (#SS for the SS segment). For expand-downsegments, the segment limit has the reverse function; the offset can rangefrom the segment limit plus 1 to FFFFFFFFH or FFFFH, depending on the settingof the B flag. Offsets less than or equal to the segment limit generategeneral-protection exceptions or stack-fault exceptions. Decreasing the valuein the segment limit field for an expand-down segment allocates new memoryat the bottom of the segment’s address space, rather than at the top. IA-32architecture stacks always grow downwards, making this mechanism convenientfor expandable stacks. 处理器以两种不同的方式使用段限制，具体取决于该段是expand-down段还是expand-up。 有关段类型的更多信息，请参见第 3.4.5.1 节“代码段和数据段描述符类型”。 对于expand-up段，逻辑地址中的偏移量范围可以从 0 到段限制。 大于段限制的偏移量会生成一般保护异常（#GP，对于除 SS 之外的所有段）或堆栈错误异常（#SS 对于 SS 段）。 对于expand-down段，段限制具有相反的功能； 偏移量的范围可以从段限制加 1 到 FFFFFFFFH 或 FFFFH，具体取决于B flag的设置。 小于或等于段限制的偏移量会生成一般保护异常或堆栈错误异常。 减小expand-down段的段限制字段中的值会在段地址空间的底部而不是顶部分配新内存。 IA-32架构堆栈总是向下增长，使得这种机制便于扩展堆栈。 Base address fields Defines the location of byte 0 of the segment within the 4-GByte linearaddress space. The processor puts together the three base address fields toform a single 32-bit value. Segment base addresses should be aligned to16-byte boundaries. Although 16-byte alignment is not required, thisalignment allows programs to maximize performance by aligning code and dataon 16-byte boundaries. maximize [ˈmæksɪmaɪz] :最大化;最大限度的利用;充分利用;使增大到最大限度 定义 4 GB 线性地址空间内段的字节 0 的位置。 处理器将三个基地址字段放在一起形成一个 32 位值。 段基地址应与 16 字节边界对齐。 尽管不需要 16 字节对齐，但这种对齐允许程序通过在 16 字节边界上对齐代码和数据来最大限度地提高性能。 Type field Indicates the segment or gate type and specifies the kinds of access that canbe made to the segment and the direction of growth. The interpretation ofthis field depends on whether the descriptor type flag specifies anapplication (code or data) descriptor or a system descriptor. The encoding ofthe type field is different for code, data, and system descriptors (seeFigure 5-1). See Section 3.4.5.1, “Code-and Data-Segment Descriptor Types,”for a description of how this field is used to specify code and data-segmenttypes. 指示段或门类型，并指定可以对段进行访问的类型和增长方向。 该字段的解释取决于描述符类型标志指定应用程序（代码或数据）描述符还是系统描述符。 代码、数据和系统描述符的类型字段的编码是不同的（见图 5-1）。 有关如何使用此字段来指定代码和数据段类型的说明，请参见第 3.4.5.1 节“代码段和数据段描述符类型”。 S (descriptor type) flag Specifies whether the segment descriptor is for a system segment (S flag isclear) or a code or data segment (S flag is set). 指定段描述符是用于系统段（S 标志清零）还是代码或数据段（S 标志设置）。 DPL (descriptor privilege level) field Specifies the privilege level of the segment. The privilege level can rangefrom 0 to 3, with 0 being the most privileged level. The DPL is used tocontrol access to the segment. See Section 5.5, “Privilege Levels,” for adescription of the relationship of the DPL to the CPL of the executing codesegment and the RPL of a segment selector. 指定段的权限级别。 权限级别的范围为 0 到 3，其中 0 是最高权限级别。 DPL 用于控制对段的访问。 有关 DPL 与执行代码段的 CPL 和段选择器的 RPL 之间关系的描述，请参见第 5.5 节“特权级别”。 P (segment-present) flag Indicates whether the segment is present in memory (set) or not present(clear). If this flag is clear, the processor generates a segment-not-presentexception (#NP) when a segment selector that points to the segment descriptoris loaded into a segment register. Memory management software can use thisflag to control which segments are actually loaded into physical memory at agiven time. It offers a control in addition to paging for managing virtualmemory. Figure 3-9 shows the format of a segment descriptor when thesegment-present flag is clear. When this flag is clear, the operating systemor executive is free to use the locations marked “Available” to store its owndata, such as information regarding the whereabouts of the missing segment. regard [rɪˈɡɑːrd] : 将...认为;看待;注意;关注;尊重regarding: prep. 关于；至于; v. 把...视为;看待whereabout: 下落,行踪 指示该段是否存在于内存中（设置）或不存在（clear）。 如果清除该标志，则当指向段描述符的段选择器加载到段寄存器中时，处理器会生成 segment-not-presentexception (#NP)。 内存管理软件可以使用此标志来控制在给定时间哪些段实际加载到物理内存中。 除了分页之外，它还提供了用于管理虚拟内存的控制。 图 3-9显示了当段存在标志清零时段描述符的格式。 当该标志被清除时，操作系统或执行程序可以自由地使用标记为“可用”的位置来存储其自己的数据，例如有关missing segment的下落的信息。 D/B (default operation size/default stack pointer size and/or upper bound) flag Performs different functions depending on whether the segment descriptor isan executable code segment, an expand-down data segment, or a stack segment.(This flag should always be set to 1 for 32-bit code and data segments and to0 for 16-bit code and data segments.) 根据段描述符是可执行代码段、向下扩展数据段还是堆栈段来执行不同的功能。 （对于 32 位代码和数据段，该标志应始终设置为 1；对于 16 位代码和数据段，该标志应始终设置为 0。） Executable code segment. The flag is called the D flag and it indicates the default length foreffective addresses and operands referenced by instructions in the segment.If the flag is set, 32-bit addresses and 32-bit or 8-bit operands areassumed; if it is clear, 16-bit addresses and 16-bit or 8-bit operands areassumed. 该标志称为 D 标志，它指示段中指令引用的有效地址和操作数的默认长度。 如果设置了该标志，则假定为 32 位地址和 32 位或 8 位操作数； 如果清除，则假定为 16 位地址和 16 位或 8 位操作数。 The instruction prefix 66H can be used to select an operand size other thanthe default, and the prefix 67H can be used select an address size otherthan the default. 指令前缀66H可用于选择默认值以外的操作数大小，并且前缀67H可用于选择默认值以外的地址大小。 Stack segment (data segment pointed to by the SS register). The flag is called the B (big) flag and it specifies the size of the stackpointer used for implicit stack operations (such as pushes, pops, andcalls). If the flag is set, a 32-bit stack pointer is used, which is storedin the 32-bit ESP register; if the flag is clear, a 16-bit stack pointer isused, which is stored in the 16-bit SP register. If the stack segment isset up to be an expand-down data segment (described in the next paragraph),the B flag also specifies the upper bound of the stack segment. 该标志称为 B（big）标志，它指定用于隐式堆栈操作（例如压入、弹出和调用）的堆栈指针的大小。 如果该标志被设置，则使用32位堆栈指针，该指针存储在32位ESP寄存器中； 如果标志清零，则使用 16 位堆栈指针，该指针存储在 16 位 SP 寄存器中。 如果堆栈段设置为向下扩展数据段（在下一段中描述），则 B 标志还指定堆栈段的上限。 Expand-down data segment. The flag is called the B flag and it specifies the upper bound of thesegment. If the flag is set, the upper bound is FFFFFFFFH (4 GBytes); ifthe flag is clear, the upper bound is FFFFH (64 KBytes). 该标志称为 B 标志，它指定段的上限。 如果设置了该标志，则上限为 FFFFFFFFH (4 GBytes)； 如果该标志被清除，则上限为 FFFFH (64 KB)。 G (granularity) flag Determines the scaling of the segment limit field. When the granularity flagis clear, the segment limit is interpreted in byte units; when flag is set,the segment limit is interpreted in 4-KByte units. (This flag does not affectthe granularity of the base address; it is always byte granular.) When thegranularity flag is set, the twelve least significant bits of an offset arenot tested when checking the offset against the segment limit. For example,when the granularity flag is set, a limit of 0 results in valid offsets from0 to 4095. 确定段限制字段的scaling(缩放比例)。 当粒度标志清除时，段限制以byte为单位解释；当设置标志时，段限制以 4 KB 为单位进行解释。 （此标志不会影响基地址的粒度；它始终是字节粒度的。）设置粒度标志后，在根据段限制检查偏移量时，不会测试偏移量的 12 个最低有效位。 例如，当设置粒度标志时，限制为 [0, 4095] 的有效偏移量。 L (64-bit code segment) flag In IA-32e mode, bit 21 of the second doubleword of the segment descriptorindicates whether a code segment contains native 64-bit code. A value of 1indicates instructions in this code segment are executed in 64-bit mode. Avalue of 0 indicates the instructions in this code segment are executed incompatibility mode. If L-bit is set, then D-bit must be cleared. When not inIA-32e mode or for non-code segments, bit 21 is reserved and should always beset to 0. 在 IA-32e 模式中，段描述符的第二个双字的位 21 指示代码段是否包含native 64 位代码。 值为 1 表示该代码段中的指令以 64 位模式执行。 值为 0 表示该代码段中的指令以兼容模式执行。 如果设置了 L 位，则必须清除 D 位。 当不在 IA-32e 模式下或对于非代码段时，位 21 被保留并且应始终设置为 0。 Available and reserved bits Bit 20 of the second doubleword of the segment descriptor is available foruse by system software. 段描述符的第二个双字的位 20 可供系统软件使用。 3.4.5.1 Code-and Data-Segment Descriptor TypesWhen the S (descriptor type) flag in a segment descriptor is set, thedescriptor is for either a code or a data segment. The highest order bit of thetype field (bit 11 of the second double word of the segment descriptor) thendetermines whether the descriptor is for a data segment (clear) or a codesegment (set). 当段描述符中的 S（描述符类型）标志被设置时，该描述符用于代码段或数据段。然后，类型字段的最高位（段描述符的第二个双字的位 11）确定描述符是用于数据段（清除）还是代码段（设置）。For data segments, the three low-order bits of the type field (bits 8, 9, and10) are interpreted as accessed (A), write-enable (W), and expansion-direction(E). See Table 3-1 for a description of the encoding of the bits in the typefield for code and data segments. Data segments can be read-only or read/writesegments, depending on the setting of the write-enable bit. 对于数据段，类型字段的三个低位（位 8、9 和 10）被解释为已访问 (A)、可写 (W)和扩展方向 (E)。 有关代码段和数据段类型字段中位编码的说明，请参见表 3-1。 数据段可以是只读段或读/写段，具体取决于write-enable bit的设置。Stack segments are data segments which must be read/write segments. Loading theSS register with a segment selector for a nonwritable data segment generates ageneral-protection exception (#GP). If the size of a stack segment needs to bechanged dynamically, the stack segment can be an expand-down data segment(expansion-direction flag set). Here, dynamically changing the segment limitcauses stack space to be added to the bottom of the stack. If the size of astack segment is intended to remain static, the stack segment may be either anexpand-up or expand-down type. 堆栈段是数据段，必须是读/写段。使用不可写数据段的段选择器加载 SS 寄存器会生成一般保护异常 (#GP)。 如果堆栈段的大小需要动态改变，则堆栈段可以是expand-donw的数据段（扩展方向标志设置）。 在这里，动态更改段限制会导致堆栈空间添加到堆栈底部。如果堆栈段的大小旨在保持static，则堆栈段可以是向上扩展类型或向下扩展类型。The accessed bit indicates whether the segment has been accessed since the lasttime the operating-system or executive cleared the bit. The processor sets thisbit whenever it loads a segment selector for the segment into a segmentregister, assuming that the type of memory that contains the segment descriptorsupports processor writes. The bit remains set until explicitly cleared. Thisbit can be used both for virtual memory management and for debugging. explicitly /ɪkˈsplɪsətli/: 明确的,显示的 已访问位指示自上次操作系统或执行程序清除该位以来该段是否已被访问过。 每当处理器将段的段选择器加载到段寄存器中时，假设包含段描述符的内存类型支持处理器写入，处理器就会设置该位。 该位保持设置状态，直到显示的清除为止。该位可用于虚拟内存管理和调试。For code segments, the three low-order bits of the type field are interpretedas accessed (A), read enable (R), and conforming (C). Code segments can beexecute-only or execute/read, depending on the setting of the read-enable bit.An execute/read segment might be used when constants or other static data havebeen placed with instruction code in a ROM. Here, data can be read from thecode segment either by using an instruction with a CS override prefix or byloading a segment selector for the code segment in a data-segment register (theDS, ES, FS, or GS registers). In protected mode, code segments are notwritable. 对于代码段，类型字段的三个低位被解释为已访问 (A)、read enable (R) 和conforming (C)。 代码段可以是只执行的，也可以是执行/读取的，具体取决于read-enable bit的设置。 当常量或其他静态数据与指令代码一起放置在 ROM 中时，可能会使用执行/读取段。 这里，可以通过使用带有 CS 覆盖前缀的指令或通过在数据段寄存器（DS、ES、FS 或 GS 寄存器）中加载代码段的段选择器来从代码段读取数据。在保护模式下，代码段不可写。Code segments can be either conforming or nonconforming. A transfer ofexecution into a more-privileged conforming segment allows execution tocontinue at the current privilege level. A transfer into a nonconformingsegment at a different privilege level results in a general-protectionexception (#GP), unless a call gate or task gate is used (see Section 5.8.1,“Direct Calls or Jumps to Code Segments,” for more information on conformingand nonconforming code segments). System utilities that do not access protectedfacilities and handlers for some types of exceptions (such as, divide error oroverflow) may be loaded in conforming code segments. Utilities that need to beprotected from less privileged programs and procedures should be placed innonconforming code segments. 代码段可以是conforming，也可以是 nonconforming。 将执行转移到特权更高的 conformingsegment 允许执行在当前特权级别上continue。 除非使用call-gate或task-gate，否则以不同权限级别传输到nonconforming段会导致一般保护异常 (#GP)（请参阅第 5.8.1 节“直接调用或跳转到代码段”有关conforming和nonconforming代码段的更多信息）。 不访问受保护facilities和某些类型异常（例如除法错误或溢出）处理程序的system utilities 可以加载到 conforming 代码段中。需要保护其不受特权较低的程序和procedure 影响的utilities 应放置在 nonconforming的代码段中。 ??? 难道某些异常handler所在的Trap Gate的Segment selector, 要指定为 conforming 代码段?? 看下面描述是的 NOTE Execution cannot be transferred by a call or a jump to a less-privileged(numerically higher privilege level) code segment, regardless of whether thetarget segment is a conforming or nonconforming code segment. Attempting suchan execution transfer will result in a general-protection exception. numerically [nuˈmɛrɪkli]: 数字上的 无论目标段是conforming代码段还是nonconforming代码段，都不能通过调用或跳转将执行转移到特权较低（数字上特权级别较高）的代码段。 尝试这样的执行转移将导致一般保护异常。 All data segments are nonconforming, meaning that they cannot be accessed byless privileged programs or procedures (code executing at numerically higherprivilege levels). Unlike code segments, however, data segments can be accessedby more privileged programs or procedures (code executing at numerically lowerprivilege levels) without using a special access gate. 所有数据段都是nonconforming的，这意味着它们不能被特权较低的程序或procedure（在数字上较高特权级别执行的代码）访问。 然而，与代码段不同的是，数据段可以由更高特权的程序或过程（在数字上较低特权级别执行的代码）访问，而无需使用特殊的访问门。If the segment descriptors in the GDT or an LDT are placed in ROM, theprocessor can enter an indefinite loop if software or the processor attempts toupdate (write to) the ROM-based segment descriptors. To prevent this problem,set the accessed bits for all segment descriptors placed in a ROM. Also, removeoperating-system or executive code that attempts to modify segment descriptorslocated in ROM. indefinite [ɪnˈdefɪnət]: 无限期的 如果 GDT 或 LDT 中的段描述符放置在 ROM 中，则当软件或处理器尝试更新（写入）ROM-based 的段描述符时，处理器可能会进入 indefinite loop。 为了防止出现此问题，请设置 ROM 中所有段描述符的accessed bits。另外，删除尝试修改 ROM 中的段描述符的操作系统或执行代码。3.5 SYSTEM DESCRIPTOR TYPESWhen the S (descriptor type) flag in a segment descriptor is clear, thedescriptor type is a system descriptor. The processor recognizes the followingtypes of system descriptors: 当段描述符中的S（描述符类型）标志清零时，该描述符类型是系统描述符。 处理器可识别以下类型的系统描述符： Local descriptor-table (LDT) segment descriptor. Task-state segment (TSS) descriptor. Call-gate descriptor. Interrupt-gate descriptor. Trap-gate descriptor. Task-gate descriptor.These descriptor types fall into two categories: system-segment descriptors andgate descriptors. System-segment descriptors point to system segments (LDT andTSS segments). Gate descriptors are in themselves “gates,” which hold pointersto procedure entry points in code segments (call, interrupt, and trap gates) orwhich hold segment selectors for TSS’s (task gates). in themselves: 本身, 自身 这些描述符类型分为两类：system-segment descriptor(系统段描述符)和gate descriptor(门描述符)。 系统段描述符指向系统段（LDT 和 TSS 段）。Gate descriptor 本身就是“gate”，它保存指向代码段中过程入口点的指针（调用、中断和陷阱门），或者保存 TSS（任务门）的段选择器。 TSS descriptor 只能在 GDT中. Table 3-2 shows the encoding of the type field for system-segment descriptorsand gate descriptors. Note that system descriptors in IA-32e mode are 16 bytesinstead of 8 bytes. Table 3-2 显示了系统段描述符和门描述符的类型字段的编码。 请注意，IA-32e 模式下的系统描述符是 16 字节，而不是 8 字节。See also: Section 3.5.1, “Segment Descriptor Tables,” and Section 8.2.2, “TSSDescriptor” (for more information on the system-segment descriptors); seeSection 5.8.3, “Call Gates”, Section 6.11, “IDT Descriptors”, and Section8.2.5, “Task-Gate Descriptor” (for more information on the gate descriptors). 另请参见：第 3.5.1 节“段描述符表”和第 8.2.2 节“TSS 描述符”（有关系统段描述符的更多信息）； 请参见第 5.8.3 节“调用门”、第 6.11 节“IDT 描述符”和第 8.2.5 节“任务门描述符”（有关门描述符的更多信息）。3.5.1 Segment Descriptor TablesA segment descriptor table is an array of segment descriptors (see Figure3-10). A descriptor table is variable in length and can contain up to 8192(213) 8-byte descriptors. There are two kinds of descriptor tables: 段描述符表是段描述符的数组（见图3-10）。 描述符表的长度是可变的，最多可以包含 8192 (2^13) 个 8 字节描述符。 描述符表有两种： The global descriptor table (GDT) The local descriptor tables (LDT)Each system must have one GDT defined, which may be used for all programs andtasks in the system. Optionally, one or more LDTs can be defined. For example,an LDT can be defined for each separate task being run, or some or all taskscan share the same LDT. 每个系统必须定义一个GDT，它可以用于系统中的所有程序和任务。 可选地，可以定义一个或多个LDT。 例如，可以为正在运行的每个单独的任务定义LDT，或者一些或所有任务可以共享相同的LDT。The GDT is not a segment itself; instead, it is a data structure in linearaddress space. The base linear address and limit of the GDT must be loaded intothe GDTR register (see Section 2.4, “Memory-Management Registers”). The baseaddress of the GDT should be aligned on an eight-byte boundary to yield thebest processor performance. The limit value for the GDT is expressed in bytes.As with segments, the limit value is added to the base address to get theaddress of the last valid byte. A limit value of 0 results in exactly one validbyte. Because segment descriptors are always 8 bytes long, the GDT limit shouldalways be one less than an integral multiple of eight (that is, 8N – 1). yield: v: 产生;屈服,投降;让步;放弃 n:产量;产出;利润integral: adj 完整的; n 整体integral multiple: 整数倍 GDT 本身不是段；相反，它是线性地址空间中的数据结构。 GDT 的基线性地址和限制必须加载到 GDTR 寄存器中（请参见第 2.4 节“内存管理寄存器”）。 GDT 的基地址应在8-byte边界上对齐，以产生最佳的处理器性能。 GDT 的限制值以字节表示。 与段一样，将限制值添加到基地址以获得最后一个有效字节的地址。 限制值 0 只会产生一个有效字节。 由于段描述符始终为 8 字节长，因此 GDT 限制应始终小于 8 的整数倍（即 8N – 1）. 这里大概的意思是说, limit达到的效果是 [0, limit], 实际上range 为 limit - 0 + 1 = limit + 1 所以要想指定N个 GDT descriptor大小, 需要将限制设置为 8N - 1, 该range正好为8N.The first descriptor in the GDT is not used by the processor. A segmentselector to this “null descriptor” does not generate an exception when loadedinto a data-segment register (DS, ES, FS, or GS), but it always generates ageneral-protection exception (#GP) when an attempt is made to access memoryusing the descriptor. By initializing the segment registers with this segmentselector, accidental reference to unused segment registers can be guaranteedto generate an exception. accidental [ˌæksɪˈdentl]: 意外的;偶然的guaranteed [ˌɡærənˈtiːd]J GDT 中的第一个描述符未被处理器使用。 当加载到数据段寄存器（DS、ES、FS 或 GS）时，此“null descriptor” 的段选择器不会生成异常，但当尝试使用该描述符access memory时，它总是生成一般保护异常 (#GP)。通过使用该段选择器初始化段寄存器，可以保证意外引用 unused 段寄存器会生成异常。The LDT is located in a system segment of the LDT type. The GDT must contain asegment descriptor for the LDT segment. If the system supports multiple LDTs,each must have a separate segment selector and segment descriptor in the GDT.The segment descriptor for an LDT can be located anywhere in the GDT. SeeSection 3.5, “System Descriptor Types”, for information on the LDTsegment-descriptor type. LDT位于LDT类型的系统段中。 GDT 必须包含 LDT 段的段描述符。 如果系统支持多个LDT，则每个LDT在GDT中必须有一个单独的段选择器和段描述符。 LDT 的段描述符可以位于 GDT 中的任何位置。 有关 LDT 段描述符类型的信息，请参见第 3.5 节“系统描述符类型”。An LDT is accessed with its segment selector. To eliminate address translationswhen accessing the LDT, the segment selector, base linear address, limit, andaccess rights of the LDT are stored in the LDTR register (see Section 2.4,“Memory-Management Registers”). eliminate [ɪˈlɪmɪneɪt]: 消除, 排除;消灭, 清除 LDT 通过其段选择器来访问。为了避免访问 LDT 时的地址转换，LDT 的段选择器、基线性地址、限制和访问权限存储在 LDTR 寄存器中（请参见第 2.4 节“内存管理寄存器”）。When the GDTR register is stored (using the SGDT instruction), a 48-bit“pseudo-descriptor” is stored in memory (see top diagram in Figure 3-11). Toavoid alignment check faults in user mode (privilege level 3), the pseudo-descriptor should be located at an odd word address (that is, address MOD 4 isequal to 2). This causes the processor to store an aligned word, followed by analigned doubleword. User-mode programs normally do not storepseudo-descriptors, but the possibility of generating an alignment check faultcan be avoided by aligning pseudo-descriptors in this way. The same alignmentshould be used when storing the IDTR register using the SIDT instruction.When storing the LDTR or task register (using the SLDT or STR instruction,respectively), the pseudo-descriptor should be located at a doubleword address(that is, address MOD 4 is equal to 0). odd /ɑːd/: 古怪的，奇怪的 当 GDTR 寄存器被存储时（使用 SGDT 指令），一个 48 位“伪描述符”被存储在memory中（参见图 3-11 中的顶图）。 为了避免user mode （权限级别 3）下的对齐检查错误，伪描述符应位于奇数字地址（即地址 MOD 4 等于 2）。 这导致处理器存储先对齐的word，后跟在对齐doubleword。 用户态程序通常不存储伪描述符，但通过这种方式对齐伪描述符可以避免产生对齐检查错误的可能性。 使用 SIDT 指令存储 IDTR 寄存器时应使用相同的对齐方式。 当存储 LDTR 或任务寄存器（分别使用 SLDT 或 STR 指令）时，伪描述符应位于双字地址（即地址 MOD 4 等于 0）。 这个没看懂, 不知道SGDT 对 地址对齐要求和 特全级有什么关系 3.5.2 Segment Descriptor Tables in IA-32e ModeIn IA-32e mode, a segment descriptor table can contain up to 8192(213) 8-byte descriptors. An entry in the segment descriptor tablecan be 8 bytes. System descriptors are expanded to 16 bytes (occupying thespace of two entries). 在IA-32e模式中，段描述符表可以包含多达8192（2^13）个8字节描述符。段描述符表中的一个条目可以是8个字节。系统描述符被扩展到16个字节（占用两个条目的空间）。GDTR and LDTR registers are expanded to hold 64-bit base address. Thecorresponding pseudo-descriptor is 80 bits. (see the bottom diagram in Figure3-11). GDTR 和 LDTR 寄存器扩展为保存 64 位基地址。 相应的伪描述符是80位。 （参见图 3-11 中的底部部分）。The following system descriptors expand to 16 bytes: Call gate descriptors (see Section 5.8.3.1, “IA-32e Mode Call Gates”). IDT gate descriptors (see Section 6.14.1, “64-Bit Mode IDT”). LDT and TSS descriptors (see Section 8.2.3, “TSS Descriptor in 64-bitmode”)." }, { "title": "when load control register during in switching rmode 2 pmode", "url": "/posts/enter-protect-mode/", "categories": "my_test", "tags": "protect-mode", "date": "2024-04-22 10:30:00 +0800", "snippet": "the intel sdm suggestionFrom intel sdm 10.9.1 Switching to Protected Mode, it give followingsteps:...3. Execute a MOV CR0 instruction that sets the PE flag (and optionally the PG flag) in control...", "content": "the intel sdm suggestionFrom intel sdm 10.9.1 Switching to Protected Mode, it give followingsteps:...3. Execute a MOV CR0 instruction that sets the PE flag (and optionally the PG flag) in control register CR0.4. Immediately following the MOV CR0 instruction, execute a far JMP or far CALL instruction. (This operation is typically a far jump or call to the next instruction in the instruction stream.)5. It can be found that after executing \"MOV to CR0\" (set PE), the relevant instructions of the load control register can be executed....9. After entering protected mode, the segment registers continue to hold the contents they had in real-address mode. The JMP or CALL instruction in step 4 resets the CS register. Perform one of the following operations to update the contents of the remaining segment registers. + Reload segment registers DS, SS, ES, FS, and GS. If the ES, FS, and/or GS registers are not going to be used, load them with a null selector. ...This means that after we execute the MOV to CR0 (set PE) instruction, it isbest to execute a far jump or call immediately. After completing the above steps, go to load control registerBut on my own opinion, after executing “MOV to CR0” (set PE), the CPU hasentered protected mode. At this time, executing MOV to SS, MOV to DS will alsosuccessfully load the control register from the segment descriptor.testI wrote a small program and run it in qemu, part of it is as follows:lgdt %cs:gdt_descmov $0x28, %eaxmov %eax, %esmov $1, %eaxmov %eax, %cr0mov $0x28, %eaxmov %eax, %esljmp $0x10, $.startup_protThe above code modifies the ES selector before and after the mov to CR0 (setPE) instruction. Debugging using qemu+gdb. gdb print information(gdb) ni38 mov $0x28, %eax(gdb) ni39 mov %eax, %es(gdb)41 mov $1, %eax(gdb) ni42 mov %eax, %cr0(gdb) ni44 mov $0x28, %eax(gdb) ni45 mov %eax, %es(gdb) ni46 ljmp $0x10, $.startup_prot When gdb is executed to position 39, use the qemu monitor info registerscommand to obtain the ES register value: ES =0028 00000280 0000ffff 00009300 When gdb is executed to position 46, use the qemu monitor info registerscommand to obtain the ES register value: ES =0028 00000000 ffffffff 00cf9300 DPL=0 DS [-WA] It can be found that after executing “MOV to CR0” (set PE), the relevantinstructions of the load control register can be executed successfully.So I want to ask, is it reasonable to execute the “load control register”instruction immediately after MOV to CR0 (set PE), and what is the meaning ofstep 5 in the manual?Thanks" }, { "title": "vm86", "url": "/posts/vm86/", "categories": "intel_sdm", "tags": "virt", "date": "2024-04-22 10:30:00 +0800", "snippet": " FROM intel sdm chapter 21 8086 emulationabstractIA-32 processors (beginning with the Intel386 processor) provide two ways toexecute new or legacy programs that are assembled and/or compiled to ru...", "content": " FROM intel sdm chapter 21 8086 emulationabstractIA-32 processors (beginning with the Intel386 processor) provide two ways toexecute new or legacy programs that are assembled and/or compiled to run on anIntel 8086 processor: IA-32处理器(起始于intel386处理器)提供了两种来执行new/legacy 程序,这些程序被assembled(组装?) and/or compiled(编译) 以在intel 8086处理器上运行. Real-address mode. Virtual-8086 mode.Figure 2-3 shows the relationship of these operating modes to protected modeand system management mode (SMM). Figure 2-3 展示了这些操作模式和 保护模式以及 SMM 的关系When the processor is powered up or reset, it is placed in the real-addressmode. This operating mode almost exactly duplicates the execution environmentof the Intel 8086 processor, with some extensions. Virtually any programassembled and/or compiled to run on an Intel 8086 processor will run on anIA-32 processor in this mode. 当处理器被 power up 或者 reset, 他处于 real-address mode. 这种操作模式几乎完全复制了Intel 8086处理器的执行环境，并进行了一些扩展。实际上，任何在 Intel 8086 处理器上组装和/或编译的程序都可以在此模式下在 IA-32 处理器上运行.When running in protected mode, the processor can be switched to virtual-8086mode to run 8086 programs. This mode also duplicates the execution environmentof the Intel 8086 processor, with extensions. In virtual-8086 mode, an 8086program runs as a separate protected-mode task. Legacy 8086 programs are thusable to run under an operating system (such as Microsoft Windows*) that takesadvantage of protected mode and to use protected-mode facilities, such as theprotected-mode interrupt- and exception-handling facilities. Protected-modemultitasking permits multiple virtual-8086 mode tasks (with each task running aseparate 8086 program) to be run on the processor along with othernon-virtual-8086 mode tasks. take advantage of : 利用facility [fəˈsɪləti] : 组件, 设施, 特色, 天赋, 才能 当运行在保护模式下时，处理器可以切换到virtual-8086模式来运行8086程序。该模式还复制了Intel 8086 处理器的执行环境，并进行了扩展。在virtual-8086 模式下，8086 程序作为单独的保护模式任务运行。 因此，传统 8086 程序能够在利用保护模式的操作系统（例如 Microsoft Windows*）下运行并使用保护模式facilities(组件, 设施)，例如保护模式中断和异常处理facilities。 保护模式多任务处理允许多个virtual-8086 模式task（每个任务运行一个单独的 8086 程序）与其他 non-virtual-8086 模式任务一起在处理器上运行。This section describes both the basic real-address mode execution environmentand the virtual-8086-mode execution environment, available on the IA-32processors beginning with the Intel386 processor. 本节介绍基于 real-address 模式执行环境和virtual-8086 模式执行环境，可在从 Intel386 处理器开始的 IA-32 处理器上使用。21.1 REAL-ADDRESS MODEThe IA-32 architecture’s real-address mode runs programs written for the Intel8086, Intel 8088, Intel 80186, and Intel 80188 processors, or for thereal-address mode of the Intel 286, Intel386, Intel486, Pentium, P6 family,Pentium 4, and Intel Xeon processors. IA-32 架构的实地址模式运行为 Intel 8086、Intel 8088、Intel 80186 和 Intel 80188 处理器编写的程序，或为 Intel 286、Intel386、Intel486、Pentium、P6 系列、Pentium 4 和 英特尔至强处理器, 实地址模式编写的程序.The execution environment of the processor in real-address mode is designed toduplicate the execution environment of the Intel 8086 processor. To an 8086program, a processor operating in real-address mode behaves like a high-speed8086 processor. The principal features of this architecture are defined inChapter 3, “Basic Execution Environment”, of the Intel® 64 and IA-32Architectures Software Developer’s Manual, Volume 1. real-address模式下处理器的执行环境旨在复制Intel 8086处理器的执行环境。对于 8086 程序来说，运行在实地址模式下的处理器的行为类似于高速 8086 处理器。该架构的主要功能在 itnel sdm Volume 1 Chapter 3 “Basic Execution Environment”The following is a summary of the core features of the real-address modeexecution environment as would be seen by a program written for the 8086: 以下是为 8086 编写的程序所看到的实地址模式执行环境的核心功能的摘要： The processor supports a nominal 1-MByte physical address space (see Section21.1.1, “Address Translation in Real-Address Mode”, for specific details).This address space is divided into segments, each of which can be up to 64KBytes in length. The base of a segment is specified with a 16-bit segmentselector, which is shifted left by 4 bits to form a 20-bit offset fromaddress 0 in the address space. An operand within a segment is addressed witha 16-bit offset from the base of the segment. A physical address is thusformed by adding the offset to the 20-bit segment base (see Section 21.1.1,“Address Translation in Real-Address Mode”). 处理器支持标称 1 MB 物理地址空间（有关具体细节，请参见第 21.1.1 节”实地址模式下的地址转换”）。 该地址空间分为多个段，每个段的长度最多可达 64 KB。 段的基址由 16 位段选择器指定，该段选择器左移 4 位，形成距地址空间中地址 0 的 20 位偏移量。 段内的操作数通过距段基址的 16 位偏移量进行寻址。 因此，通过将偏移量添加到 20 位段基址来形成物理地址（请参见第 21.1.1 节“实地址模式下的地址转换”）。 All operands in “native 8086 code” are 8-bit or 16-bit values. (Operand sizeoverride prefixes can be used to access 32-bit operands.) “native 8086 代码”中的所有操作数都是 8 位或 16 位值。（操作数大小覆盖前缀可用于访问 32 位操作数。） Eight 16-bit general-purpose registers are provided: AX, BX, CX, DX, SP, BP,SI, and DI. The extended 32 bit registers (EAX, EBX, ECX, EDX, ESP, EBP, ESI,and EDI) are accessible to programs that explicitly perform a size overrideoperation. 提供 8 个 16 位通用寄存器：AX、BX、CX、DX、SP、BP、SI 和 DI。 扩展的 32 位寄存器（EAX、EBX、ECX、EDX、ESP、EBP、ESI 和 EDI）可供显式执行大小覆盖操作的程序访问。 Four segment registers are provided: CS, DS, SS, and ES. (The FS and GSregisters are accessible to programs that explicitly access them.) The CSregister contains the segment selector for the code segment; the DS and ESregisters contain segment selectors for data segments; and the SS registercontains the segment selector for the stack segment. 提供了四个段寄存器：CS、DS、SS 和 ES。 （FS 和 GS 寄存器可供显式访问它们的程序访问。）CS 寄存器包含代码段的段选择器； DS和ES寄存器包含数据段的段选择器；SS 寄存器包含堆栈段的段选择器。 The 8086 16-bit instruction pointer (IP) is mapped to the lower 16-bits ofthe EIP register. Note this register is a 32-bit register and unintentionaladdress wrapping may occur. unintentional: [ˌʌnɪnˈtenʃənl] 无意的; 非故意的; 偶然的 8086 16 位指令指针（IP）映射到 EIP 寄存器的低 16 位。 请注意，该寄存器是 32 位寄存器，可能会发生 unintentional address wrapping unintentional address wrapping 在 “21.1.1 Address Translation in Real-Address Mode” 有介绍 The 16-bit FLAGS register contains status and control flags. (This registeris mapped to the 16 least significant bits of the 32-bit EFLAGS register.) 16 位标志寄存器包含状态和控制标志。（该寄存器映射到 32 位 EFLAGS 寄存器的 16 个最低有效位。） All of the Intel 8086 instructions are supported (see Section 21.1.3,“Instructions Supported in Real-Address Mode”). 支持所有 Intel 8086 指令（请参见第 21.1.3 节“instruction supported in real-address mode”）。 A single, 16-bit-wide stack is provided for handling procedure calls andinvocations of interrupt and exception handlers. This stack is contained inthe stack segment identified with the SS register. The SP (stack pointer)register contains an offset into the stack segment. The stack grows down(toward lower segment offsets) from the stack pointer. The BP (base pointer)register also contains an offset into the stack segment that can be used as apointer to a parameter list. When a CALL instruction is executed, theprocessor pushes the current instruction pointer (the 16 least-significantbits of the EIP register and, on far calls, the current value of the CSregister) onto the stack. On a return, initiated with a RET instruction, theprocessor pops the saved instruction pointer from the stack into the EIPregister (and CS register on far returns). When an implicit call to aninterrupt or exception handler is executed, the processor pushes the EIP, CS,and EFLAGS (low-order 16-bits only) registers onto the stack. On a returnfrom an interrupt or exception handler, initiated with an IRET instruction,the processor pops the saved instruction pointer and EFLAGS image from thestack into the EIP, CS, and EFLAGS registers. invocations [ˌɪnvəʊˈkeɪʃənz]: 调用; 启用; 祈祷procedure [prəˈsiːdʒə(r)] : 程序, 步骤, 手续, 手术 提供了一个 16 位宽的堆栈来处理procedure calls以及中断和异常处理程序的调用。 该堆栈包含在由 SS 寄存器标识的堆栈段中。 SP（堆栈指针）寄存器包含堆栈段的偏移量。 堆栈从堆栈指针向下增长（朝向较低的段偏移量）。 BP（基指针）寄存器还包含堆栈段的偏移量，可用作指向参数列表的指针。 当执行 CALL 指令时，处理器将当前指令指针（EIP 寄存器的 16 个最低有效位，以及far all 时 CS 寄存器的当前值）推送到堆栈上。 在使用 RET 指令启动的返回时，处理器将保存的指令指针从堆栈pop到 EIP 寄存器（以及远返回时的 CS 寄存器）。 当执行对中断或异常处理程序的隐式调用时，处理器会将 EIP、CS 和 EFLAGS（仅限低位 16 位）寄存器压入堆栈。 从使用 IRET 指令启动的中断或异常处理程序返回时，处理器将保存的指令指针和 EFLAGS image从堆栈pop到 EIP、CS 和 EFLAGS 寄存器中。 A single interrupt table, called the “interrupt vector table” or “interrupttable,” is provided for handling interrupts and exceptions (see Figure 21-2).The interrupt table (which has 4-byte entries) takes the place of theinterrupt descriptor table (IDT, with 8-byte entries) used when handlingprotected-mode interrupts and exceptions. Interrupt and exception vectornumbers provide an index to entries in the interrupt table. Each entryprovides a pointer (called a “vector”) to an interrupt- or exception-handlingprocedure. See Section 21.1.4, “Interrupt and Exception Handling”, for moredetails. It is possible for software to relocate the IDT by means of the LIDTinstruction on IA-32 processors beginning with the Intel386 processor. by means of: 通过take the place of: 取代, 代替 提供了一个称为“中断向量表”或“中断表”的中断表来处理中断和异常（见图 21-2）。 中断表（具有 4-byte 条目）取代了处理保护模式中断和异常时使用的中断描述符表（IDT，具有 8-byte条目）。 中断和异常向量号提供中断表中条目的索引。 每个条目都提供一个指向interrupt &amp;&amp; exception-handling procedure 的指针（称为“向量”）。 更多详细信息，请参见第 21.1.4 节”中断和异常处理”。 从 Intel386 处理器开始，软件可以通过 IA-32 处理器上的 LIDT 指令来重新定位 IDT。 The x87 FPU is active and available to execute x87 FPU instructions inreal-address mode. Programs written to run on the Intel 8087 and Intel 287math coprocessors can be run in real-address mode without modification. coprocessors: 辅助处理器, 协处理器 x87 FPU 处于活动状态，可在实地址模式下执行 x87 FPU 指令。 为在 Intel8087 和 Intel 287 数学协处理器上运行而编写的程序无需修改即可在实地址模式下运行。 The following extensions to the Intel 8086 execution environment are availablein the IA-32 architecture’s real-address mode. If backwards compatibility toIntel 286 and Intel 8086 processors is required, these features should not beused in new programs written to run in real-address mode. Intel 8086 执行环境的以下扩展可在 IA-32 架构的实地址模式下使用。如果需要向后兼容 Intel 286 和 Intel 8086 处理器，则不应在为在实地址模式下运行而编写的新程序中使用这些功能。 Two additional segment registers (FS and GS) are available. Many of the integer and system instructions that have been added to laterIA-32 processors can be executed in real-address mode (see Section 21.1.3,“Instructions Supported in Real-Address Mode”). integer [ˈɪntɪdʒər]: 整数 许多已添加到后续 IA-32 处理器中的整数和系统指令都可以在实地址模式下执行（请参见第 21.1.3 节“实地址模式支持的指令”）。 The 32-bit operand prefix can be used in real-address mode programs toexecute the 32-bit forms of instructions. This prefix also allowsreal-address mode programs to use the processor’s 32-bit general-purposeregisters. 32 位操作数前缀可用于实地址模式程序来执行 32 位形式的指令。 该前缀还允许实地址模式程序使用处理器的 32 位通用寄存器。 The 32-bit address prefix can be used in real-address mode programs, allowing32-bit offsets. Many of the integer and system instructions that have beenadded to later IA-32 processors can be executed in real-address mode (seeSection 21.1.3, “Instructions Supported in Real-Address Mode”). 32位地址前缀可用于实地址模式程序，允许32位偏移。 许多已添加到后续 IA-32 处理器中的整数和系统指令都可以在实地址模式下执行（请参见第 21.1.3 节“实地址模式支持的指令”）。 The following sections describe address formation, registers, availableinstructions, and interrupt and exception handling in real-address mode. Forinformation on I/O in real-address mode, see Chapter 19, “Input/Output”, of theIntel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 1. a32-bit register and unintentional address wrapping may occur. 以下部分描述了实地址模式下的地址形成、寄存器、可用指令以及中断和异常处理。有关实地址模式下 I/O 的信息，请参阅intel sdm 第 1 卷第 19 章“Input/Output”。可能会发生 32 位寄存器和unintentional address wrapping。21.1.1 Address Translation in Real-Address ModeIn real-address mode, the processor does not interpret segment selectors asindexes into a descriptor table; instead, it uses them directly to form linearaddresses as the 8086 processor does. It shifts the segment selector left by 4bits to form a 20-bit base address (see Figure 21-1). The offset into a segmentis added to the base address to create a linear address that maps directly tothe physical address space. interpret [ɪnˈtɜːprət]: 解释, 说明; 把...理解为 在实地址模式下，处理器不会将段选择器解释为描述符表的索引； 相反，它像 8086 处理器一样直接使用它们来形成线性地址。 它将段选择子左移 4 位，形成 20 位基地址（见图 21-1）。 段中的偏移量被添加到基地址以创建直接映射到物理地址空间的线性地址。When using 8086-style address translation, it is possible to specify addresseslarger than 1 MByte. For example, with a segment selector value of FFFFH and anoffset of FFFFH, the linear (and physical) address would be 10FFEFH (1 megabyteplus 64 KBytes). The 8086 processor, which can form addresses only up to 20bits long, truncates the high-order bit, thereby “wrapping” this address toFFEFH. When operating in real-address mode, however, the processor does nottruncate such an address and uses it as a physical address. (Note, however,that for IA-32 processors beginning with the Intel486 processor, the A20M#signal can be used in real-address mode to mask address line A20, therebymimicking the 20-bit wrap-around behavior of the 8086 processor.) Care shouldbe take to ensure that A20M# based address wrapping is handled correctly inmultiprocessor based system. 当使用 8086 类型的地址转换时，可以指定大于 1 MB 的地址。 例如，如果段选择器值为 FFFFH，偏移量为 FFFFH，则线性（物理）地址将为 10FFEFH（1 兆字节加 64 KB）。 0xffff&lt;&lt;4 + 0xffff = 64K * 16 + 64k = 1M-byte + 64K = 0x10ffef 8086 处理器只能形成最多 20 位长的地址，它会截断高位，从而将该地址“包装”为 FFEFH。然而，当在实地址模式下运行时，处理器不会截断此类地址并将其用作物理地址。 （但请注意，对于从 Intel486 处理器开始的 IA-32 处理器，可以在实地址模式下使用 A20M# 信号来maks address line A20，从而模仿 8086 处理器的 20 位wrap-around行为。 ）应注意确保在基于多处理器的系统中正确处理基于 A20M# 的address wrappingThe IA-32 processors beginning with the Intel386 processor can generate 32-bitoffsets using an address override prefix; however, in real-address mode, thevalue of a 32-bit offset may not exceed FFFFH without causing an exception. 从Intel386处理器开始的IA-32处理器可以使用address override prefix生成32位偏移量；然而，在实地址模式下，32位偏移量的值不能超过FFFFH而不引起异常。For full compatibility with Intel 286 real-address mode, pseudo-protectionfaults (interrupt 12 or 13) occur if a 32- bit offset is generated outside therange 0 through FFFFH. 为了与 Intel 286 实地址模式完全兼容，如果在 0 到 FFFFH 范围之外生成 32 位偏移，则会发生 pseudo-protection (伪保护故障（中断 12 或 13）。21.1.2 Registers Supported in Real-Address ModeThe register set available in real-address mode includes all the registersdefined for the 8086 processor plus the new registers introduced in later IA-32processors, such as the FS and GS segment registers, the debug registers, thecontrol registers, and the floating-point unit registers. The 32-bit operandprefix allows a real-address mode program to use the 32-bit general-purposeregisters (EAX, EBX, ECX, EDX, ESP, EBP, ESI, and EDI). 实地址模式下可用的寄存器集包括为 8086 处理器定义的所有寄存器以及后来的 IA-32 处理器中引入的新寄存器，例如 FS 和 GS 段寄存器、调试寄存器、控制寄存器和浮点寄存器。 32 位操作数前缀允许实地址模式程序使用 32 位通用寄存器（EAX、EBX、ECX、EDX、ESP、EBP、ESI 和 EDI）。21.1.3 Instructions Supported in Real-Address ModeThe following instructions make up the core instruction set for the 8086processor. If backwards compatibility to the Intel 286 and Intel 8086processors is required, only these instructions should be used in a new programwritten to run in real-address mode. 以下指令构成了 8086 处理器的核心指令集。 如果需要向后兼容 Intel 286 和 Intel 8086 处理器，在编写为在实地址模式下运行的新程序中仅使用这些指令。 Move (MOV) instructions that move operands between general-purpose registers,segment registers, and between memory and general-purpose registers. The exchange (XCHG) instruction. Load segment register instructions LDS and LES. Arithmetic instructions ADD, ADC, SUB, SBB, MUL, IMUL, DIV, IDIV, INC, DEC,CMP, and NEG. Logical instructions AND, OR, XOR, and NOT. Decimal instructions DAA, DAS, AAA, AAS, AAM, and AAD. decimal [ˈdesɪml] :十进制 Stack instructions PUSH and POP (to general-purpose registers and segmentregisters). Type conversion instructions CWD, CDQ, CBW, and CWDE. conversion : 转换, 转变 Shift and rotate instructions SAL, SHL, SHR, SAR, ROL, ROR, RCL, and RCR. rotate [ˈroʊteɪt]: 旋转 TEST instruction. Control instructions JMP, Jcc, CALL, RET, LOOP, LOOPE, and LOOPNE. Interrupt instructions INT n, INTO, and IRET. EFLAGS control instructions STC, CLC, CMC, CLD, STD, LAHF, SAHF, PUSHF, andPOPF. I/O instructions IN, INS, OUT, and OUTS. Load effective address (LEA) instruction, and translate (XLATB) instruction. LOCK prefix. Repeat prefixes REP, REPE, REPZ, REPNE, and REPNZ. Processor halt (HLT) instruction. No operation (NOP) instruction.The following instructions, added to later IA-32 processors (some in the Intel286 processor and the remainder in the Intel386 processor), can be executed inreal-address mode, if backwards compatibility to the Intel 8086 processor isnot required. 如果不需要向后兼容 Intel 8086 处理器，则添加到后来的 IA-32 处理器（一些在 Intel 286 处理器中，其余在 Intel386 处理器中）的以下指令可以在实地址模式下执行。 Move (MOV) instructions that operate on the control and debug registers. Load segment register instructions LSS, LFS, and LGS. Generalized multiply instructions and multiply immediate data. Generalized [ˈdʒenrəlaɪzd] : 广义的 Shift and rotate by immediate counts. Stack instructions PUSHA, PUSHAD, POPA, POPAD, and PUSH immediate data. Move with sign extension instructions MOVSX and MOVZX. Long-displacement Jcc instructions. displacement: 移位;取代 Exchange instructions CMPXCHG, CMPXCHG8B, and XADD. String instructions MOVS, CMPS, SCAS, LODS, and STOS. Bit test and bit scan instructions BT, BTS, BTR, BTC, BSF, and BSR; thebyte-set-on condition instruction SETcc;and the byte swap (BSWAP) instruction. EFLAGS control instructions PUSHF and POPF. ENTER and LEAVE control instructions. BOUND instruction. CPU identification (CPUID) instruction. System instructions CLTS, INVD, WINVD, INVLPG, LGDT, SGDT, LIDT, SIDT, LMSW,SMSW, RDMSR, WRMSR, RDTSC, and RDPMC.Execution of any of the other IA-32 architecture instructions (not given in theprevious two lists) in real-address mode result in an invalid-opcode exception(#UD) being generated. 在实地址模式下执行任何其他 IA-32 架构指令（前两个列表中未给出）都会导致生成invaild-opcode 异常 (#UD)。 21.1.4 Interrupt and Exception HandlingWhen operating in real-address mode, software must provide interrupt andexception-handling facilities that are separate from those provided inprotected mode. Even during the early stages of processor initialization whenthe processor is still in real-address mode, elementary real-address modeinterrupt and exception-handling facilities must be provided to ensure reliableoperation of the processor, or the initialization code must ensure that nointerrupts or exceptions will occur. 当在实地址模式下运行时，软件必须提供与保护模式下提供的中断和异常处理设施分开的facilities。 即使在处理器初始化的早期阶段，当处理器仍处于实地址模式时，也必须提供基本实地址模式中断和异常处理设施，以确保处理器的可靠运行，或者必须保证初始化代码没有中断或触发异常。The IA-32 processors handle interrupts and exceptions in real-address modesimilar to the way they handle them in protected mode. When a processorreceives an interrupt or generates an exception, it uses the vector number ofthe interrupt or exception as an index into the interrupt table. (In protectedmode, the interrupt table is called the interrupt descriptor table (IDT), butin real-address mode, the table is usually called the interrupt vector table,or simply the interrupt table.) The entry in the interrupt vector tableprovides a pointer to an interrupt- or exception-handler procedure. (Thepointer consists of a segment selector for a code segment and a 16-bit offsetinto the segment.) The processor performs the following actions to make animplicit call to the selected handler: IA-32 处理器在实地址模式下处理中断和异常的方式与在保护模式下处理中断和异常的方式类似。 当处理器接收到中断或生成异常时，它使用中断或异常的向量号作为中断表的索引。（在保护模式下，中断表称为中断描述符表（IDT），但在实地址模式下，该表通常称为中断向量表，或简称为中断表。）中断向量表中的条目提供 指向中断或异常处理程序的指针。（指针由代码段的段选择器和段中的 16 位偏移量组成。）处理器执行以下操作以隐式调用所选处理程序： Pushes the current values of the CS and EIP registers onto the stack. (Onlythe 16 least-significant bits of the EIP register are pushed.) Pushes the low-order 16 bits of the EFLAGS register onto the stack. Clears the IF flag in the EFLAGS register to disable interrupts. Clears the TF, RF, and AC flags, in the EFLAGS register. Transfers program control to the location specified in the interrupt vectortable.An IRET instruction at the end of the handler procedure reverses these steps toreturn program control to the interrupted program. Exceptions do not returnerror codes in real-address mode. The interrupt vector table is an array of4-byte entries (see Figure 21-2). Each entry consists of a far pointer to ahandler procedure, made up of a segment selector and an offset. The processorscales the interrupt or exception vector by 4 to obtain an offset into theinterrupt table. Following reset, the base of the interrupt vector table islocated at physical address 0 and its limit is set to 3FFH. In the Intel 8086processor, the base address and limit of the interrupt vector table cannot bechanged. In the later IA-32 processors, the base address and limit of theinter- rupt vector table are contained in the IDTR register and can be changedusing the LIDT instruction. reverses [rɪˈvɜːsɪz] : 反转 处理程序末尾的 IRET 指令反转这些步骤，将程序控制权返回给被中断的程序。 在实地址模式下，异常不会返回错误代码。 中断向量表是一个 4 字节条目的数组（见图 21-2）。 每个条目都包含一个指向处理程序过程的远指针，该指针由段选择器和偏移量组成。 处理器将中断或异常向量 乘 4 以获得中断表中的偏移量。 复位后，中断向量表的基址位于物理地址 0，其限制设置为 3FFH。 在Intel 8086处理器中，中断向量表的基地址和限制是不能改变的。 在后来的 IA-32 处理器中，中断向量表的基址和限制包含在 IDTR 寄存器中，并且可以使用 LIDT 指令进行更改。(For backward compatibility to Intel 8086 processors, the default base addressand limit of the interrupt vector table should not be changed.) （为了向后兼容 Intel 8086 处理器，不应更改中断向量表的默认基址和限制。）Table 21-1 shows the interrupt and exception vectors that can be generated inreal-address mode and virtual-8086 mode, and in the Intel 8086 processor. SeeChapter 6, “Interrupt and Exception Handling”, for a description of theexception conditions. 表 21-1 显示了在实地址模式和虚拟 8086 模式以及 Intel 8086 处理器中可以生成的中断和异常向量。有关异常情况的描述，请参见第 6 章“interrupt and exception handling”。21.2 VIRTUAL-8086 MODEVirtual-8086 mode is actually a special type of a task that runs in protectedmode. When the operating-system or executive switches to a virtual-8086-modetask, the processor emulates an Intel 8086 processor. The execution environmentof the processor while in the 8086-emulation state is the same as is describedin Section 21.1, “Real-Address Mode” for real-address mode, including theextensions. The major difference between the two modes is that in virtual-8086mode the 8086 emulator uses some protected-mode services (such as theprotected-mode interrupt and exception-handling and paging facilities). Virtual-8086 模式实际上是一种在保护模式下运行的特殊任务类型。 当操作系统或执行程序切换到虚拟 8086 模式任务时，处理器将模拟 Intel 8086 处理器。处理器在 8086 仿真状态下的执行环境与第 21.1 节“real address mode”中描述的实地址模式相同，包括扩展。 两种模式之间的主要区别在于，在虚拟 8086 模式下，8086 仿真器使用一些保护模式服务（例如保护模式中断、异常处理和分页功能）。As in real-address mode, any new or legacy program that has been assembledand/or compiled to run on an Intel 8086 processor will run in avirtual-8086-mode task. And several 8086 programs can be run asvirtual-8086-mode tasks concurrently with normal protected-mode tasks, usingthe processor’s multitasking facilities. concurrently [kənˈkʌrəntli]: 同时 与实地址模式一样，任何已组装和/或编译以在 Intel 8086 处理器上运行的new/legacy程序都将在虚拟 8086 模式任务中运行。 使用处理器的多任务处理功能，多个 8086 程序可以作为虚拟 8086 模式任务与正常保护模式任务同时运行。 NOTE: In the real-address mode, vector 13 is the segment overrun exception. Inprotected and virtual-8086 modes, this exception covers allgeneral-protection error conditions, including traps to the virtual-8086monitor from virtual-8086 mode. 在实地址模式下，向量13是段溢出异常。 在受保护模式和虚拟 8086 模式下，此异常涵盖所有general-proctection错误情况，包括从virtual-8086 模式到virtual-8086监视器的陷阱。 21.2.1 Enabling Virtual-8086 ModeThe processor runs in virtual-8086 mode when the VM (virtual machine) flag inthe EFLAGS register is set. This flag can only be set when the processorswitches to a new protected-mode task or resumes virtual-8086 mode via an IRETinstruction. 当 EFLAGS 寄存器中的 VM（虚拟机）标志被设置时，处理器以virtual-8086 模式运行。 仅当处理器切换到新的protected-mode task 或通过 IRET 指令恢复虚拟 8086 模式时，才能设置此标志。System software cannot change the state of the VM flag directly in the EFLAGSregister (for example, by using the POPFD instruction). Instead it changes theflag in the image of the EFLAGS register stored in the TSS or on the stackfollowing a call to an interrupt- or exception-handler procedure. For example,software sets the VM flag in the EFLAGS image in the TSS when first creating avirtual-8086 task. 系统软件无法直接更改 EFLAGS 寄存器中 VM 标志的状态（例如，通过使用 POPFD 指令）。相反，它会在调用中断或异常处理程序过程后更改存储在 TSS 或堆栈中的 EFLAGS 寄存器映像中的标志。 例如，当首次创建虚拟 8086 任务时，软件会在 TSS 的 EFLAGS image中设置 VM 标志。The processor tests the VM flag under three general conditions: When loading segment registers, to determine whether to use 8086-styleaddress translation. 当加载段寄存器时，确定是否使用8086风格的地址转换。 When decoding instructions, to determine which instructions are not supportedin virtual-8086 mode and which instructions are sensitive to IOPL sensitive: 敏感 解码指令时，确定哪些指令在 virtual-8086 模式下不支持以及哪些指令对 IOPL sensitive When checking privileged instructions, on page accesses, or when performingother permission checks. (Virtual-8086 mode always executes at CPL 3.) 检查特权指令、页面访问或执行其他权限检查时。 （虚拟 8086 模式始终在 CPL 3 上执行。） 21.2.2 Structure of a Virtual-8086 TaskA virtual-8086-mode task consists of the following items: A 32-bit TSS for the task. The 8086 program. A virtual-8086 monitor. 8086 operating-system services.The TSS of the new task must be a 32-bit TSS, not a 16-bit TSS, because the16-bit TSS does not load the most-significant word of the EFLAGS register,which contains the VM flag. All TSS’s, stacks, data, and code used to handleexceptions when in virtual-8086 mode must also be 32-bit segments. 新任务的 TSS 必须是 32 位 TSS，而不是 16 位 TSS，因为 16 位 TSS 不加载 EFLAGS 寄存器的最高有效字，该寄存器包含 VM 标志。 在虚拟 8086 模式下用于处理异常的所有 TSS、堆栈、数据和代码也必须是 32 位段。 RFLAGS.VM (Bit 17) The processor enters virtual-8086 mode to run the 8086 program and returns toprotected mode to run the virtual- 8086 monitor. 处理器进入虚拟8086模式以运行8086程序，并返回到保护模式以运行虚拟8086 monitor。The virtual-8086 monitor is a 32-bit protected-mode code module that runs at aCPL of 0. The monitor consists of initialization, interrupt- andexception-handling, and I/O emulation procedures that emulate a personalcomputer or other 8086-based platform. Typically, the monitor is either part ofor closely associated with the protected-mode general-protection (#GP)exception handler, which also runs at a CPL of 0. As with any protected-modecode module, code-segment descriptors for the virtual-8086 monitor must existin the GDT or in the task’s LDT. The virtual-8086 monitor also may needdata-segment descriptors so it can examine the IDT or other parts of the 8086program in the first 1 MByte of the address space. The linear addresses above10FFEFH are available for the monitor, the operating system, and other systemsoftware. closely: 紧密的, 接近的examine [ɪɡˈzæmɪn]: 检查审查 virtual-8086 monitor是一个 32 位保护模式code module，运行于 CPL 0 。监视器由初始化、中断和异常处理以及模拟个人计算机或其他 8086-based platform 的 I/O 模拟程序组成。通常，监视器是受保护模式通用保护 (#GP) 异常处理程序的一部分或与之密切相关，该异常处理程序也在 CPL 为 0 时运行。与任何受保护模式代码模块一样， virtual-8086 监视器必须存在于 GDT 或任务的 LDT 中。 virtual-8086 监视器还可能需要数据段描述符，以便它可以检查地址空间前 1 MB 中的 IDT 或 8086 程序的其他部分。 10FFEFH 以上的线性地址可供显示器、操作系统和其他系统软件使用。The 8086 operating-system services consists of a kernel and/or operating-systemprocedures that the 8086 program makes calls to. These services can beimplemented in either of the following two ways: 8086 操作系统服务由 8086 程序调用的内核和/或操作系统过程组成。 这些服务可以通过以下两种方式实现： They can be included in the 8086 program. This approach is desirable foreither of the following reasons: desirable [dɪˈzaɪərəbl]: 可取的 它们可以包含在 8086 程序中。 由于以下任一原因，这种方法是可取的： The 8086 program code modifies the 8086 operating-system services. 8086程序代码修改8086操作系统服务。 There is not sufficient development time to merge the 8086 operating-systemservices into main operating system or executive. sufficient [səˈfɪʃnt] : 足够的 没有足够的开发时间将 8086 操作系统服务合并到主操作系统或执行程序中。 They can be implemented or emulated in the virtual-8086 monitor. This approachis desirable for any of the following reasons: 它们可以在virtual-8086 监视器中实现或模拟。 由于以下任一原因，这种方法是可取的： The 8086 operating-system procedures can be more easily coordinated amongseveral virtual-8086 tasks. coordinateda [koʊˈɔːrdɪneɪtɪd] : 使协调; 使相配合; 8086 操作系统程序可以更轻松地在多个虚拟 8086 任务之间进行协调。 Memory can be saved by not duplicating 8086 operating-system procedure codefor several virtual-8086 tasks. 通过不为多个虚拟 8086 任务复制 8086 操作系统过程代码，可以节省内存。 The 8086 operating-system procedures can be easily emulated by calls to themain operating system or executive. 通过调用主操作系统或执行程序可以轻松模拟 8086 操作系统程序。 The approach chosen for implementing the 8086 operating-system services mayresult in different virtual-8086- mode tasks using different 8086operating-system services. 选择用于实现 8086 操作系统服务的方法可能会因使用不同 8086 操作系统服务的导致virtual-8086-mode task 不同21.2.3 Paging of Virtual-8086 TasksEven though a program running in virtual-8086 mode can use only 20-bit linearaddresses, the processor converts these addresses into 32-bit linear addressesbefore mapping them to the physical address space. If paging is being used, the8086 address space for a program running in virtual-8086 mode can be paged andlocated in a set of pages in physical address space. If paging is used, it istransparent to the program running in virtual-8086 mode just as it is for anytask running on the processor. done B, before done A: done B, 然后在 done A 即使在virtual-8086 模式下运行的程序只能使用 20 位线性地址，处理器也会将这些地址转换为 32 位线性地址，然后再将它们映射到物理地址空间。 如果正在使用分页，则可以对在虚拟 8086 模式下运行的程序的 8086 地址空间进行分页并将其定位在物理地址空间中的一组页面中。 如果使用分页，则它对于在虚拟 8086 模式下运行的程序是透明的，就像对于处理器上运行的任何任务一样。Paging is not necessary for a single virtual-8086-mode task, but paging isuseful or necessary in the following situations: 对于单个虚拟 8086 模式任务来说，分页不是必需的，但在以下情况下分页是有用或必要的： When running multiple virtual-8086-mode tasks. Here, paging allows the lower1 MByte of the linear address space for each virtual-8086-mode task to bemapped to a different physical address location. 运行多个虚拟 8086 模式任务时。 这里，分页允许将每个虚拟 8086 模式任务的线性地址空间的低 1 MB 映射到不同的物理地址位置。 When emulating the 8086 address-wraparound that occurs at 1 MByte. When using8086-style address translation, it is possible to specify addresses largerthan 1 MByte. These addresses automatically wraparound in the Intel 8086processor (see Section 21.1.1, “Address Translation in Real-Address Mode”).If any 8086 programs depend on address wraparound, the same effect can beachieved in a virtual-8086-mode task by mapping the linear addresses between100000H and 110000H and linear addresses between 0 and 10000H to the samephysical addresses. 当模拟 1 MB 处发生的 8086 address-wraparound时。 当使用 8086 类型的地址转换时，可以指定大于 1 MB 的地址。 这些地址在 Intel 8086 处理器中自动 wraparound（请参见第 21.1.1 节“实地址模式下的地址转换”）。如果任何8086程序依赖于addresswraparound, 则通过将100000H和110000H之间的线性地址以及0和10000H之间的线性地址映射到相同的物理地址，可以在虚拟8086模式任务中实现相同的效果。 When sharing the 8086 operating-system services or ROM code that is common toseveral 8086 programs running as different 8086-mode tasks. 当共享作为不同 8086 模式任务运行的多个 8086 程序所共用的 8086 操作系统服务或ROM 代码时。 When redirecting or trapping references to memory-mapped I/O devices. 当重定向或捕获对 memory-mapped I/O 设备的引用时。 21.2.4 Protection within a Virtual-8086 TaskProtection is not enforced between the segments of an 8086 program. Either ofthe following techniques can be used to protect the system software running ina virtual-8086-mode task from the 8086 program: enforced [ɪnˈfɔːst]: 强迫的, 强制性的 8086 程序的段之间不强制执行保护。 可以使用以下任一技术来保护在 virtual-8086 模式任务中运行的系统软件免受 8086 程序的影响： Reserve the first 1 MByte plus 64 KBytes of each task’s linear address spacefor the 8086 program. An 8086 processor task cannot generate addressesoutside this range. 为 8086 程序保留每个任务的前 1 MB 加上 64 KB 的线性地址空间。 8086 处理器task无法生成此范围之外的地址。 Use the U/S flag of page-table entries to protect the virtual-8086 monitorand other system software in the virtual-8086 mode task space. When theprocessor is in virtual-8086 mode, the CPL is 3. Therefore, an 8086 processorprogram has only user privileges. If the pages of the virtual-8086 monitorhave supervisor privilege, they cannot be accessed by the 8086 program. 使用页表条目的 U/S 标志来保护virtual-8086 monitor和virtual-8086 模式任务空间中的其他系统软件。 当处理器处于virtual-8086模式时，CPL为3。因此，8086处理器程序仅具有用户权限。 如果虚拟 8086 监视器的页面具有管理员权限，则 8086 程序无法访问它们。 21.2.5 Entering Virtual-8086 ModeFigure 21-3 summarizes the methods of entering and leaving virtual-8086 mode.The processor switches to virtual-8086 mode in either of the followingsituations: 图21-3总结了进入和离开虚拟8086模式的方法。 在以下任一情况下，处理器会切换到虚拟 8086 模式： Task switch when the VM flag is set to 1 in the EFLAGS register image storedin the TSS for the task. Here the task switch can be initiated in either oftwo ways: 当任务的 TSS 中存储的 EFLAGS 寄存器映像中的 VM 标志设置为 1 时，进行任务切换。 这里可以通过两种方式启动任务切换： A CALL or JMP instruction. An IRET instruction, where the NT flag in the EFLAGS image is set to 1. IRET, with EFLAGS image ‘s NT flag == 1 Return from a protected-mode interrupt or exception handler when the VM flagis set to 1 in the EFLAGS register image on the stack. 当堆栈上 EFLAGS 寄存器映像中的 VM 标志设置为 1 时，从保护模式中断或异常处理程序返回。 When a task switch is used to enter virtual-8086 mode, the TSS for thevirtual-8086-mode task must be a 32-bit TSS. (If the new TSS is a 16-bit TSS,the upper word of the EFLAGS register is not in the TSS, causing the processorto clear the VM flag when it loads the EFLAGS register.) The processor updatesthe VM flag prior to loading the segment registers from their images in the newTSS. The new setting of the VM flag determines whether the processor interpretsthe contents of the segment registers as 8086-style segment selectors orprotected-mode segment selectors. When the VM flag is set, the segmentregisters are loaded from the TSS, using 8086-style address translation to formbase addresses. 当使用任务切换进入virtual-8086模式时，virtual-8086模式任务的TSS必须是32位TSS。（如果新的TSS是16位TSS，则EFLAGS寄存器的高位不在TSS中，导致处理器在加载EFLAGS寄存器时清除VM标志。）处理器在加载之前更新VM标志 该段将image注册到新的 TSS 中。 VM 标志的新设置确定处理器是否将段寄存器的内容解释为 8086 型段选择器或保护模式段选择器。 当VM标志被设置时，段寄存器从TSS加载，使用8086类型的地址转换来形成基地址。 否则, 段寄存器的值将在段选择子 indicate 的 段描述符中加载 See Section 21.3, “Interrupt and Exception Handling in Virtual-8086 Mode”, forinformation on entering virtual- 8086 mode on a return from an interrupt orexception handler. 有关从中断或异常处理程序返回时进入虚拟 8086 模式的信息，请参见第 21.3 节“虚拟 8086 模式中的中断和异常处理”。21.2.6 Leaving Virtual-8086 ModeThe processor can leave the virtual-8086 mode only through an interrupt orexception. The following are situations where an interrupt or exception willlead to the processor leaving virtual-8086 mode (see Figure 21-3): 处理器只能通过中断或异常离开虚拟 8086 模式。 以下是中断或异常将导致处理器离开虚拟 8086 模式的情况（见图 21-3）： The processor services a hardware interrupt generated to signal thesuspension of execution of the virtual-8086 application. This hardwareinterrupt may be generated by a timer or other external mechanism. Uponreceiving the hardware interrupt, the processor enters protected mode andswitches to a protected-mode (or another virtual-8086 mode) task eitherthrough a task gate in the protected-mode IDT or through a trap or interruptgate that points to a handler that initiates a task switch. A task switchfrom a virtual-8086 task to another task loads the EFLAGS register from theTSS of the new task. The value of the VM flag in the new EFLAGS determines ifthe new task executes in virtual-8086 mode or not. 处理器处理硬件中断，该中断产生用于作为暂停执行虚拟 8086 应用程序的信号。 该硬件中断可以由定时器或其他外部机制产生。 收到硬件中断后，处理器进入保护模式并且切换到一个 protected-mode task(或者 另一个 virtual-8086 mode task).方式有两种, 要么通过保护模式 IDT 中的任务门或通过指向handler的陷阱或中断门,该handler 会发起一个task switch. 从virtual-8086 任务到另一个任务的任务切换会从新任务的 TSS 加载 EFLAGS 寄存器。新 EFLAGS 中 VM 标志的值决定新任务是否以 virtual-8086 模式执行。 The processor services an exception caused by code executing the virtual-8086task or services a hardware interrupt that “belongs to” the virtual-8086task. Here, the processor enters protected mode and services the exception orhardware interrupt through the protected-mode IDT (normally through aninterrupt or trap gate) and the protected-mode exception- andinterrupt-handlers. The processor may handle the exception or interruptwithin the context of the virtual 8086 task and return to virtual-8086 modeon a return from the handler procedure. The processor may also execute a taskswitch and handle the exception or interrupt in the context of another task. 处理器为执行 virtual-8086 任务的代码引起的异常提供服务，或者为“属于”virtual-8086任务的硬件中断提供服务。 这里，处理器进入保护模式并通过保护模式IDT（通常通过中断或陷阱门）以及保护模式异常和中断处理程序来处理异常或硬件中断。 处理器可以在虚拟8086任务的上下文中处理异常或中断，并在从处理程序过程返回时返回到虚拟8086模式。 处理器还可以执行任务切换并在另一个任务的上下文中处理异常或中断。 The processor services a software interrupt generated by code executing inthe virtual-8086 task (such as a software interrupt to call a MS-DOS*operating system routine). The processor provides several methods of handlingthese software interrupts, which are discussed in detail in Section 21.3.3,“Class 3—Software Interrupt Handling in Virtual-8086 Mode”. Most of theminvolve the processor entering protected mode, often by means of ageneral-protection (#GP) exception. In protected mode, the processor can sendthe interrupt to the virtual-8086 monitor for handling and/or redirect theinterrupt back to the application program running in virtual-8086 mode taskfor handling. 处理器为 virtual-8086 任务中执行的代码生成的软件中断提供服务（例如调用 MS-DOS* 操作系统例程的软件中断）。 处理器提供了几种处理这些软件中断的方法，这些方法在第 21.3.3 节“Class 3—Software Interrupt Handling in Virtual-8086 Mode”中详细讨论。其中大多数涉及处理器进入保护模式，通常是通过通用保护（#GP）异常的方式。 在保护模式下，处理器可以将中断发送到virtual-8086监视器以进行处理和/或将中断重定向回以virtual-8086模式任务运行的应用程序以进行处理。 IA-32 processors that incorporate the virtual mode extension (enabled withthe VME flag in control register CR4) are capable of redirectingsoftware-generated interrupts back to the program’s interrupt handlerswithout leaving virtual-8086 mode. See Section 21.3.3.4, “Method 5: SoftwareInterrupt Handling”, for more information on this mechanism. incorporate /ɪnˈkɔːpəreɪt/: 合并,包含 包含虚拟模式扩展（通过控制寄存器 CR4 中的 VME 标志启用）的 IA-32 处理器能够将软件生成的中断重定向回程序的中断处理程序，而无需离开虚拟 8086 模式。 有关此机制的更多信息，请参见第 21.3.3.4 节“方法 5：softwareinterrupt handling”。 A hardware reset initiated by asserting the RESET or INIT pin is a specialkind of interrupt. When a RESET or INIT is signaled while the processor is invirtual-8086 mode, the processor leaves virtual-8086 mode and entersreal-address mode. 通过置位 RESET 或 INIT 引脚启动的硬件复位是一种特殊类型的中断。 当处理器处于虚拟 8086 模式时发出 RESET 或 INIT 信号时，处理器将离开虚拟 8086 模式并进入实地址模式。 Execution of the HLT instruction in virtual-8086 mode will cause ageneral-protection (GP#) fault, which the protected-mode handler generallysends to the virtual-8086 monitor. The virtual-8086 monitor then determinesthe correct execution sequence after verifying that it was entered as aresult of a HLT execution. 在虚拟 8086 模式下执行 HLT 指令将导致general-protection (GP#) fault，保护模式处理程序通常会将其发送到 virtual-8086 监视器。 然后，virtual-8086 监视器在验证它是作为 HLT 执行的结果输入后确定正确的执行顺序。 See Section 21.3, “Interrupt and Exception Handling in Virtual-8086 Mode”, forinformation on leaving virtual-8086 mode to handle an interrupt or exceptiongenerated in virtual-8086 mode.有关离开 virtual-8086 模式以处理 virtual-8086 模式中生成的中断或异常的信息，请参见第 21.3 节 “Virtual-8086 模式下的中断和异常处理”。21.2.7 Sensitive InstructionsWhen an IA-32 processor is running in virtual-8086 mode, the CLI, STI, PUSHF,POPF, INT n, and IRET instructions are sensitive to IOPL. The IN, INS, OUT, andOUTS instructions, which are sensitive to IOPL in protected mode, are notsensitive in virtual-8086 mode. 当 IA-32 处理器运行在virtual-8086 模式下时，CLI、STI、PUSHF、POPF、INT n 和 IRET 指令对 IOPL 敏感。 IN、INS、OUT 和 OUTS 指令在保护模式下对 IOPL 敏感，但在virtual-8086 模式下不敏感。The CPL is always 3 while running in virtual-8086 mode; if the IOPL is lessthan 3, an attempt to use the IOPL-sensitive instructions listed abovetriggers a general-protection exception (#GP). These instructions are sensitiveto IOPL to give the virtual-8086 monitor a chance to emulate the facilitiesthey affect. 在virtual-8086 模式下运行时，CPL 始终为 3； 如果 IOPL 小于 3，则尝试使用上面列出的 IOPL 敏感指令会触发一般保护异常 (#GP)。 这些指令对 IOPL 敏感，使virtual-8086 监视器有机会模拟它们影响的facilities。21.2.8 Virtual-8086 Mode I/ONULL21.3 INTERRUPT AND EXCEPTION HANDLING IN VIRTUAL-8086 MODENULL21.4 PROTECTED-MODE VIRTUAL INTERRUPTSNULL" }, { "title": "async pf -- GUP change", "url": "/posts/async-pf-gup-change/", "categories": "kvm, async_pf", "tags": "para_virt", "date": "2024-04-16 15:00:00 +0800", "snippet": "参考代码 该部分代码, mail list中和commit中内容不同, 而且mail list中也没有提到为什么当时没有全部合入, 我们先以mail list 为准: [KVM: Add host swap event notifications for PV guest][v7] 后续, 我们在另一篇文章中详细介绍: [link][2] 遗留问题 get_user_pag...", "content": "参考代码 该部分代码, mail list中和commit中内容不同, 而且mail list中也没有提到为什么当时没有全部合入, 我们先以mail list 为准: [KVM: Add host swap event notifications for PV guest][v7] 后续, 我们在另一篇文章中详细介绍: [link][2] 遗留问题 get_user_pages_noio 该部分代码来自于: [Add get_user_pages() variant that fails if major fault is required.][3]社区并没有合入该patch该patch 引入了 get_user_page()的noio 版的变体, 他只在不需要 major fault的情况下才会成功的 get page reference 以上来自该patch的commit message This patch add get_user_pages() variant that only succeeds if gettinga reference to a page doesn't require major fault. 具体改动是: 增加了新的flow flag和fault flag flow/fault flag细节 flow flag: 该flag会作为gup_flags入参传入__get_user_pages(), 可以作为一些约束e.g., FOLL_WRITE 表明要要get的pages必须是可写入的 会对比vma-&gt;vm_flags 是否是可写的. 另外, 会在 follow page期间, 影响handle_mm_fault的fault flag e.g., FOLL_WRITE-&gt;FAULT_FLAG_WRITE 新增的flag为: +#define FOLL_MINOR\t0x20\t/* do only minor page faults */ 表明要在 follow page期间, 只允许处理 minor page fault.(不能处理swapin) fault flag: 用于handle_mm_fault()入参flags, 表明本次fault的类型.该参数可以用于一些优化和约束. e.g. 如果检测到没有FAULT_FLAG_WRITE, 说明是read access, 而又是第一次建立映射, 那么可以建立和zero page的映射 do_anonymous_page(){ ... if (!(flags &amp; FAULT_FLAG_WRITE)) { entry = pte_mkspecial(pfn_pte(my_zero_pfn(address), vma-&gt;vm_page_prot)); page_table = pte_offset_map_lock(mm, pmd, address, &amp;ptl); if (!pte_none(*page_table)) goto unlock; goto setpte; } ...} 新增的flag为: +#define FAULT_FLAG_MINOR\t0x08\t/* Do only minor fault */ 是由 FOLL_MINOR转化而来, 和其作用一样. vm fault reason: 其实, 还有一些flag, 是用于表示handle_mm_fault()的原因, 例如这里我们遇到的:VM_FAULT_MAJOR, 实际上是表明, 该函数返回失败是由于该fault是 major fault. 我们下面会结合代码改动详细看下, 这些flag的应用 关于处理这些\"flags\"具体代码流程改动: \"flags\"具体代码改动 __get_user_pages-&gt;handle_mm_fault @@ -1441,10 +1441,13 @@ int __get_user_pages(struct task_struct *tsk, struct mm_struct *mm, \t\t\tcond_resched(); \t\t\twhile (!(page = follow_page(vma, start, foll_flags))) { \t\t\t\tint ret;+\t\t\t\tunsigned int fault_fl =+\t\t\t\t\t((foll_flags &amp; FOLL_WRITE) ?+\t\t\t\t\tFAULT_FLAG_WRITE : 0) |+\t\t\t\t\t((foll_flags &amp; FOLL_MINOR) ?+\t\t\t\t\tFAULT_FLAG_MINOR : 0); -\t\t\t\tret = handle_mm_fault(mm, vma, start,-\t\t\t\t\t(foll_flags &amp; FOLL_WRITE) ?-\t\t\t\t\tFAULT_FLAG_WRITE : 0);+\t\t\t\tret = handle_mm_fault(mm, vma, start, fault_fl); 可以看到, 这里会将 FOLL_WRITE-&gt;FAULT_FLAG_WRITE, FOLL_MINOR-&gt;FAULT_FLAG_MINOR do_swap_page @@ -2648,6 +2670,9 @@ static int do_swap_page(struct mm_struct *mm, struct vm_area_struct *vma, \tdelayacct_set_flag(DELAYACCT_PF_SWAPIN); \tpage = lookup_swap_cache(entry); \tif (!page) {+\t\tif (flags &amp; FAULT_FLAG_MINOR)+\t\t\treturn VM_FAULT_MAJOR | VM_FAULT_ERROR;+ \t\tgrab_swap_token(mm); /* Contend for token _before_ read-in */ \t\tpage = swapin_readahead(entry, \t\t\t\t\tGFP_HIGHUSER_MOVABLE, vma, address); 如果没有在swap cache中找到, 说明该page 被swap出去, 并且被free了,需要swapin, 这时, 如果有FAULT_FLAG_MINOR,表明只允许处理 minor fault, 而swapin, 属于 major fault, 不允许处理, 需要返回错误, 同时把错误原因:VM_FAULT_MAJOR也返回 filemap_fault 和swapcache 相对应的还有pagecache diff --git a/mm/filemap.c b/mm/filemap.cindex 3d4df44..ef28b6d 100644--- a/mm/filemap.c+++ b/mm/filemap.c@@ -1548,6 +1548,9 @@ int filemap_fault(struct vm_area_struct *vma, struct vm_fault *vmf) \t\t\tgoto no_cached_page; \t\t} \t} else {+\t\tif (vmf-&gt;flags &amp; FAULT_FLAG_MINOR)+\t\t\treturn VM_FAULT_MAJOR | VM_FAULT_ERROR; 也是同样的处理逻辑 handle_mm_fault() --return-&gt;__get_user_pages() --handle retval @@ -1452,6 +1455,8 @@ int __get_user_pages(struct task_struct *tsk, struct mm_struct *mm, \t\t\t\t\tif (ret &amp; \t\t\t\t\t (VM_FAULT_HWPOISON|VM_FAULT_SIGBUS)) \t\t\t\t\t\treturn i ? i : -EFAULT;+\t\t\t\t\telse if (ret &amp; VM_FAULT_MAJOR)+\t\t\t\t\t\treturn i ? i : -EFAULT; \t\t\t\t\tBUG(); 如果是 FAULT_MAJOR并且没有get 到 page, 直接返回错误 新增get_user_pages_noio接口 +int get_user_pages_noio(struct task_struct *tsk, struct mm_struct *mm,+\t\tunsigned long start, int nr_pages, int write, int force,+\t\tstruct page **pages, struct vm_area_struct **vmas)+{+\tint flags = FOLL_TOUCH | FOLL_MINOR;++\tif (pages)+\t\tflags |= FOLL_GET;+\tif (write)+\t\tflags |= FOLL_WRITE;+\tif (force)+\t\tflags |= FOLL_FORCE;++\treturn __get_user_pages(tsk, mm, start, nr_pages, flags, pages, vmas);+}+EXPORT_SYMBOL(get_user_pages_noio);+ 不多解释, 在该接口中将FOLL_MINOR置位. NOTE 所以该部分patch的主要作用就是增加了get_user_pages_noio(), 使其, 只处理minor fault(假如只是alloc page, 那属于minor fault), 但是不能处理major fault.(例如swapin, pagecachein) 目前个人理解是这样, 之后还需要看下page fault的相关细节 我们接下来看下, async pf 框架是如何利用上面GUP noio接口的usage of GUP noio in async pf我们先看下, 触发 async pf 的入口, 我们上面介绍到, 在 EPT violation hook 中会去start 该work, 过程如下:tdp_page_fault@@ -2609,7 +2655,11 @@ static int tdp_page_fault(struct kvm_vcpu *vcpu, gva_t gpa, mmu_seq = vcpu-&gt;kvm-&gt;mmu_notifier_seq; smp_rmb(); //==(1)==- pfn = gfn_to_pfn(vcpu-&gt;kvm, gfn);+ //==(2)==+ if (try_async_pf(vcpu, gfn, gpa, &amp;pfn))+ return 0;++ /* mmio */ if (is_error_pfn(pfn)) 将现有的gfn_to_pfn(), 替换为try_async_pf(), 之前的gfn2pfn接口, 是必须async, 也就是上面提到的使用GUP时, 可以处理 MAJOR FAULT. 而现在替换为了 try_async_pf(), 打算尝试执行 async pf(也可能不需要, 例如遇到了 MINOR FAULT. 我们接下来会详细看下该接口 tdp_page_fault()中会执行try_async_pf()该函数返回值为true, 表示已经做了async pf,所以现在还不能去 map GPA-&gt;HPA. 需要该接口直接返回. 对于HALT的处理方式, 则是让vcpublock. 我们下面会看到.old version of gfn_to_pfn在看try_async_pf之前, 我们先看下合入patch之前的 gfn_to_pfn接口.gfn_to_pfn { __gfn_to_pfn(atomic=false) { gfn_to_hva { gfn_to_hva_many gfn_to_hva_memslot } //gfn_to_hva ----- 上面 gfn_to_hva 下面 hva_to_pfn ----- hva_to_pfn(atomic=false) { if (atomic) __get_user_pages_fast() else //走这个路径 get_user_pages_fast() } //hva_to_pfn } //__gfn_to_pfn} //gfn_to_pfn关于__get_user_pages_fast和get_user_pages_fast的不同, 主要是: __get_user_pages_fast()是atomic版本(IRQ-safe), 主要是因为get_user_pages_fast需要走slow path, 这个时候需要开中断, 而__get_user_pages_fast则不需要, 所以其过程是关中断的, 也可以在关中断的情况下执行 由于上面提到的原因, get_user_pages_fast 并不保存中断状态, 所以该函数必须在开中断的情况下执行 两个接口前的代码注释, 以及大致流程 get_user_pages_fast /** * get_user_pages_fast() - pin user pages in memory * @start: starting user address * @nr_pages: number of pages from start to pin * @write: whether pages will be written to * @pages: array that receives pointers to the pages pinned. * Should be at least nr_pages long. * * Attempt to pin user pages in memory without taking mm-&gt;mmap_sem. * If not successful, it will fall back to taking the lock and * calling get_user_pages(). * * &gt; 在不拿mm-&gt;mmap_sem 锁的情况下, 尝试将user page pin 到memory中. * &gt; 如果没有成功, 它将fall back 来拿锁, 并且调用get_user_pages() * * Returns number of pages pinned. This may be fewer than the number * requested. If nr_pages is 0 or negative, returns 0. If no pages * were pinned, returns -errno. * * &gt; 返回 page 被 pinned数量. 他可能比所需的数量要少. 如果nr_pages是0, * 或者是负数, 返回0. 如果没有page被pinned, 返回 -errno */get_user_pages_fast { local_irq_disable fast_path { //仅去看有多少page present } local_irq_enable get_user_page} __get_user_pages_fast /* * Like get_user_pages_fast() except its IRQ-safe in that it won't fall * back to the regular GUP. * * 除了他的 IRQ-safe(因为他不会fall bak to regular GUP), 其他的和 * get_user_pages_fast()一样 */__get_user_pages_fast { local_irq_save() fast_path local_irq_restore()} 这里, 我们不再过多展开GUP的代码, 总之, 早期的__get_user_pages_fast不会fall back到 regular GPU(slow pathget_user_pages)我们再来看下其改动,gfn_to_pfn-&gt;get_user_pages新增gfn_to_pfn_async(), 替代现有流程中的gfn_to_pfn(), 该接口新增了async:bool*参数, 该参数是一个iparam &amp;&amp; oparam iparam: 表示只走get_user_page fast path也就是__get_user_pages_fast oparam: 表示是否需要做 async pf具体改动如下+pfn_t gfn_to_pfn_async(struct kvm *kvm, gfn_t gfn, bool *async)+{+ return __gfn_to_pfn(kvm, gfn, false, async);+}+EXPORT_SYMBOL_GPL(gfn_to_pfn_async);+ pfn_t gfn_to_pfn(struct kvm *kvm, gfn_t gfn) {- return __gfn_to_pfn(kvm, gfn, false); //可以走slow path+ return __gfn_to_pfn(kvm, gfn, false, NULL); } EXPORT_SYMBOL_GPL(gfn_to_pfn);/* * !!MY NOTE!! * __gfn_to_pfn { * ... * //先初始化为false * if (async) * *async = false; * ... * return hva_to_pfn(kvm, addr, atomic, async); * } */我们再来看下hva_to_pfn改动:+static pfn_t hva_to_pfn(struct kvm *kvm, unsigned long addr, bool atomic,+ bool *async) { struct page *page[1];- int npages;+ int npages = 0; pfn_t pfn;- if (atomic)+ /* we can do it either atomically or asynchronously, not both */+ BUG_ON(atomic &amp;&amp; async); //==(1)==+ if (atomic || async) npages = __get_user_pages_fast(addr, 1, 1, page);- else {+ //==(2)==+ if (unlikely(npages != 1) &amp;&amp; !atomic) { might_sleep();- npages = get_user_pages_fast(addr, 1, 1, page);+ + if (async) {+ down_read(&amp;current-&gt;mm-&gt;mmap_sem);+ npages = get_user_pages_noio(current, current-&gt;mm,+ \t\t\t addr, 1, 1, 0, page, NULL);+ up_read(&amp;current-&gt;mm-&gt;mmap_sem);+ } else+ npages = get_user_pages_fast(addr, 1, 1, page); } if (unlikely(npages != 1)) { struct vm_area_struct *vma; if (atomic) goto return_fault_page; down_read(&amp;current-&gt;mm-&gt;mmap_sem); if (is_hwpoison_address(addr)) { up_read(&amp;current-&gt;mm-&gt;mmap_sem); get_page(hwpoison_page); return page_to_pfn(hwpoison_page); } vma = find_vma(current-&gt;mm, addr); if (vma == NULL || addr &lt; vma-&gt;vm_start || !(vma-&gt;vm_flags &amp; VM_PFNMAP)) { //==(3)==+ if (async &amp;&amp; !(vma-&gt;vm_flags &amp; VM_PFNMAP) &amp;&amp;+ (vma-&gt;vm_flags &amp; VM_WRITE))+ *async = true; up_read(&amp;current-&gt;mm-&gt;mmap_sem);return_fault_page: get_page(fault_page); return page_to_pfn(fault_page); } pfn = ((addr - vma-&gt;vm_start) &gt;&gt; PAGE_SHIFT) + vma-&gt;vm_pgoff; up_read(&amp;current-&gt;mm-&gt;mmap_sem); BUG_ON(!kvm_is_mmio_pfn(pfn)); } else pfn = page_to_pfn(page[0]); return pfn;} 如果是async, 会先尝试走一次fast path, 如果成功了, 则 npages = 1 如果上面fast path 失败了, 并且还是async, 则会执行get_user_pages_noio()该函数上面也提到过, 该过程不处理 MAJOR fault. 这里说明失败了, 也就是因为遇到了MAJOR fault, 所以该fault 并没有handle,需要异步处理, 那么就将 oparam async 置为true. 这里我们先不关心这里的几个判断条件, 之后放到GUP/内存管理的章节中介绍 遗留问题 " }, { "title": "async pf -- gfn2hva cache", "url": "/posts/async-pf-gfn2hva-cache/", "categories": "kvm, async_pf", "tags": "para_virt", "date": "2024-04-16 15:00:00 +0800", "snippet": "introduce该功能仅通过name就可以得知, 是为了缓存gfn(gpa)到hva的映射. 但是这个映射关系不是一直存在么, 为什么设计看似比较复杂的机制, 我们一步步来看user memory region support我们知道,在比较早期的版本, kvm 创建memslot APIkvm_vm_ioctl KVM_SET_USER_MEMORY_REGION就已经支持了对 use...", "content": "introduce该功能仅通过name就可以得知, 是为了缓存gfn(gpa)到hva的映射. 但是这个映射关系不是一直存在么, 为什么设计看似比较复杂的机制, 我们一步步来看user memory region support我们知道,在比较早期的版本, kvm 创建memslot APIkvm_vm_ioctl KVM_SET_USER_MEMORY_REGION就已经支持了对 user memory region申请的支持. 涉及patch Patch: KVM: Support assigning userspace memory to the guest mail list: mail 这里只展示下, 用户态入参的数据结构: +/* for KVM_SET_USER_MEMORY_REGION */+struct kvm_userspace_memory_region {+ __u32 slot;+ __u32 flags;+ __u64 guest_phys_addr;+ __u64 memory_size; /* bytes */+ __u64 userspace_addr; /* start of the userspace allocated memory */+}; 可以看到最后一个参数为, userspace_addr在该接口的支持下, qemu为guest申请memory region同时, 该内存也作为qemu进程的 anon memoryspace 存在, qemu 可以通过管理匿名页的方式, 对该地址空间进行管理, kernel其他组建, 也可以通过操作这部分匿名页来操作guest memory, 例如: memory reclaim, memory migrate…所以基本流程是: guest先通过mmap申请匿名内存空间, 调用完成后, kernel已经申请好了这段内存空间的virtual base address(userspace_addr) 调用kvm_vm_ioctl -- KVM_SET_USER_MEMORY_REGION 执行完成时, kvm 已经建立起了 hva-&gt;gpa映射关系 guest访问gpa, 触发EPT violation trap kvm, kvm 调用 get_user_page() 申请page, 并建立hva-&gt;hpa 同时, 创建gpa-&gt;hpa的mmu pgtables(if guest enable EPT feature, is ept pgtable)re-set memory region所以, 既然两者在set memory region 接口中就已经确立了映射关系, 那是不是只是保存下[hva, gpa]就相当于cache了.大部分情况下是这样, 但是在下面情况下, hva-&gt;gpa的映射关系会改变 guest call kvm_vm_ioctl -- KVM_SET_USER_MEMORY_REGION, map [hva-&gt;gpa]-&gt;[hpa_1, gpa] guest call kvm_vm_ioctl -- KVM_SET_USER_MEMORY_REGION again, remap [hva-&gt;gpa]-&gt;[hpa_2, gpa]在这种情况下, 映射关系就改变了.所以, 我们需要一个机制, 在re-set memory region 发生之后, 我们再次 “access this cache”时, 需要“invalidate this cache”, 这就是该patch要做的事情.patch 细节change of struct struct kvm_memslots { \tint nmemslots;+\tu32 generation; \tstruct kvm_memory_slot memslots[KVM_MEMORY_SLOTS + \t\t\t\t\tKVM_PRIVATE_MEM_SLOTS]; }; generation: 表示当前memslots 的generation, 也就是latest.+struct gfn_to_hva_cache {+\tu32 generation;+\tgpa_t gpa;+\tunsigned long hva;+\tstruct kvm_memory_slot *memslot;+}; generation: 获取cache时, memslots的generation, 可能是old的. memslot: 当前gpa所属的memslot, 主要用于 mark_page_dirty 作者在这里有个小心思, 因为这个地方没有该成员也没有关系, 也可以执行, mark_page_dirty, 但是在执行时, 需要每次获取memslot, 所以作者想了,既然缓存, 那为什么不缓存多一些, 将memslot也缓存 interfacecache init+int kvm_gfn_to_hva_cache_init(struct kvm *kvm, struct gfn_to_hva_cache *ghc,+\t\t\t gpa_t gpa)+{+\tstruct kvm_memslots *slots = kvm_memslots(kvm);+\tint offset = offset_in_page(gpa);+\tgfn_t gfn = gpa &gt;&gt; PAGE_SHIFT;++\tghc-&gt;gpa = gpa;+\t//==(1)==+\tghc-&gt;generation = slots-&gt;generation;+\tghc-&gt;memslot = __gfn_to_memslot(kvm, gfn);+\tghc-&gt;hva = gfn_to_hva_many(ghc-&gt;memslot, gfn, NULL);+\t//==(2)==+\tif (!kvm_is_error_hva(ghc-&gt;hva))+\t\tghc-&gt;hva += offset;+\telse+\t\treturn -EFAULT;++\treturn 0;+} 将此时slots-&gt;generation赋值给ghc-&gt;generation 错误情况暂时不看.write cache+int kvm_write_guest_cached(struct kvm *kvm, struct gfn_to_hva_cache *ghc,+\t\t\t void *data, unsigned long len)+{+\tstruct kvm_memslots *slots = kvm_memslots(kvm);+\tint r;++\t//==(1)==+\tif (slots-&gt;generation != ghc-&gt;generation)+\t\tkvm_gfn_to_hva_cache_init(kvm, ghc, ghc-&gt;gpa);+\t+\tif (kvm_is_error_hva(ghc-&gt;hva))+\t\treturn -EFAULT;++\t//==(2)==+\tr = copy_to_user((void __user *)ghc-&gt;hva, data, len);+\tif (r)+\t\treturn -EFAULT;+\t//==(3)==+\tmark_page_dirty_in_slot(kvm, ghc-&gt;memslot, ghc-&gt;gpa &gt;&gt; PAGE_SHIFT);++\treturn 0;+} 如果slots-&gt;generation 和当前cache generation(ghc-&gt;generation)不一致, 说明 该cache已经是stale的了, 需要update, 那就直接重新init cache(调用 kvm_gfn_to_hva_cache_init()) 将数据写入hva 该接口是新增的, 为mark_page_dirty()的变体. -void mark_page_dirty(struct kvm *kvm, gfn_t gfn)+void mark_page_dirty_in_slot(struct kvm *kvm, struct kvm_memory_slot *memslot,+\t\t\t gfn_t gfn) {-\tstruct kvm_memory_slot *memslot;--\tmemslot = gfn_to_memslot(kvm, gfn); \tif (memslot &amp;&amp; memslot-&gt;dirty_bitmap) { \t\tunsigned long rel_gfn = gfn - memslot-&gt;base_gfn; @@ -1284,6 +1325,14 @@ void mark_page_dirty(struct kvm *kvm, gfn_t gfn) \t} } +void mark_page_dirty(struct kvm *kvm, gfn_t gfn)+{+\tstruct kvm_memory_slot *memslot;++\tmemslot = gfn_to_memslot(kvm, gfn);+\tmark_page_dirty_in_slot(kvm, memslot, gfn);+} 该变体较mark_page_dirty()来说, 主要是增加memslot参数. 原因在介绍数据结构的时候已经说明 该功能和dirty log功能相关, guest可以通过bitmap知道那些page是dirty的,在热迁移的时候会用到, 这里不过多介绍 那slots-&gt;generation 什么时候改变的呢bump slots-&gt;generationdiff --git a/virt/kvm/kvm_main.c b/virt/kvm/kvm_main.cindex db58a1b..45ef50c 100644--- a/virt/kvm/kvm_main.c+++ b/virt/kvm/kvm_main.cint __kvm_set_memory_region(struct kvm *kvm, struct kvm_userspace_memory_region *mem, int user_alloc){skip_lpage: //==(1)== if (!npages) { r = -ENOMEM; slots = kzalloc(sizeof(struct kvm_memslots), GFP_KERNEL); if (!slots) goto out_free; memcpy(slots, kvm-&gt;memslots, sizeof(struct kvm_memslots)); if (mem-&gt;slot &gt;= slots-&gt;nmemslots) slots-&gt;nmemslots = mem-&gt;slot + 1;+\t\tslots-&gt;generation++; slots-&gt;memslots[mem-&gt;slot].flags |= KVM_MEMSLOT_INVALID; old_memslots = kvm-&gt;memslots; rcu_assign_pointer(kvm-&gt;memslots, slots); synchronize_srcu_expedited(&amp;kvm-&gt;srcu); /* From this point no new shadow pages pointing to a deleted * memslot will be created. * * validation of sp-&gt;gfn happens in: * - gfn_to_hva (kvm_read_guest, gfn_to_pfn) * - kvm_is_visible_gfn (mmu_check_roots) */ kvm_arch_flush_shadow(kvm); kfree(old_memslots); } //==(2)== r = kvm_arch_prepare_memory_region(kvm, &amp;new, old, mem, user_alloc); if (r) goto out_free; /* map the pages in iommu page table */ if (npages) { r = kvm_iommu_map_pages(kvm, &amp;new); if (r) goto out_free; } r = -ENOMEM; slots = kzalloc(sizeof(struct kvm_memslots), GFP_KERNEL); if (!slots) goto out_free; memcpy(slots, kvm-&gt;memslots, sizeof(struct kvm_memslots)); if (mem-&gt;slot &gt;= slots-&gt;nmemslots) slots-&gt;nmemslots = mem-&gt;slot + 1;+ slots-&gt;generation++; 说明不是内存, 有可能是mmio, 这里变动memslots, 需要使用rcu机制,这样可以保证在无锁的情况下把这个动作完成 normal 内存因为更新到了memslots, 说明hva-&gt;gpa的关系有改变, 所以需要更新generationhistory of change avi在Re: [PATCH v2 02/12] Add PV MSR to enable asynchronous page faults delivery. 中提到, 目前这一版本patch可能在遇到 memslots 情况下, 会有问题 原文 &gt; +static int kvm_pv_enable_async_pf(struct kvm_vcpu *vcpu, u64 data)&gt; +{&gt; +\tu64 gpa = data&amp; ~0x3f;&gt; +\tint offset = offset_in_page(gpa);&gt; +\tunsigned long addr;&gt; +&gt; +\taddr = gfn_to_hva(vcpu-&gt;kvm, gpa&gt;&gt; PAGE_SHIFT);&gt; +\tif (kvm_is_error_hva(addr))&gt; +\t\treturn 1;&gt; + //只初始化一次&gt; +\tvcpu-&gt;arch.apf_data = (u32 __user*)(addr + offset);&gt; +&gt; +\t/* check if address is mapped */&gt; +\tif (get_user(offset, vcpu-&gt;arch.apf_data)) {&gt; +\t\tvcpu-&gt;arch.apf_data = NULL;&gt; +\t\treturn 1;&gt; +\t}&gt; What if the memory slot arrangement changes? This needs to be revalidated (and gfn_to_hva() called again).&gt; validate &lt;==&gt; invalidate&gt; revalidate : 重新生效, 重新验证 在[PATCH v3 07/12] Maintain memslot version number和[PATCH v3 08/12] Inject asynchronous page fault into a guest if page is swapped out.中, 作者引入了该功能, 不过该功能是嵌入到async pf 功能中, 并非独立接口 代码 diff --git a/include/linux/kvm_host.h b/include/linux/kvm_host.hindex 600baf0..3f5ebc2 100644--- a/include/linux/kvm_host.h+++ b/include/linux/kvm_host.h@@ -163,6 +163,7 @@ struct kvm { \tspinlock_t requests_lock; \tstruct mutex slots_lock; \tstruct mm_struct *mm; /* userspace tied to this vm */+\tu32 memslot_version; \tstruct kvm_memslots *memslots; \tstruct srcu_struct srcu;@@ -364,7 +364,9 @@ struct kvm_vcpu_arch { \tunsigned long singlestep_rip; \tu32 __user *apf_data;+\tu32 apf_memslot_ver; \tu64 apf_msr_val;+\tu32 async_pf_id; };+static int apf_put_user(struct kvm_vcpu *vcpu, u32 val)+{+\tif (unlikely(vcpu-&gt;arch.apf_memslot_ver !=+\t\t vcpu-&gt;kvm-&gt;memslot_version)) {+\t\tu64 gpa = vcpu-&gt;arch.apf_msr_val &amp; ~0x3f;+\t\tunsigned long addr;+\t\tint offset = offset_in_page(gpa);++\t\taddr = gfn_to_hva(vcpu-&gt;kvm, gpa &gt;&gt; PAGE_SHIFT);+\t\tvcpu-&gt;arch.apf_data = (u32 __user*)(addr + offset);+\t\tif (kvm_is_error_hva(addr)) {+\t\t\tvcpu-&gt;arch.apf_data = NULL;+\t\t\treturn -EFAULT;+\t\t}+\t}++\treturn put_user(val, vcpu-&gt;arch.apf_data);+} 可以看到, 相当于引入了两个version, 并在apf_put_user()时,比对两个version. 作者在Re: [PATCH v4 08/12] Inject asynchronous page fault into a guest if page is swapped out.回答了为什么不使用kvm_write_guest Q: why A: want to cache gfn_to_hva_translation avi 在Re: [PATCH v5 08/12] Inject asynchronous page fault into a guest if page is swapped out.建议将该功能剥离, 因为这个功能很好,其他代码也可以用. 原文 This nice cache needs to be outside apf to reduce complexity for reviewers and since it is useful for others. Would be good to have memslot-cached kvm_put_guest() and kvm_get_guest(). 作者在Re: [PATCH v5 08/12] Inject asynchronous page fault into a guest if page is swapped out.首次提供该接口. Marcelo Tosatti 在Re: [PATCH v6 04/12] Add memory slot versioning and use it to provide fast guest write interface提到两个问题: 在kvm_gfn_to_hva_cache_init中使用gfn_to_memslot 获取memslot, 可能会造成如下问题 自己的理解 thread1 thread2 guestkvm_write_guest_cached kvm_gfn_to_hva_cache_init { __kvm_set_memory_region slots = kvm_memslots(kvm) { rcu_dereference_check } ghc-&gt;generation = slots-&gt;generation; slots-&gt;generation++; ghc-&gt;memslot = gfn_to_memslot( slots, gfn) { rcu_dereference_check { //may have a gp rcu_assign_pointer( kvm-&gt;memslots, slots); } ghc-&gt;hva = gfn_to_hva_many( ghc-&gt;memslot, gfn, NULL); }copy_to_user(); kvm_arch_commit_memory_region do_munmap access apf reason, LOSS 这样可能会导致在这个函数中, 前面和后面获取的信息来自于不同的memslots, 个人认为, 不仅仅是这样, 还可能导致, thread2 因为中间释放了rcu, 导致其流程和thread1有race, 最终导致 本次copy_to_user()数据丢失 作者在下一版patch中将gfn_to_memslot修改为了__gfn_to_memslot, 该接口不会在使用rcu_dereference_check " }, { "title": "embedding markdown in HTML tag", "url": "/posts/embedding_markdown_in_html_tag/", "categories": "markdown", "tags": "markdown, html-details", "date": "2024-04-12 10:53:00 +0800", "snippet": "ISSUEWhen I try to use the markdown syntax in &lt;details&gt; HTML tags, for example,code blocks, encounter the problem of code blocks that cannot be rendered.The source code is as follows:&lt;deta...", "content": "ISSUEWhen I try to use the markdown syntax in &lt;details&gt; HTML tags, for example,code blocks, encounter the problem of code blocks that cannot be rendered.The source code is as follows:&lt;details&gt;&lt;summary&gt; aaa &lt;/summary&gt;` ` `cppint a = 1;` ` `&lt;/details&gt; ` char seems unable to be translated in code block, so I added spacecharacters between themIt will display in browser as follows:aaa```cppint a = 1;```SOLUTIONThis issue seems to occur in the kramdowm markup process, rather than in GFM: GFM allows embedding HTML inside Markdown Embedding Markdown in Jekyll HTMLAnd in the link Embedding Markdown in Jekyll HTML, a solution is provided:Use &lt;details markdown=\"1\"&gt; instead &lt;details&gt;.It will run as expected aaa int a = 1; " }, { "title": "async pf", "url": "/posts/async-pf/", "categories": "kvm, async_pf", "tags": "para_virt", "date": "2024-04-10 12:20:00 +0800", "snippet": "introduce在支持EPT的架构中, 对于GVA-&gt;HPA一般有两段映射: GVA-&gt;GPA GPA-&gt;HPA而host kernel (kvm) 需要关心的是 GPA-&gt;HPA的映射, 需要host做的事情主要有以下几个: 捕捉相关 VM-exit event (EPT violation), 得到 GPA 分配page 建立映射关系(当然这个映射关系...", "content": "introduce在支持EPT的架构中, 对于GVA-&gt;HPA一般有两段映射: GVA-&gt;GPA GPA-&gt;HPA而host kernel (kvm) 需要关心的是 GPA-&gt;HPA的映射, 需要host做的事情主要有以下几个: 捕捉相关 VM-exit event (EPT violation), 得到 GPA 分配page 建立映射关系(当然这个映射关系, 不止是GPA-&gt;HPA的mmu pgtable, 还有 HVA – GPA,在这里不展开, 总之分配好具体的page(分配HPA), 以及为其建立好 mmu pgtable, 就可以完成该事件的处理)如下图:图示graphviz-ae4ca25f7bf30b9e61f0f3b83bc12338digraph G { subgraph cluster_guest { EPT_violation [ label=&quot;EPT mapping(GPA-&gt;HPA) \\nloss, trigger EPT violation&quot; ] &quot;access a VA&quot;-&gt; &quot;trigger PF in VMX\\n non-root operation&quot;-&gt; &quot;mapping GVA-&gt;GPA\\n in GUEST #PF hook&quot;-&gt; &quot;fixup #PF, continue \\naccess this VA&quot;-&gt; EPT_violation label=&quot;guest&quot; } subgraph cluster_host { &quot;find HVA though GPA&quot;-&gt; &quot;GUP(HVA)&quot;-&gt; &quot;mapping GPA-&gt;HPA&quot; label=&quot;host&quot; } &quot;mapping GPA-&gt;HPA&quot;-&gt;&quot;access a VA&quot; [ label=&quot;fixup EPT violation,\\n VM entry&quot; ] EPT_violation-&gt;&quot;find HVA though GPA&quot; [ label=&quot;VM exit&quot; ]}Gcluster_guestguestcluster_hosthostEPT_violationEPT mapping(GPA&#45;&gt;HPA) loss, trigger EPT violationfind HVA though GPAfind HVA though GPAEPT_violation&#45;&gt;find HVA though GPAVM exitaccess a VAaccess a VAtrigger PF in VMX\\n non&#45;root operationtrigger PF in VMX non&#45;root operationaccess a VA&#45;&gt;trigger PF in VMX\\n non&#45;root operationmapping GVA&#45;&gt;GPA\\n in GUEST #PF hookmapping GVA&#45;&gt;GPA in GUEST #PF hooktrigger PF in VMX\\n non&#45;root operation&#45;&gt;mapping GVA&#45;&gt;GPA\\n in GUEST #PF hookfixup #PF, continue \\naccess this VAfixup #PF, continue access this VAmapping GVA&#45;&gt;GPA\\n in GUEST #PF hook&#45;&gt;fixup #PF, continue \\naccess this VAfixup #PF, continue \\naccess this VA&#45;&gt;EPT_violationGUP(HVA)GUP(HVA)find HVA though GPA&#45;&gt;GUP(HVA)mapping GPA&#45;&gt;HPAmapping GPA&#45;&gt;HPAGUP(HVA)&#45;&gt;mapping GPA&#45;&gt;HPAmapping GPA&#45;&gt;HPA&#45;&gt;access a VAfixup EPT violation, VM entry但是, 已经建立好映射的页面, 也是qemu进程的虚拟地址空间(匿名页), 是可以被swap out,当被swap out后, GUEST 访问该HPA对应的 GVA/GPA时, 仍然会触发 EPT violation. 这时还会再走一次 VM-exit, 而且也需要完成上面所述的三件事, 其中第二件:分配page, 需要swap in之前被swap out的page, 路径比较长, 如下:VM-exit handle_ept_violation kvm_mmu_page_fault tdp_page_fault gfn_to_pfn hva_to_pfn get_user_pages --slow pathget_user_pages会走到slow path, 由于会走swap in流程, 所以该过程执行较慢. 所以大佬们就想着能不能让其异步执行, 然后让vcpu先不complete 造成 EPT violation 的 instruction, 去干别的事情, 等page present后, 再去执行该指令. 另外将 get_user_pages 让一个 dedicated thread 去完成,这样, 对于虚拟机来说, 就相当于搞了一个额外的 硬件, 专门去处理 swap in, 解放了vcpu的算力. NOTE 大家思考下, 如果要达到该目的, 一定是让GUEST有意无意的 sche out 造成 EPT violation的进程,该上面流程总结如下:流程图graphviz-f8c81926c9687c237f8513f3a6fb3624digraph G { subgraph cluster_host { style=&quot;filled&quot; color=&quot;#693886699&quot; subgraph cluster_host_dedicated_thread { do_slow_path [ shape=&quot;note&quot; label=&quot;I&#39;m a delicated \\nthread, Like a \\nspecial hardware, \\nsharing the \\npressure of VCPU&quot; ] label=&quot;dedicated thread&quot; have_got_page_success [ label=&quot;work in done!\\n tell the guest&quot; ] do_slow_path-&gt;have_got_page_success [ label=&quot;a. get page, swap in...&quot; fontcolor=&quot;blue&quot; color=&quot;blue&quot; ] } subgraph cluster_host_kvm_vcpu_thread { ept_violation_handler [ label=&quot;ept violation handler&quot; ] dont_do_slow_path [ shape=&quot;note&quot; label=&quot;I don&#39;t want \\nhandle slow path, \\nit will speed\\nto much time&quot; ] tell_guest_sched_out [ shape=&quot;note&quot; label=&quot;work is doing,\\nneed wait\\n a a bit time,\\n let guest do\\n other things&quot; ] dont_do_slow_path -&gt;tell_guest_sched_out [ label=&quot;4.let guest \\ndo other thing&quot; fontcolor=&quot;green&quot; color=&quot;green&quot; ] ept_violation_handler-&gt; dont_do_slow_path [ label=&quot;2.find page swap out&quot; fontcolor=&quot;green&quot; color=&quot;green&quot; ] label=&quot;host kvm vcpu thread&quot; } label = &quot;host&quot; } subgraph cluster_guest { style=&quot;filled&quot; color=&quot;#77323456&quot; subgraph cluster_trigger_ept_violation_task { task1_access_a_memory [ label=&quot;acesss a memory\\n address [BEG]&quot; color=&quot;white&quot; style=&quot;filled&quot; ] label=&quot;TASK1 trigger ept vioaltion&quot; } subgraph cluster_sched_in_task2 { task2_run_a_time [ label=&quot;task2_run_a_time&quot; ] label=&quot;task2&quot; } label=&quot;guest&quot; } dont_do_slow_path-&gt;do_slow_path [ label=&quot;3. start a work \\nto do it&quot; fontcolor=&quot;green&quot; color=&quot;green&quot; ] task1_access_a_memory -&gt; ept_violation_handler [ label=&quot;1.page NOT present,\\ntrigger EPT violation&quot; fontcolor=&quot;green&quot; color=&quot;green&quot; ] have_got_page_success -&gt; task2_run_a_time [ label=&quot;b. page NOT present\\n SCHED IN&quot; fontcolor=&quot;blue&quot; color=&quot;blue&quot; ] tell_guest_sched_out -&gt; task1_access_a_memory [ label=&quot;5. page NOT present\\n SCHED OUT&quot; fontcolor=&quot;green&quot; color=&quot;green&quot; ] task2_run_a_time-&gt;task1_access_a_memory [ label=&quot;c. sched in\\n task1&quot; fontcolor=&quot;blue&quot; color=&quot;blue&quot; ] task1_access_a_memory-&gt;task2_run_a_time [ label=&quot;6.sched out\\n task1&quot; fontcolor=&quot;green&quot; color=&quot;green&quot; ]}Gcluster_hosthostcluster_host_dedicated_threaddedicated threadcluster_host_kvm_vcpu_threadhost kvm vcpu threadcluster_guestguestcluster_trigger_ept_violation_taskTASK1 trigger ept vioaltioncluster_sched_in_task2task2do_slow_pathI&#39;m a delicated thread, Like a special hardware, sharing the pressure of VCPUhave_got_page_successwork in done! tell the guestdo_slow_path&#45;&gt;have_got_page_successa. get page, swap in...task2_run_a_timetask2_run_a_timehave_got_page_success&#45;&gt;task2_run_a_timeb. page NOT present SCHED INept_violation_handlerept violation handlerdont_do_slow_pathI don&#39;t want handle slow path, it will speedto much timeept_violation_handler&#45;&gt;dont_do_slow_path2.find page swap outdont_do_slow_path&#45;&gt;do_slow_path3. start a work to do ittell_guest_sched_outwork is doing,need wait a a bit time, let guest do other thingsdont_do_slow_path&#45;&gt;tell_guest_sched_out4.let guest do other thingtask1_access_a_memoryacesss a memory address [BEG]tell_guest_sched_out&#45;&gt;task1_access_a_memory5. page NOT present SCHED OUTtask1_access_a_memory&#45;&gt;ept_violation_handler1.page NOT present,trigger EPT violationtask1_access_a_memory&#45;&gt;task2_run_a_time6.sched out task1task2_run_a_time&#45;&gt;task1_access_a_memoryc. sched in task1由上图可见, 引入async pf 的逻辑是让其能够在触发 EPT violation后, 能够让VCPU 调度到另外一个task, 从而阻塞触发 EPT violation 的进程执行. 为了达到这一目的, 做了以下改动: VCPU 线程在执行get_user_page()时, 仅执行fast path, 如果page 不是present的, 该接口直接返回, 而剩下的工作, 则交给另外一个dedicated thread 去做 KVM 会通过一些方式, 让 GUEST 执行调度, 从而避免再次执行触发EPT violation的指令. 而dedicatedthread 完成了swap in 的动作后, 会通知guest再次唤醒该之前调度出去的进程代码细节para virt interface一般的半虚拟化实现往往都有一下几个特征: use CPUID report this feature use MSR transparent less information, e.g. : a share memory address enable/disable use a share memory transparent more information而 para virt async PF 也是这样实现的. 在v1 Add shared memory hypercall to PV Linux guest版本中, 作者以hypercall的方式实现了半虚拟化, 但是avi在随后建议(link)使用MSR来替代 hypercall, 因为该方式在INIT和热迁移流程中有现成的 save/restore 接口 原文如下: Better to set this up as an MSR (with bit zero enabling, bits 1-5 features, and 64-byte alignment). This allows auto-reset on INIT and live migration using the existing MSR save/restore infrastructure.最好将其设置为MSR - bit 0: enabling - bit 1-5: features - 64-byte alignment他允许在INIT时 auto-reset, 并且可以使用现有的 MSR save/restore infrastructure 完成热迁移 接口流程图图示graphviz-5816c8c78422729ad7411897407bd311digraph G { subgraph cluster_host { host_page_not_present [ label=&quot;initiate page \\nnot present\\n APF&quot; color=&quot;red&quot; ] host_page_present [ label=&quot;initiate page \\nhave been\\n present APF&quot; color=&quot;green&quot; ] label=&quot;host&quot; } subgraph cluster_guest { pf_handler [ label=&quot;page fault handler&quot; ] guest_invoke_task [ label=&quot;invoke task&quot; ] label=&quot;guest&quot; } cpuid [ shape=&quot;record&quot; label=&quot;cpuid:\\n KVM_FEATURE_ASYNC_PF:\\n 1&quot; ] subgraph cluster_msr { msr_bit_map [ shape=&quot;record&quot; label=&quot;{ bit0\\n enable bit\\n value 1(enable)| bit 1-5\\n reserved\\n value 0| &lt;shm_gpa&gt;bit 63-6\\n 64-byte aligned GPA\\n value 0xabc }&quot; ] label=&quot;MSR_KVM_ASYNC_PF_EN&quot; } subgraph cluster_cr2 { token [ shape=&quot;record&quot; label=&quot;token: \\n unique id&quot; ] label=&quot;cr2&quot; } subgraph cluster_shm { shm [ shape=&quot;record&quot; label=&quot;APF reason&quot; ] label=&quot;share memory&quot; } cpuid-&gt;msr_bit_map [ arrowhead=&quot;none&quot; style=&quot;dashed&quot; label=&quot;indicate apf \\nfeature \\navailable,\\n so access\\n MSR_KVM_ASYNC_PF_EN \\nis valid&quot; ] msr_bit_map:shm_gpa-&gt;shm [ arrowhead=&quot;none&quot; style=&quot;dashed&quot; label=&quot;point base GPA \\nof this share\\n memory&quot; ] host_page_not_present-&gt;token [ label=&quot;1. initiate page \\nnot present \\nAPF, generate \\ntoken write \\nto CR2&quot; color=&quot;red&quot; fontcolor=&quot;red&quot; ] host_page_not_present-&gt;shm [ label=&quot;2. update apf \\nreason to 1&quot; color=&quot;red&quot; fontcolor=&quot;red&quot; ] host_page_not_present-&gt;pf_handler [ label=&quot;3. inject page \\nnot present \\n#APF&quot; color=&quot;red&quot; fontcolor=&quot;red&quot; ] pf_handler-&gt;shm [ label=&quot;4. get reason \\nfrom shm:\\n PAGE \\nnot present\\n&quot; color=&quot;red&quot; fontcolor=&quot;red&quot; ] pf_handler-&gt;token [ label=&quot;5. get token \\nfrom cr2,\\nbind sched\\n out thread\\n and token\\n&quot; color=&quot;red&quot; fontcolor=&quot;red&quot; ] pf_handler-&gt;guest_invoke_task [ label=&quot;6. sched\\n out it&quot; color=&quot;red&quot; fontcolor=&quot;red&quot; ] host_page_present-&gt;token [ label=&quot;a. initiate page \\n present APF, \\nwrite prev \\ntoken write \\nto CR2&quot; color=&quot;green&quot; fontcolor=&quot;green&quot; ] host_page_present-&gt;shm [ label=&quot;b. update apf \\nreason to 2&quot; color=&quot;green&quot; fontcolor=&quot;green&quot; ] host_page_present-&gt;pf_handler [ label=&quot;c. inject page \\n present \\n#APF&quot; color=&quot;green&quot; fontcolor=&quot;green&quot; ] pf_handler-&gt;shm [ label=&quot;d. get reason \\nfrom shm:\\nPAGE present &quot; color=&quot;green&quot; fontcolor=&quot;green&quot; ] pf_handler-&gt;token [ label=&quot;e. get token \\nfrom cr2,\\n find sched \\nout thread \\nby token&quot; color=&quot;green&quot; fontcolor=&quot;green&quot; ] pf_handler-&gt;guest_invoke_task [ label=&quot;f.wakeup it&quot; color=&quot;green&quot; fontcolor=&quot;green&quot; ]}Gcluster_hosthostcluster_guestguestcluster_msrMSR_KVM_ASYNC_PF_ENcluster_cr2cr2cluster_shmshare memoryhost_page_not_presentinitiate page not present APFpf_handlerpage fault handlerhost_page_not_present&#45;&gt;pf_handler3. inject page not present #APFtokentoken: unique idhost_page_not_present&#45;&gt;token1. initiate page not present APF, generate token write to CR2shmAPF reasonhost_page_not_present&#45;&gt;shm2. update apf reason to 1host_page_presentinitiate page have been present APFhost_page_present&#45;&gt;pf_handlerc. inject page present #APFhost_page_present&#45;&gt;tokena. initiate page present APF, write prev token write to CR2host_page_present&#45;&gt;shmb. update apf reason to 2guest_invoke_taskinvoke taskpf_handler&#45;&gt;guest_invoke_task6. sched out itpf_handler&#45;&gt;guest_invoke_taskf.wakeup itpf_handler&#45;&gt;token5. get token from cr2,bind sched out thread and tokenpf_handler&#45;&gt;tokene. get token from cr2, find sched out thread by tokenpf_handler&#45;&gt;shm4. get reason from shm: PAGE not presentpf_handler&#45;&gt;shmd. get reason from shm:PAGE present cpuidcpuid: KVM_FEATURE_ASYNC_PF: 1msr_bit_mapbit0 enable bit value 1(enable)bit 1&#45;5 reserved value 0bit 63&#45;6 64&#45;byte aligned GPA value 0xabccpuid&#45;&gt;msr_bit_mapindicate apf feature available, so access MSR_KVM_ASYNC_PF_EN is validmsr_bit_map:shm_gpa&#45;&gt;shmpoint base GPA of this share memory图中描述了host, guest在处理async pf时, 对寄存器/share memory 的操作从图中可以看出, 会涉及到cpuid, MSR_KVM_ASYNC_PF_EN, share memory, 由于async pf 的实现,需要注入#PF, 所以还会涉及 CR2cpuid新增半虚拟化cpuid bit: KVM_FEATURE_ASYNC_PFdiff --git a/arch/x86/include/asm/kvm_para.h b/arch/x86/include/asm/kvm_para.h+#define KVM_FEATURE_ASYNC_PF\t\t4关于该bit的文档说明diff --git a/Documentation/kvm/cpuid.txt b/Documentation/kvm/cpuid.txt+KVM_FEATURE_ASYNC_PF || 4 || async pf can be enabled by+ || || writing to msr 0x4b564d02大致意思是, 该cpuid如果时能, 表示可以通过write to MSR (0x4b564d02) 来enable async pfMSR – share memaddr &amp;&amp; enable bitdiff --git a/arch/x86/include/asm/kvm_para.h b/arch/x86/include/asm/kvm_para.h+#define MSR_KVM_ASYNC_PF_EN 0x4b564d02文档说明:diff --git a/Documentation/kvm/msr.txt b/Documentation/kvm/msr.txt+ MSR_KVM_ASYNC_PF_EN: 0x4b564d02+ data: Bits 63-6 hold 64-byte aligned physical address of a+ 64 byte memory area which must be in guest RAM and must be+ zeroed. Bits 5-1 are reserved and should be zero. Bit 0 is 1+ when asynchronous page faults are enabled on the vcpu 0 when+ disabled. &gt; Bits 63-6 保存着 64-byte 对其的 一个64 byte memory area 的物理地址, &gt; 该memory area 必须是 guest RAM, 并且必须是被赋值为0. &gt; &gt; Bit 5-1 被reserved并且应该为0. &gt; &gt; 当 在 vcpu 0 启用 async pf enable async pf(当是disable时), &gt; Bit 0 是1该段主要介绍了MSR的 bit 组成: MSR bit Bit [63, 6]: a 64-byte aligned physical address Bit [5, 1]: reserved Bit 0 : enable bit 其实文档中还介绍了. share memory format 和 CR2, 但是为了方便阅读, 我们将拆分开到各个小节shared memory structure – APF reasondiff --git a/Documentation/kvm/msr.txt b/Documentation/kvm/msr.txt ...+ First 4 byte of 64 byte memory location will be written to by+ the hypervisor at the time of asynchronous page fault (APF)+ injection to indicate type of asynchronous page fault. Value+ of 1 means that the page referred to by the page fault is not+ present. Value 2 means that the page is now available. Disabling+ interrupt inhibits APFs. Guest must not enable interrupt+ before the reason is read, or it may be overwritten by another+ APF. Since APF uses the same exception vector as regular page+ fault guest must reset the reason to 0 before it does+ something that can generate normal page fault. If during page+ fault APF reason is 0 it means that this is regular page+ fault. &gt; 在 hypervisor 触发 APF 注入时, 4 byte memory location的前4个byte将被 &gt; 写入 来指示 APF 的类型. &gt; 1: page fault 涉及到的page 是 not present的. &gt; 2: page 现在已经 available &gt; 另外Disabling interrupt 将会 inhibits APF. &gt; &gt; Guest必须不能enable interrupt 在reason 被read之前, 否则可能会被另一个 &gt; APF覆盖. 因为 APF 使用 相同的 exception vector 作为 regular page &gt; fault, 所以在做可能生成normal page fault 的事情之前, guest 必须 reset &gt; reason to 0. 如果 在 page fault 期间, APF reason 为0, 他意味着这是一个 &gt; regular page fault.shared memory 一共有64 byte, 其中前4个byte(32 bit) 用来indicate apf type. hostkvm 在注入 apf之前会将type写入该地址.APF 有两种type(APF reason): 1: page is not present 2: not present page becomes available另外, 在处理APF时, guest和host有下面约束: 如果guest处于 disable interrupt, host不能注入apf guest必须在enable interrupt 之前, 处理完当前的apf guest必须在触发 normal #PF时, 处理完当前的apf, 并且reset reason to 0CR2diff --git a/Documentation/kvm/msr.txt b/Documentation/kvm/msr.txt ...+ During delivery of type 1 APF cr2 contains a token that will+ be used to notify a guest when missing page becomes+ available. When page becomes available type 2 APF is sent with+ cr2 set to the token associated with the page. There is special+ kind of token 0xffffffff which tells vcpu that it should wake+ up all processes waiting for APFs and no individual type 2 APFs+ will be sent. &gt; 在 type1 APF delivery 期间, cr2 包含了一个token, 当missing page &gt; becomes available, 该token将会用于通知guest. &gt; &gt; 当page becomes available, type2 APF 将会把 cr2 设置为和该page相关的 &gt; token. &gt; &gt; 这里有一个特殊的类型 token 0xffffffff, 他将告诉vcpu, 需要wakeup 所有 &gt; 等待APF的process 并且不会有单独的 type 2 APF 将会再发送 + If APF is disabled while there are outstanding APFs, they will+ not be delivered. &gt; 当 outstanding APFs时, 如果APF 被disabled, 他们将不会被delivered. + Currently type 2 APF will be always delivered on the same vcpu as+ type 1 was, but guest should not rely on that. &gt; 当前 type 2 APF 将始终在与type 1 相同的vcpu上deliver, 但是guest不应该依赖它.cr2 包含了一个token, 该token 用来唯一标识, 当前正在发生的APF 的 id. 但是其有一个特殊value 0xffffffff, 该值用来告诉vcpu, 需要wakeup所有的正在等待 APF (type 2) 的 进程. 并且不会有单独的type2再发送.另外还有几点约束和限制 如果还有 outstanding APFs 时, 如果 APF 被disable了, 他们将不会被deliver guest 不应该依赖 type2 APF 和 type1 APF在相同vcpu上deliver, 虽然目前是这样实现的. 大家可以思考下, 为什么要支持wake up all这样的API 可以想象一下热迁移场景. 当进行热迁移时, 我们先suspend vcpu, 然后迁移memory, 这时, 会等所有page swapin,然后在进行迁移, 但是这时, guest已经不能再去注入异常了, 只能等dest端在注入. 此时来到dest端, 这时所有的memory都是present的. 所以直接注入wakeup all就可以唤醒所有wait task.(当然, 也可能再此期间有swapout, 无非是再触发一次async pf)GUP change关于GUP 改动的细节我们放到link中介绍.STRUCT – host总体数据结构图比较简单, 如下: struct 结构图 graphviz-7842836ccacf1278b495c08c9dc5b30cdigraph G {\tsubgraph cluster_vcpu0 {\t\tkvm_vcpu0 [\t\t\tshape=&quot;record&quot;\t\t\tlabel=&quot;{struct kvm_vcpu||&lt;queue&gt;queue|&lt;done&gt;done}&quot;\t\t]\t\tsubgraph cluster_uncomplete_work {\t\t\twork_uncomplete_1 [\t\t\t\tshape=&quot;record&quot;\t\t\t\tlabel=&quot;{kvm_vcpu_pf||&lt;queue&gt;queue|&lt;link&gt;link}&quot;\t\t\t]\t\t\twork_uncomplete_2 [\t\t\t\tshape=&quot;record&quot;\t\t\t\tlabel=&quot;{kvm_vcpu_pf||&lt;queue&gt;queue|&lt;link&gt;link}&quot;\t\t\t]\t\t\tlabel=&quot;uncomplete work&quot;\t\t}\t\tsubgraph cluster_done_work {\t\t\twork_done_1 [\t\t\t\tshape=&quot;record&quot;\t\t\t\tlabel=&quot;{kvm_vcpu_pf||&lt;queue&gt;queue|&lt;link&gt;link}&quot;\t\t\t]\t\t\twork_done_2 [\t\t\t\tshape=&quot;record&quot;\t\t\t\tlabel=&quot;{kvm_vcpu_pf||&lt;queue&gt;queue|&lt;link&gt;link}&quot;\t\t\t]\t\t\tlabel=&quot;done work&quot;\t\t}\t\tlabel = &quot;vcpu 0&quot;\t}\tkvm_vcpu0:queue-&gt;\t\twork_done_1:queue-&gt;\t\twork_done_2:queue-&gt;\t\twork_uncomplete_1:queue-&gt;\t\twork_uncomplete_2:queue [\t\tcolor=&quot;red&quot;\t]\tkvm_vcpu0:done-&gt;\t\twork_done_1:link-&gt;\t\twork_done_2:link [\t\tcolor=&quot;blue&quot;\t]\tsubgraph cluster_vcpu1 {\t\tkvm_vcpu1 [\t\t\tshape=&quot;record&quot;\t\t\tlabel=&quot;struct kvm_vcpu&quot;\t\t]\t\twork_5 [\t\t\tshape=&quot;record&quot;\t\t\tlabel=&quot;kvm_vcpu_pf&quot;\t\t]\t\twork_6 [\t\t\tshape=&quot;record&quot;\t\t\tlabel=&quot;kvm_vcpu_pf&quot;\t\t]\t\tlabel = &quot;vcpu 1&quot;\t\tkvm_vcpu1-&gt;work_5-&gt;work_6\t}\tsubgraph cluster_vcpu2 {\t\tkvm_vcpu2 [\t\t\tshape=&quot;record&quot;\t\t\tlabel=&quot;struct kvm_vcpu&quot;\t\t]\t\twork_7 [\t\t\tshape=&quot;record&quot;\t\t\tlabel=&quot;kvm_vcpu_pf&quot;\t\t]\t\twork_8 [\t\t\tshape=&quot;record&quot;\t\t\tlabel=&quot;kvm_vcpu_pf&quot;\t\t]\t\tlabel = &quot;vcpu 2&quot;\t\tkvm_vcpu2-&gt;work_7-&gt;work_8\t}\tsubgraph cluster_vcpu3 {\t\tkvm_vcpu3 [\t\t\tshape=&quot;record&quot;\t\t\tlabel=&quot;struct kvm_vcpu&quot;\t\t]\t\twork_9 [\t\t\tshape=&quot;record&quot;\t\t\tlabel=&quot;kvm_vcpu_pf&quot;\t\t]\t\twork_10 [\t\t\tshape=&quot;record&quot;\t\t\tlabel=&quot;kvm_vcpu_pf&quot;\t\t]\t\tlabel = &quot;vcpu 3&quot;\t\tkvm_vcpu3-&gt;work_9-&gt;work_10\t}}Gcluster_vcpu0vcpu 0cluster_uncomplete_workuncomplete workcluster_done_workdone workcluster_vcpu1vcpu 1cluster_vcpu2vcpu 2cluster_vcpu3vcpu 3kvm_vcpu0struct kvm_vcpu queuedonework_done_1kvm_vcpu_pf queuelinkkvm_vcpu0:queue&#45;&gt;work_done_1:queuekvm_vcpu0:done&#45;&gt;work_done_1:linkwork_uncomplete_1kvm_vcpu_pf queuelinkwork_uncomplete_2kvm_vcpu_pf queuelinkwork_uncomplete_1:queue&#45;&gt;work_uncomplete_2:queuework_done_2kvm_vcpu_pf queuelinkwork_done_1:queue&#45;&gt;work_done_2:queuework_done_1:link&#45;&gt;work_done_2:linkwork_done_2:queue&#45;&gt;work_uncomplete_1:queuekvm_vcpu1struct kvm_vcpuwork_5kvm_vcpu_pfkvm_vcpu1&#45;&gt;work_5work_6kvm_vcpu_pfwork_5&#45;&gt;work_6kvm_vcpu2struct kvm_vcpuwork_7kvm_vcpu_pfkvm_vcpu2&#45;&gt;work_7work_8kvm_vcpu_pfwork_7&#45;&gt;work_8kvm_vcpu3struct kvm_vcpuwork_9kvm_vcpu_pfkvm_vcpu3&#45;&gt;work_9work_10kvm_vcpu_pfwork_9&#45;&gt;work_10 每个cpu有自己链表, 串起属于该cpu的async pf work, 其中有两条链. queue: 串起所有work done: 串起所有完成的work struct kvm_async_pf该数据结构主要用来描述上面提到的dedicated threadstruct kvm_async_pf { struct work_struct work; struct list_head link; struct list_head queue; struct kvm_vcpu *vcpu; struct mm_struct *mm; gva_t gva; unsigned long addr; struct kvm_arch_async_pf arch; struct page *page; bool done;}; work: dedicated thread实例, 使用 workqueue机制 link: 在patch中, 链接点主要有一个: vcpu 的work完成队列 queue: 用于链接该vcpu上的所有 kvm_async_pf gva: 触发EPT violation, 需要get_user_page_slow的 GVA addr: hva done: indicate该work完没完成 kvm_arch_async_pf: struct kvm_arch_async_pf { u32 token; gfn_t gfn;}; token: 该成员用于唯一标识一次async PF, 由kvm_vcpu.arch.apf.id和vcpu-&gt;vcpu_id综合计算得到. 在注入#PF时, 会当作 CR2 传入GUEST, 方便guest管理每一次的async PF. 上面说提到的kvm_async_pf-&gt;link,kvm_async_pf-&gt;queue所链接的队列, 如下:CHANGE of struct kvm_vcpu@@ -104,6 +125,15 @@ struct kvm_vcpu { gpa_t mmio_phys_addr; #endif+#ifdef CONFIG_KVM_ASYNC_PF+ struct {+ u32 queued;+ struct list_head queue;+ struct list_head done;+ spinlock_t lock;+ } async_pf;+#endif queue: 链接所有kvm_async_pf(work) done: 链接以完成的kvm_async_pf(work) lock: 队列锁change of struct kvm_vcpu_archstruct kvm_vcpu_arch { ...+ struct {+ bool halted;+ gfn_t gfns[roundup_pow_of_two(ASYNC_PF_PER_VCPU)];+ struct gfn_to_hva_cache data;+ u64 msr_val;+ u32 id;+ bool send_user_only;+ } apf; ...} 该数据结构变动涉及多个patch, 这里把最终的数据结构变动列出. halted: 表示是否因为async PF halt 了vcpu gfns : 这里做了一个数组, 用于记录所有现存的async pf work 的 gfn data: 相当于HVA-&gt;HPA的cache, 这个映射关系一直存在且不变(大多数情况下, 除非执行__kvm_set_memory_region更改映射关系), 该HPA 指向上面提到的 share memory 该部分被作者做成了一个通用功能, 相当于是 memslot-cached kvm_put_guest()and kvm_get_guest(). 我们放到另一篇文章中介绍. 主要介绍这个功能引入和其实现. msr_val: 记录guest设置的msr值 id: 记录下一个async pf work的id, 和kvm_vcpu-&gt;vcpu_id一起,唯一标识一次async PF send_user_only: 表示只有trigger EPT violation in guest user space, host才能做async PFSTRUCT - GUESTguest 数据结构主要是用于管理, 因为async PF 调度出去的task.数据结构图 数据结构图 graphviz-e889c62c04290bdb7d5685fb187da7d7digraph G { sleep_head [ shape=&quot;record&quot; label=&quot;{ kvm_task_sleep_head|| [0]| &lt;key0&gt;link(key0)|| [1]| &lt;key1&gt;link(key1)|| [2]| &lt;key2&gt;link(key2) }&quot; ] subgraph cluster_cpu0 { sleep_node0 [ shape=&quot;record&quot; label=&quot;{ kvm_task_sleep_node|| &lt;link&gt;link| token=[id=0, vcpu=0]| cpu=0| mm=mm_struct of task0| halted=false }&quot; ] sleep_node1 [ shape=&quot;record&quot; label=&quot;{ kvm_task_sleep_node|| &lt;link&gt;link| token=[id=1, vcpu=0]| cpu=0| mm=mm_struct of task1| halted=false }&quot; ] run_task_vcpu0 [ label=&quot;current task: task2&quot; shape=&quot;record&quot; color=&quot;red&quot; ] label=&quot;cpu0 RUNNING&quot; } subgraph cluster_cpu1 { run_task_vcpu1 [ label=&quot;current task: task4&quot; shape=&quot;record&quot; color=&quot;red&quot; ] sleep_node3 [ shape=&quot;record&quot; label=&quot;{ kvm_task_sleep_node|| &lt;link&gt;link| token=[id=0, vcpu=1]| cpu=1| mm=mm_struct of task3| halted=false }&quot; ] sleep_node4 [ shape=&quot;record&quot; label=&quot;{ kvm_task_sleep_node|| &lt;link&gt;link| token=[id=1, vcpu=1]| cpu=1| mm=mm_struct of task4| halted=true }&quot; color=&quot;red&quot; ] label=&quot;cpu1 HALT&quot; } sleep_head:key0-&gt;sleep_node0:link [ color=&quot;blue&quot; ] sleep_head:key1-&gt;sleep_node1:link [ color=&quot;gold&quot; ] sleep_head:key2-&gt; sleep_node3:link-&gt; sleep_node4:link [ color=&quot;green&quot; ] sleep_node4-&gt;run_task_vcpu1 [ arrowhead=none style=dashed ]}Gcluster_cpu0cpu0 RUNNINGcluster_cpu1cpu1 HALTsleep_headkvm_task_sleep_head [0]link(key0) [1]link(key1) [2]link(key2)sleep_node0kvm_task_sleep_node linktoken=[id=0, vcpu=0]cpu=0mm=mm_struct of task0halted=falsesleep_head:key0&#45;&gt;sleep_node0:linksleep_node1kvm_task_sleep_node linktoken=[id=1, vcpu=0]cpu=0mm=mm_struct of task1halted=falsesleep_head:key1&#45;&gt;sleep_node1:linksleep_node3kvm_task_sleep_node linktoken=[id=0, vcpu=1]cpu=1mm=mm_struct of task3halted=falsesleep_head:key2&#45;&gt;sleep_node3:linkrun_task_vcpu0current task: task2run_task_vcpu1current task: task4sleep_node4kvm_task_sleep_node linktoken=[id=1, vcpu=1]cpu=1mm=mm_struct of task4halted=truesleep_node3:link&#45;&gt;sleep_node4:linksleep_node4&#45;&gt;run_task_vcpu1 图中一共有4个涉及async PF的task, 同时每个task关联一个kvm_task_sleep_node kvm_task_sleep_head[]-&gt;link负责将所有key相同的 sleep_node串联起来, 方便查找 每个kvm_task_sleep_node有一个唯一的 identify kvm_task_sleep_node-&gt;token cpu0 上之前触发过两次async PF, 并且涉及到的task调度走了,目前正在运行task2 cpu1 上触发过两次async PF, 当task3 触发时, 成功将task3 sched out, 当task4触发时, 由于此时guest vcpu 不能调度, 所以将该cpu halt. 目前该cpu正在task4的上下文中halt. kvm_task_sleep_headstatic struct kvm_task_sleep_head { spinlock_t lock; struct hlist_head list;} async_pf_sleepers[KVM_TASK_SLEEP_HASHSIZE];该数据结构是一个hash map, 使用token作为hash key. lock: 可以看到是每个hash key, 有一个lock. 减少race情况kvm_task_sleep_nodestruct kvm_task_sleep_node { struct hlist_node link; wait_queue_head_t wq; u32 token; int cpu; bool halted; struct mm_struct *mm;};该数据结构作为hash node, 描述每一个因为async pf 调度出去的task 这里并不一定指被调度出去的task, 可能链接着即将发生调度的task信息,我们下面会介绍到. wq: 等待队列 token: 和上面描述一样, 唯一标识一次async PF halted: 有时候kvm注入async PF时, guest在这个时间点不能做schedule, 又 为了再次避免执行该代码流, 只能halt 该cpu. 这里用于标识是否该task halt了cpuinitiate async pf-&gt;inject async pf上面提到了为了使用GUP noio接口, 将tdp_page_fault中的gfn_to_pfn改动为try_async_pf. 我们来看下该接口try_async_pfstatic bool try_async_pf(struct kvm_vcpu *vcpu, gfn_t gfn, gva_t gva, pfn_t *pfn){ bool async; //==(1)== *pfn = gfn_to_pfn_async(vcpu-&gt;kvm, gfn, &amp;async); //==(2)== if (!async) return false; /* *pfn has correct page already */ //==(3)== put_page(pfn_to_page(*pfn)); //==(4)== if (can_do_async_pf(vcpu)) { trace_kvm_try_async_get_page(async, *pfn); //==(5)== if (kvm_find_async_pf_gfn(vcpu, gfn)) { trace_kvm_async_pf_doublefault(gva, gfn); kvm_make_request(KVM_REQ_APF_HALT, vcpu); return true; //==(6)== } else if (kvm_arch_setup_async_pf(vcpu, gva, gfn)) return true; } //==(7)== *pfn = gfn_to_pfn(vcpu-&gt;kvm, gfn); return false;} 前面提到过, 在try_async_pf 中会执行到gfn_to_pfn_async(), async作为oparam 表示是否需要做async pf, 另外还有一个返回值, 该返回值表示在该过程中得到的 pfn of gfn 当然, 如果得到的async为false, 说明不需要async pf, 那肯定得到了pfn所以直接返回 false put_page 这里会判断当前vcpu的状态是否可以做async pf can_do_async_pf细节 +static bool can_do_async_pf(struct kvm_vcpu *vcpu)+{+\tif (unlikely(!irqchip_in_kernel(vcpu-&gt;kvm) ||+\t\t kvm_event_needs_reinjection(vcpu)))+\t\treturn false;++\treturn kvm_x86_ops-&gt;interrupt_allowed(vcpu);+} 我们这里详细讲解下, 这三个判断条件, irqchip_in_kernel() kvm_event_need_reinjection(): static inline bool kvm_event_needs_reinjection(struct kvm_vcpu *vcpu){ return vcpu-&gt;arch.exception.pending || vcpu-&gt;arch.interrupt.pending || vcpu-&gt;arch.nmi_injected;} 可以看到这里, 在检测到有其他pending 事件的情况下, 不允许做async pf. 自己的理解 关于pending的event, 我们需要参考__vmx_complete_interrupts, 但是这里我们不过度展开, 大概就是在 VM entry inject event 期间, 由于某些原因, 触发了VM exit, 此时, VM entry, 还没有完成, 所以这些事件并没有被inject, 需要再次VM entry时注入. 再这种情况下, 就会有这样的顺序 inject_event1-&gt; VM entry-&gt; VM exit(get uncomplete event)-&gt; get vm exit reason: EPT violation PAGE not present-&gt; (do some handler)-&gt; VM entry 那现在问题来了, 本次是该注入async PF, 还是注入 uncomplete event呢? 我个人认为是注入uncomplete event. 首先按照顺序 uncomplete event先发生.如果不注入 uncomplete event的情况下, 直接注入async pf, 给guest感觉是某些event延后了. 另外, uncomplete event是由于 EPT violation 而触发的. 所以在本次处理完EPT violation之后,正好可以注入 uncomplete event, 并且大概率不会再次触发VM exit during EVENTinject. 以上是自己的理解, 而且不确定处理 tdp_page_fault()时, 所有的event是否都来自于上一次注入失败的uncomplete event. 遗留问题 interrupt_allowed: 我们来看下intel vmx 代码 static int vmx_interrupt_allowed(struct kvm_vcpu *vcpu){ return (vmcs_readl(GUEST_RFLAGS) &amp; X86_EFLAGS_IF) &amp;&amp; !(vmcs_read32(GUEST_INTERRUPTIBILITY_INFO) &amp; (GUEST_INTR_STATE_STI | GUEST_INTR_STATE_MOV_SS));} 该部分代码, 主要是检测当前interrupt windows 是否open, 这里对 这些判断条件不做过多解释, 详细见virtual interrupt 文章 还未写该文章 遗留部分 但是我们需要理解下, 为什么要关注guest 是否能接收中断呢? 毕竟async pf 注入的是#PF首先我们需要明确的是: 自己的理解 Q: async pf的目的是什么? A: 调度 Q: 该调度能发生在guest 运行的任何时机么 A: 需要满足guest意愿 所以, 综上所述, 得需要在guest认为自己可以调度的情况下, 才能做async pf这个事情. 否则,即使去启动了一个dedicated thread, 让guest调度, guest也不会去调度, 这样就没有意义了. 那好在这样的背景下, 我们分情况考虑: non-para virt: halt 在halt vcpu之后, 能够wakeup vcpu的方式有两种event interrupt async pf work complete 那在guest 不能注入中断的情况下, 只能由第二种event wakeup, 那就变成了sync的方式. 没有意义. para virt, 因为是半虚拟化方式, 相当于通知guest去主动做一次调度, 但是也得满足guest意愿.这实际上就像是和guest 协商的过程, 需要去关心guest这一刻是否能做调度. 作者在介绍MSR_KVM_ASYNC_PF_EN明确了, guest在关中断时, 不能去再次注入async PF, guest可能还处在APF handler中. 如果在此期间再次注入APF, 可能会导致 APF information 被覆盖, 例如: host guest cr2write token(a) to cr2 value: ainject APF1 trigger #PF (disable interrupt in VM-entry) do some thing...write token(b) to cr2 value: binject APF2 intend to read cr2 to get APF1 token, loss it !!! 在avi 的自问自答 中, 我们也能看到关于interrupt allow的解释. 这里说明之前, 该vcpu触发过该地址的 EPT violation , 并且已经做了async pf, 相当于再次遇到了.说明频率比较高, 那么直接halt该vcpu ????????? 下个小节中介绍 如果上述条件不满足, 则直接同步去做.kvm_setup_async_pfint kvm_setup_async_pf(struct kvm_vcpu *vcpu, gva_t gva, gfn_t gfn, struct kvm_arch_async_pf *arch){ struct kvm_async_pf *work; //==(1)== if (vcpu-&gt;async_pf.queued &gt;= ASYNC_PF_PER_VCPU) return 0; /* setup delayed work */ /* * do alloc nowait since if we are going to sleep anyway we * may as well sleep faulting in page */ //==(2)== work = kmem_cache_zalloc(async_pf_cache, GFP_NOWAIT); if (!work) return 0; work-&gt;page = NULL; work-&gt;done = false; work-&gt;vcpu = vcpu; work-&gt;gva = gva; work-&gt;addr = gfn_to_hva(vcpu-&gt;kvm, gfn); work-&gt;arch = *arch; work-&gt;mm = current-&gt;mm; atomic_inc(&amp;work-&gt;mm-&gt;mm_count); kvm_get_kvm(work-&gt;vcpu-&gt;kvm); /* this can't really happen otherwise gfn_to_pfn_async would succeed */ if (unlikely(kvm_is_error_hva(work-&gt;addr))) goto retry_sync; //==(2.1)== INIT_WORK(&amp;work-&gt;work, async_pf_execute); //==(3)== if (!schedule_work(&amp;work-&gt;work)) goto retry_sync; //==(4)== list_add_tail(&amp;work-&gt;queue, &amp;vcpu-&gt;async_pf.queue); vcpu-&gt;async_pf.queued++; //==(5)== kvm_arch_async_page_not_present(vcpu, work); return 1;retry_sync: kvm_put_kvm(work-&gt;vcpu-&gt;kvm); mmdrop(work-&gt;mm); kmem_cache_free(async_pf_cache, work); return 0;} 说明per cpu async_pf(work)超过了最大限制 – ASYNC_PF_PER_VCPU 申请,work并做相关初始化, 在(2.1)中将work hook设置为async_pf_execute schedule work 将work加到 vcpu-&gt;async_pf.queue队列中 代码如下: void kvm_arch_async_page_not_present(struct kvm_vcpu *vcpu, struct kvm_async_pf *work){ trace_kvm_async_pf_not_present(work-&gt;arch.token, work-&gt;gva); kvm_add_async_pf_gfn(vcpu, work-&gt;arch.gfn); //==(1)== if (!(vcpu-&gt;arch.apf.msr_val &amp; KVM_ASYNC_PF_ENABLED) || (vcpu-&gt;arch.apf.send_user_only &amp;&amp; kvm_x86_ops-&gt;get_cpl(vcpu) == 0)) kvm_make_request(KVM_REQ_APF_HALT, vcpu); //==(2)== else if (!apf_put_user(vcpu, KVM_PV_REASON_PAGE_NOT_PRESENT)) { vcpu-&gt;arch.fault.error_code = 0; vcpu-&gt;arch.fault.address = work-&gt;arch.token; kvm_inject_page_fault(vcpu); }} 和can_do_async_pf, 这里也有一些判断当前状态是否合适向guest注入async pf的条件, 我们放到下面介绍 如果可以注入, 则将KVM_PV_REASON_PAGE_NOT_PRESENT其写入 guest host 共享的内存中, 表示本次注入的是page not present类型的 async pf. 另外, 设置好本次注入异常的 address和 error code async pf workstatic void async_pf_execute(struct work_struct *work){ struct page *page = NULL; struct kvm_async_pf *apf = container_of(work, struct kvm_async_pf, work); struct mm_struct *mm = apf-&gt;mm; struct kvm_vcpu *vcpu = apf-&gt;vcpu; unsigned long addr = apf-&gt;addr; gva_t gva = apf-&gt;gva; might_sleep(); use_mm(mm); down_read(&amp;mm-&gt;mmap_sem); //==(1)== get_user_pages(current, mm, addr, 1, 1, 0, &amp;page, NULL); up_read(&amp;mm-&gt;mmap_sem); unuse_mm(mm); spin_lock(&amp;vcpu-&gt;async_pf.lock); //==(2)== list_add_tail(&amp;apf-&gt;link, &amp;vcpu-&gt;async_pf.done); apf-&gt;page = page; apf-&gt;done = true; spin_unlock(&amp;vcpu-&gt;async_pf.lock); /* * apf may be freed by kvm_check_async_pf_completion() after * this point */ trace_kvm_async_pf_completed(addr, page, gva); //==(3)== if (waitqueue_active(&amp;vcpu-&gt;wq)) wake_up_interruptible(&amp;vcpu-&gt;wq); mmdrop(mm); kvm_put_kvm(vcpu-&gt;kvm);} 调用get_user_pages, 该接口可以处理MAJOR fault get_user_pages() 第四个参数, 如果不为空,则会设置FOLL_GET int get_user_pages(struct task_struct *tsk, struct mm_struct *mm, unsigned long start, int nr_pages, int write, int force, struct page **pages, struct vm_area_struct **vmas){ int flags = FOLL_TOUCH; if (pages) flags |= FOLL_GET; ...} 如果设置了FOLL_GET, 则会在get_user_pages()的过程中, pin this page.也就是get_page(), 但是需要注意的是, 该接口可能会返回错误, 但是看起来此流程并没有判断该接口是否执行成功. IOW, 无论该接口是否执行成功, 都认为该work已经complete, 都需要再次wakeup GUEST blocking thread. 将该work, 链接到vcpu-&gt;async_pf.done链表中 如果vcpu在等待队列中(halt), 唤醒该vcpu接下来, 我们来看下, host是如何检测 page present事件, 并注入page present async pf的host inject PAGE PRESENT aync pf@@ -5272,6 +5288,9 @@ static int __vcpu_run(struct kvm_vcpu *vcpu) \t\t\tvcpu-&gt;run-&gt;exit_reason = KVM_EXIT_INTR; \t\t\t++vcpu-&gt;stat.request_irq_exits; \t\t}+\t\t+\t\tkvm_check_async_pf_completion(vcpu);+ \t\tif (signal_pending(current)) { \t\t\tr = -EINTR;在vm exit后, 检测是否有需要 async pf completevoid kvm_check_async_pf_completion(struct kvm_vcpu *vcpu){ struct kvm_async_pf *work; //==(1)== if (list_empty_careful(&amp;vcpu-&gt;async_pf.done) || !kvm_arch_can_inject_async_page_present(vcpu)) return; spin_lock(&amp;vcpu-&gt;async_pf.lock); work = list_first_entry(&amp;vcpu-&gt;async_pf.done, typeof(*work), link); list_del(&amp;work-&gt;link); spin_unlock(&amp;vcpu-&gt;async_pf.lock); //==(2)== if (work-&gt;page) kvm_arch_async_page_ready(vcpu, work); //==(3)== kvm_arch_async_page_present(vcpu, work); list_del(&amp;work-&gt;queue); vcpu-&gt;async_pf.queued--; if (work-&gt;page) put_page(work-&gt;page); kmem_cache_free(async_pf_cache, work);} 有两个判断条件: 判断是否有完成的work guest此时是否适合注入 page present async PF (下面章节介绍) 如果work-&gt;page为 NULL, 说明async work中, 执行get_user_pages()失败了, 那么本次就不需要在执行kvm_arch_async_page_ready(), 该函数作用是, 再次执行tdp_page_fault, 如果page is ready, 那只需要执行get_user_page fast path和__direct_map建立GPA-&gt;HPA的映射. 但是如果page is not ready(work-&gt;page)为NULL, 作者的想法是, 让其在次vm entry,wakeup guest blocking thread, 让其再次触发EPT violation, 然后再发起async pf.所以在这里没有必要在做一次kvm_arch_async_page_ready-&gt;tdp_page_fault, 那可能有同学会说, 那为什么不在HOST中, 等待get_user_pages()一定返回成功之后, 再注入 page present #PF, 实话说,我也不知道, 但这里总感觉作者不想增加复杂的代码逻辑, 需要关注下后续的patch,看看是否对这部分有优化 遗留问题 kvm_arch_async_page_present void kvm_arch_async_page_present(struct kvm_vcpu *vcpu, struct kvm_async_pf *work){ trace_kvm_async_pf_ready(work-&gt;arch.token, work-&gt;gva); //==(1)== if (is_error_page(work-&gt;page)) work-&gt;arch.token = ~0; /* broadcast wakeup */ else kvm_del_async_pf_gfn(vcpu, work-&gt;arch.gfn); //==(2)== if ((vcpu-&gt;arch.apf.msr_val &amp; KVM_ASYNC_PF_ENABLED) &amp;&amp; !apf_put_user(vcpu, KVM_PV_REASON_PAGE_READY)) { vcpu-&gt;arch.fault.error_code = 0; vcpu-&gt;arch.fault.address = work-&gt;arch.token; kvm_inject_page_fault(vcpu); }} 关于error page, 我们放在另一篇文章中讲述. 遗留问题 置入KVM_ASYNC_PF_PF_ENABLED, 准备注入 page present async #PF guest handle async PFdotraplinkage void __kprobesdo_async_page_fault(struct pt_regs *regs, unsigned long error_code){ //==(1)== switch (kvm_read_and_reset_pf_reason()) { default: //==(2)== do_page_fault(regs, error_code); break; case KVM_PV_REASON_PAGE_NOT_PRESENT: //==(3)== /* page is swapped out by the host. */ kvm_async_pf_task_wait((u32)read_cr2()); break; //==(4)== case KVM_PV_REASON_PAGE_READY: kvm_async_pf_task_wake((u32)read_cr2()); break; }}该部分代码逻辑很清晰, async PF event 是使用了原有的#PF exception vector,guest 需要在exception handler 中判断这个#PF的类型, 然后执行相应的handler 从share memory 中获取 async pf reason indicate NORMAL #PF indicate PAGE NOT PRESENT async pf indicate PAGE PRESENT async pfpage not present async pfvoid kvm_async_pf_task_wait(u32 token){ u32 key = hash_32(token, KVM_TASK_SLEEP_HASHBITS); struct kvm_task_sleep_head *b = &amp;async_pf_sleepers[key]; struct kvm_task_sleep_node n, *e; DEFINE_WAIT(wait); int cpu, idle; cpu = get_cpu(); idle = idle_cpu(cpu); put_cpu(); spin_lock(&amp;b-&gt;lock); //===(1)== e = _find_apf_task(b, token); if (e) { /* dummy entry exist -&gt; wake up was delivered ahead of PF */ hlist_del(&amp;e-&gt;link); kfree(e); spin_unlock(&amp;b-&gt;lock); return; } //===(2)== n.token = token; n.cpu = smp_processor_id(); n.mm = current-&gt;active_mm; //===(2.1)== n.halted = idle || preempt_count() &gt; 1; atomic_inc(&amp;n.mm-&gt;mm_count); init_waitqueue_head(&amp;n.wq); //===(3)== hlist_add_head(&amp;n.link, &amp;b-&gt;list); spin_unlock(&amp;b-&gt;lock); for (;;) { //===(4)== if (!n.halted) prepare_to_wait(&amp;n.wq, &amp;wait, TASK_UNINTERRUPTIBLE); if (hlist_unhashed(&amp;n.link)) break; //===(4)== if (!n.halted) { local_irq_enable(); schedule(); local_irq_disable(); } else { /* * We cannot reschedule. So halt. */ native_safe_halt(); local_irq_disable(); } } if (!n.halted) finish_wait(&amp;n.wq, &amp;wait); return;} 在kernel doc介绍MSR_KVM_ASYNC_PF_EN, 作者有提到过. 一对[type2 APF, type1 APF] 不一定会在同一个vcpu上触发, 那也就意味着两者可能并行执行(虽然现在的host kvm 没有这样做,但是guest不能依赖它), 如下: kvm vcpu1 vcpu21.inject type1 APF to VCPU1 2. inject type2 APF to VCPU2 3. handle type2 APF 4. handle type1 APF 可以看到kvm虽然是按照顺序注入的type1 APF, 和type2 APF, 但是注入到了不同的vcpu. vcpu在处理时,handle type2 APF先执行, 此时page 已经present了, 不需要再sched out, 这里会在type2 APFhandler中预先将带有该token的sleep_node放到head中, 以便type 1 APF handler 可以跳过这次的sched out(需要结合type2 APF handle – kvm_async_pf_task_wake().) 将task(current-&gt;active_mm)和token绑定, 这样当type2 APF触发时, 可以根据token找到当前block的task 需要注意的时, guest在某些情况下不能sched out, 这时, 只能halt当前cpu 我们放到另一篇文章中去介绍 遗留问题 将sleep_node链到sleep_head上 如果guest此时可以调度, 则将进程D住, sched outpage present async pfvoid kvm_async_pf_task_wake(u32 token){ u32 key = hash_32(token, KVM_TASK_SLEEP_HASHBITS); struct kvm_task_sleep_head *b = &amp;async_pf_sleepers[key]; struct kvm_task_sleep_node *n; if (token == ~0) { apf_task_wake_all(); return; }again: spin_lock(&amp;b-&gt;lock); //===(1)== n = _find_apf_task(b, token); //===(2)== if (!n) { /* * async PF was not yet handled. * Add dummy entry for the token. */ n = kmalloc(sizeof(*n), GFP_ATOMIC); if (!n) { /* * Allocation failed! Busy wait while other cpu * handles async PF. */ spin_unlock(&amp;b-&gt;lock); cpu_relax(); goto again; } n-&gt;token = token; n-&gt;cpu = smp_processor_id(); n-&gt;mm = NULL; init_waitqueue_head(&amp;n-&gt;wq); hlist_add_head(&amp;n-&gt;link, &amp;b-&gt;list); } else //===(3)== apf_task_wake_one(n); spin_unlock(&amp;b-&gt;lock); return;} 根据token, 在sleep_head中查找sleep_node 同type1 APF handler, type2 APF可能在于type1 APF不同的cpu上先执行, 此时在sleep_head中找不到和该token相关的sleep_node, 这时, 需要新创建一个sleep_node将其添加到sleep_head中, 以便type1 APF handler可以查找到,避免block该task 如果查找到了, 说明type1 APF handler已经触发, task已经block, 需要wakeup该task参考链接 MAIL list:v1 v2 v3 v4 v5 v6 v7 " } ]
