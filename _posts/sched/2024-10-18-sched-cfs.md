---
layout: post
title:  "CFS"
author: fuqiang
date:   2024-04-12 10:53:00 +0800
categories: [sched,cfs]
tags: sched cfs
---
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-mml-chtml.js">
</script>
## 调度类
sched_class
```cpp
struct sched_class {
    const struct sched_class *next;
    
    void (*enqueue_task) (struct rq *rq, struct task_struct *p, int flags);
    void (*dequeue_task) (struct rq *rq, struct task_struct *p, int flags);
    void (*yield_task)   (struct rq *rq);
};
```



## 调度周期

调度周期就是保证一个running进程至少执行一次的时间间隔。

我们看下调度周期相关变量:

```cpp
static unsigned int sched_nr_latency = 8;
//6ms
unsigned int normalized_sysctl_sched_latency            = 6000000ULL;

//0.75ms
unsigned int sysctl_sched_min_granularity               = 750000ULL;
unsigned int sysctl_sched_latency                       = 6000000ULL;
```

`normalized_sysctl_sched_latency` 和 `sysctl_sched_min_granularity`
以及`sched_nr_latency` 之间的关系:

```
normalized_sysctl_sched_latency(通常调度周期) 
  =  sysctl_sched_min_granularity（每个进程最小调度周期)
     * sched_nr_latency(能保证 每个进程最小调度周期的最大进程数量)
```

调度周期计算:
```cpp
/*
 * The idea is to set a period in which each task runs once.
 *
 * When there are too many tasks (sched_nr_latency) we have to stretch
 * this period because otherwise the slices get too small.
 *
 * p = (nr <= nl) ? l : l*nr/nl
 */
static u64 __sched_period(unsigned long nr_running)
{
        if (unlikely(nr_running > sched_nr_latency))
                return nr_running * sysctl_sched_min_granularity;
        else
                return sysctl_sched_latency;
}
```

`nr_running` 表示当前正在运行的进程数量，当进程数量 > `sched_nr_latency`
则无法在保证6ms的调度周期，设置调度周期为每个进程的最小调度周期
`sysctl_sched_min_granularity`乘进程数量, 否则设置调度周期为
`sysctl_sched_latency`.

一个进程在调度周期内的运行时间范围为:`[0.75ms, 6ms]`(默认情况下)


## vruntime

CFS调度器梦想是让每一个进程完全公平调度。但是完全公平调度也是在加权
的基础上。例如系统中有两个进程，A, B. A进程权重是2， B进程权重是1，
B进程所占的时间片比例为:

$$
A进程比例=\frac{A进程权重}{B进程权重+A进程权重}

$$
$$
A进程运行时间=\frac{A进程权重*总时间}{B进程权重+A进程权重}
$$

而vruntime则是让大家运行的时间，看起来一样，只不过权重大的进程时间
走的比较慢(这样就能运行更多时间), 权重小的的进程时间走的比较快。
这样有啥好处呢。

在进程调度流程中，比较进程运行时间比更新进程运行时间的频率要高很多，
如果能够让不同权重的进程在比较时都按照一个比例，那比较起来就方便多了.
而更新时候，按照权重，把实际运行时间做乘法运算。这样可以减少计算量。

举个例子:

未来人类文明达到了三体文明, 星系旅行不再是梦想。这时候，
人类贸易也做到了全银河。有个资本家想统计下这些星球的每个星
球能挣多少钱，每个星球有不同的国家，每个国家有不同的货币，
有美元，人民币，也有火星币，北斗币等1亿种货币，但是每个星球每天
也不一定能卖出一件商品。但是资本家想每小时看下排行榜。

之前的做法是，每次统计，都现将各种货币按照汇率做运算，然后再比较。
效率很低，后来改变了算法，每次产生交易时，就把挣得钱按照汇率做运算，
然后每小时比较排行榜时，不用在做汇率运算了。

vruntime也是这么做的，更新排行榜，就相当于选择下一个运行进程. 财富进账，
相当于进程运行更新runtime，不同汇率的货币，相当于不同权重进程。

那我们来看下相关计算:

$$
\begin{align}
vruntime &= wall\_time * \frac{NICE\_0\_LOAD}{weight} \\
&= wall\_time * \frac{NICE\_0\_LOAD * 2^{32}}{weight} >> 32 \\
&= (wall\_time * NICE\_0\_LOAD * inv\_weight) >> 32 \\
\end{align}
$$

在公式中，

$$
\begin{align}
inv\_weight = \frac{2 ^{32}}{weight}
=\frac{2^{32}}{sched\_prio\_to\_weight[nice]}
\end{align}
$$

### weight

linux进程配置权重是通过nice值，nice值取值范围是[-20, 20]
而nice值和权重又一个计算关系
```
weight = 1024 / (1.25 ^ nice)
```

nice 每增加1, 相当于 
```
a = a  / 1.25 
  = a * 0.8
```
相当于权重减少20%

所以不同的nice值计算出的是一个常量, kernel用一个数组枚举:
```cpp
const int sched_prio_to_weight[40] = {
 /* -20 */     88761,     71755,     56483,     46273,     36291,
 /* -15 */     29154,     23254,     18705,     14949,     11916,
 /* -10 */      9548,      7620,      6100,      4904,      3906,
 /*  -5 */      3121,      2501,      1991,      1586,      1277,
 /*   0 */      1024,       820,       655,       526,       423,
 /*   5 */       335,       272,       215,       172,       137,
 /*  10 */       110,        87,        70,        56,        45,
 /*  15 */        36,        29,        23,        18,        15,
};
```


weight 1024 对应权重0， 也就是`NICE_0_LOAD`, 默认情况下的权重.

而上面提到inv_weight和weight也有一定关系，所以我们可以直接用nice值
知道inv_weight:
```cpp
const u32 sched_prio_to_wmult[40] = {
 /* -20 */     48388,     59856,     76040,     92818,    118348,
 /* -15 */    147320,    184698,    229616,    287308,    360437,
 /* -10 */    449829,    563644,    704093,    875809,   1099582,
 /*  -5 */   1376151,   1717300,   2157191,   2708050,   3363326,
 /*   0 */   4194304,   5237765,   6557202,   8165337,  10153587,
 /*   5 */  12820798,  15790321,  19976592,  24970740,  31350126,
 /*  10 */  39045157,  49367440,  61356676,  76695844,  95443717,
 /*  15 */ 119304647, 148102320, 186737708, 238609294, 286331153,
};
```

### 通过weight 将wall_time->vtime

系统中用`struct load_weight`描述进程相关`weight`信息
```cpp
struct load_weight {
        //sched_prio_to_weight[nice] 对于64 bit而言，为weight << 10
        unsigned long                   weight;
        //sched_prio_to_wmult[nice]
        u32                             inv_weight;
};
```
用(3)中的公式将wall_time转换vtime的函数:
```cpp
static inline u64 calc_delta_fair(u64 delta, struct sched_entity *se)
{
        //nice0无需转换
        if (unlikely(se->load.weight != NICE_0_LOAD))
                delta = __calc_delta(delta, NICE_0_LOAD, &se->load);

        return delta;
}
static u64 __calc_delta(u64 delta_exec, unsigned long weight, struct load_weight *lw)
{
        u64 fact = scale_load_down(weight);
        int shift = WMULT_SHIFT;

        __update_inv_weight(lw);        //==(1)==

        if (unlikely(fact >> 32)) {     //==(2)==
                while (fact >> 32) {
                        fact >>= 1;
                        shift--;
                }
        }

        fact = mul_u32_u32(fact, lw->inv_weight); //==(3)==

        while (fact >> 32) {
                fact >>= 1;
                shift--;
        }

        return mul_u64_u32_shr(delta_exec, fact, shift); //==(4)==
}
```
* delta_exec: 表示执行的一个时间段, wall clock频率
* weigth: 当前权重,(从`calc_delta_fair()`传下来, 应该是NICE_0_LOAD)

  `NICE_0_LOAD` 在64bit上，是`1 << 10 << 10`
  ```cpp
  # define SCHED_FIXEDPOINT_SHIFT         10
  # define NICE_0_LOAD_SHIFT      (SCHED_FIXEDPOINT_SHIFT + SCHED_FIXEDPOINT_SHIFT)
  ```
* lw: `struct load_weight`

1. 根据weight计算inv_weight
   <details markdown=1 open>
   <summary>__update_inv_weight代码</summary>

   ```cpp
   static void __update_inv_weight(struct load_weight *lw)
   {
           unsigned long w;
   
           if (likely(lw->inv_weight))
                   return;
           //__w = max(2UL, __w >> SCHED_FIXEDPOINT_SHIFT(10) )
           //获取 lw->weight 应该记录的是 weight * NICE_0_LOAD(1024)
           w = scale_load_down(lw->weight); 
  
           //WMULT_CONST(2^32), 这里表示是64bit，并且w>= 2 ^ 32
           //这时相当于去 w=2^32, 最终计算inv_weight = 1
           if (BITS_PER_LONG > 32 && unlikely(w >= WMULT_CONST))
                   lw->inv_weight = 1;
           //如果计算weight为0(不知道啥时候会遇到), 这时候取w=1,
           //算出来inv_weight=WMULT_CONST
           else if (unlikely(!w))
                   lw->inv_weight = WMULT_CONST;
           else
           //weight在范围 [1, WMULT_CONST), 正常公式计算
                   lw->inv_weight = WMULT_CONST / w;
   }
   ```

   </details>
2. 这里允许`weight > 2 ^ 32`(当然按照当前代码流是NICE_0_LOAD), 
   但是为了防止溢出，现使达到32bit, 然后用shift记录， 
3. 然后执行 `weight * inv_weight`计算，然后再为了防止溢出，又让其
   达到32bit，
4. delta_exec(wall_time) * fact >> shift, 

> NOTE 
>
> 这样做会丢失精度么，个人不知道。

## runqueue

每个cpu都有一个全局的runqueue, 用来链接所有该cpu所有running的进程

我们可以通过crash`runq`命令, 查看每个cpu的runq

```
CPU 0 RUNQUEUE: ffff8caaaf833e00
  CURRENT: PID: 33041  TASK: ffff8cab34f78000  COMMAND: "main0"
  RT PRIO_ARRAY: ffff8caaaf834040
     [no tasks queued]
  CFS RB_ROOT: ffff8caaaf833ec0
     [120] PID: 33041  TASK: ffff8cab34f78000  COMMAND: "main1"
     [120] PID: 32308  TASK: ffff8ca7549a0000  COMMAND: "main2"

```
> 该cpu有main0正在运行，runq上两个进程main1,main2正在等待运行

相关数据结构:

**struct rq**

```cpp
struct rq {
      unsigned int nr_running;

      struct cfs_rq cfs;

      struct rt_rq rt;

#ifdef CONFIG_SMP
        struct llist_head wake_list;
#endif

      struct sched_avg avg;

      RH_KABI_EXTEND(struct dl_rq dl)

      ...
};
```

简单列举几个成员:
* nr_running:表示就绪队列上的进程数量
* cfs: 表示cfs runq
* rt: 实时调度runq
* wake_list: 唤醒队列
* avg: 队列负载
* dl: deadline runq

**struct cfs_rq**

```cpp
struct cfs_rq {
        struct load_weight load;
        unsigned int nr_running, h_nr_running; 

        u64 exec_clock;
        u64 min_vruntime;

        struct rb_root tasks_timeline;
        struct rb_node *rb_leftmost;
        /*
         * 'curr' points to currently running entity on this cfs_rq.
         * It is set to NULL otherwise (i.e when none are currently running).
         */
        struct sched_entity *curr, *next, *last, *skip;
        ...
};
```
* load: 就绪队列负载，所有调度实体负载和
* nr_running: 就绪队列上调度实体的个数
* h_nr_running:
* exec_clock:
* min_vruntime: 用来记录该runq上所有调度实体的最小vruntime
* task_timeline: 串联该队列上所有调度实体，并且按照vruntime大小，从小到大排列
* rb_leftmost: 指向红黑树最左边的调度实体
* curr,next,last,skip: 用来记录调度实体

调度实体暂时不过多展开.
```cpp
struct sched_entity {
        struct load_weight              load; 
        struct rb_node                  run_node;
};
```
* load: 上面介绍过，存储进程`weight`和 `inv_weight`
* run_node: 用来链接rq的红黑树

## CFS部分流程解析

### 更新runq上当前进程的vruntime

### 创建新进程

进程创建函数堆栈:
```
do_fork
  _do_fork
    copy_process
      sched_fork
```
`sched_fork`如下:
```cpp
int sched_fork(unsigned long clone_flags, struct task_struct *p)
{
        ...
        if (dl_prio(p->prio)) {              //==(1)==
                put_cpu();
                return -EAGAIN;
        } else if (rt_prio(p->prio)) {
                p->sched_class = &rt_sched_class;
        } else {
                p->sched_class = &fair_sched_class;
        }

        ...
        __set_task_cpu(p, cpu);                 //==(3)==
        if (p->sched_class->task_fork)
                p->sched_class->task_fork(p);   //==(4)==
        ...
}
```
1. 选择调度类, 这里我们只看cfs
2. 根据`se->load_weight`初始化 `se->avg.load_avg`
3. 设置进程运行的cpu
4. 调用 `task_fork_fair`

```cpp
static void task_fork_fair(struct task_struct *p)
{
        struct cfs_rq *cfs_rq;
        struct sched_entity *se = &p->se, *curr;
        struct rq *rq = this_rq();
        struct rq_flags rf;

        rq_lock(rq, &rf);
        update_rq_clock(rq);

        //==(1)==
        cfs_rq = task_cfs_rq(current);
        curr = cfs_rq->curr;
        if (curr) {
                update_curr(cfs_rq);
                se->vruntime = curr->vruntime;
        }
        //==(2)==
        place_entity(cfs_rq, se, 1);

        //==(3)==
        if (sysctl_sched_child_runs_first && curr && entity_before(curr, se)) {
                /*
                 * Upon rescheduling, sched_class::put_prev_task() will place
                 * 'current' within the tree based on its new key value.
                 */
                swap(curr->vruntime, se->vruntime);
                resched_curr(rq);
        }
        //==(4)==
        se->vruntime -= cfs_rq->min_vruntime;
        rq_unlock(rq, &rf);
}
```
1. 如果`rq`上有正在运行的进程(`curr`), 更新该进程的runtime，并且copy 到
   新创建进程的vruntime. 
2. (1)中的流程可能会导致一个问题，现在不太清楚当前进程的一个`vruntime`
   的情况，但是这样相当于在当前调度周期中插入一个新进程，对其他老进程不公平。
   （本来答应老进程在这个调度周期中，让其调度0.75ms, 结果来了一堆新进程, 去分
   这个调度周期, 程序员也变聪明了，为了让自己的程序有更多机会运行，就疯狂fork,
   在子进程中执行生产力任务), . 而`place_entity`就是想把新创建的进程安排到下一个
   调度周期，一般执行的时机有几个
   * 创建新进程
   * 唤醒入队
   * `detach_task_cfs_rq` ??
   具体代码分析如下:
   <details markdown=1 open>
   <summary> place_entity 代码折叠 </summary>

   ```cpp
   static void
   place_entity(struct cfs_rq *cfs_rq, struct sched_entity *se, int initial)
   {
           u64 vruntime = cfs_rq->min_vruntime;
   
           /*
            * The 'current' period is already promised to the current tasks,
            * however the extra weight of the new task will slow them down a
            * little, place the new task so that it fits in the slot that
            * stays open at the end.
            */
           /*
            * 翻译:
            *
            * "`当前`"周期已经承诺给当前的任务，然而新任务的额外权重会稍微减慢
            * 它们的速度，因此将新任务放置在周期末端空出的时间段中。”
            */
           if (initial && sched_feat(START_DEBIT))           //==(1)==
                   vruntime += sched_vslice(cfs_rq, se);
   
           /* sleeps up to a single latency don't count. */
           if (!initial) {                                   //==(2)==
                   unsigned long thresh = sysctl_sched_latency;
   
                   /*
                    * Halve their sleep time's effect, to allow
                    * for a gentler effect of sleepers:
                    */
                   if (sched_feat(GENTLE_FAIR_SLEEPERS))
                           thresh >>= 1;
   
                   vruntime -= thresh;
           }
           //==(3)==   
           /* ensure we never gain time by being placed backwards. */
           se->vruntime = max_vruntime(se->vruntime, vruntime);
   }
   ```
   1. 如果该调度器有`START_DEBIT`的feature，则将vruntime增加一个值, 而该值
      就是根据新创建进程的weight，rq的weigth计算一个调度周期中该进程执行的
      时间.

      具体代码
      <details markdown=1 open>
      <summary>sched_vslice代码折叠</summary>

      ```cpp
      static u64 sched_vslice(struct cfs_rq *cfs_rq, struct sched_entity *se)
      {
              return calc_delta_fair(sched_slice(cfs_rq, se), se);
      }
      
      static u64 sched_slice(struct cfs_rq *cfs_rq, struct sched_entity *se)
      {
              //获取一个调度周期，调度周期的计算上面介绍过. 如果当前调度实体，
              //没有在runq上，需要将当前调度实体也算上。因为这个进程也即将分割
              //调度周期
              u64 slice = __sched_period(cfs_rq->nr_running + !se->on_rq);

              //这里和组调度相关(下面介绍)
              //依次向上找parent
              for_each_sched_entity(se) {
                      struct load_weight *load;
                      struct load_weight lw;
          
                      cfs_rq = cfs_rq_of(se);
                      load = &cfs_rq->load;
                      //如果之前没有将权重添加到该rq上, 现在添加  
                      if (unlikely(!se->on_rq)) {
                              lw = cfs_rq->load;
      
                              update_load_add(&lw, se->load.weight);
                              load = &lw;
                      }
                      //计算当前的调度实体的时间片
                      slice = __calc_delta(slice, se->load.weight, load);
              }
              return slice;
      } 
      ```

      该函数主要作用有两个
      1. 如果se还没有在runq上，需要把自己的权重, 添加到每一级的rq
      2. 依次计算在每个runq上的时间片, 举个例子:
         
         A 进程的 parent 调度组a， 调度组a的 parent 调度组b, 调度组b 无parent

         这时需要计算的一个调度周期内的时间片为:

         $$
         \begin{align}
         vrumtime\_one\_sched\_period=sched\_period\_one * & \frac{A进程权重}{a调度组中调度实体的总权重} \\
         &* \frac{a调度组权重}{b调度组中调度实体总权重} \\
         &* \frac{b调度组权重}{cpu runq 中调度实体的总权重}
         \end{align}
         $$
      </details>
      然后将计算获得的额外的runtime家到vruntime中, 这样就相当于这个调度周期没有执行，安排到了
      下一个调度周期
   2. <font color="red" size="4"> 可能和唤醒相关先空着</font>
   3. se->vruntime, 新计算的vruntime取最大值
   </details>
3. 这里，我们如果想让新创建的进程在本调度周期运行，但是不影响其他进程的公平性。
   那就有一个办法: 和别人交换下（如果是父子进程，那就是坑爹)。具体做法是, 如果
   配置了`sysctl_sched_child_runs_first`, 并且当前进程vruntime比se要小，那么就将
   这两者的vruntime交换下
4. 这里要减去cfs_rq->min_vruntime, 是因为当前进程还未进入rq，等进入runq是在把`min_vruntime`加上.
   这样有什么好处呢，相当于得到一个相对值。可以无视时间线变化。

## 参考链接

[主要参考](https://blog.csdn.net/weixin_47465999/article/details/131955734)

https://blog.csdn.net/weixin_40179091/article/details/131057028

https://www.wowotech.net/about.html
