---
layout: post
title:  "kvm mmu virtualization"
author: fuqiang
date:   2024-05-09 18:50:00 +0800
categories: [kvm,mmu]
tags: [virt]
---

## what is MMU virtualization

![what_is_mmu_virt](pic/what_is_mmu_virt.png)

在NO virtualization的情况下, CPU 如果要进行访存(开启分页), 需要通过
硬件mmu, 将 VA 转化为PA. 然后再对该内存进行读写操作.

但是在虚拟机中, 在GUEST 视角下, 其访存行为应该和NO virtualization场景
一致, I.E, 都是由"MMU" 将GVA 通过自己定义的pgtable 转化为GPA. 但是在
KVM下, KVM为guest分配其内存 -- HPA, 而这些HPA 应该尽量是自由的. 所以,
需要GPA和HPA之间存在一定的映射关系.

> 一般情况下, 会将
> * guest视角的 VA, PA 称为 GVA, GPA.
> * host 视角的 VA, PA 称为 HVA, HPA
{: .prompt-info}

而`mmu virtualization` 就是完成上述工作. 但是光有映射关系不行, GUEST还有
其他需求:

### GUEST需求

很简单, 和硬件MMU行为越像越好, 硬件MMU的工作比较抽象, 我们有一个更具体的实
体可以参考 MMU 应该关心哪些内容, 那就是**`TLB`**. TLB 有啥呢?

* VA->PA mapping relations
* access right flag
  + R/W 
  + U/S
* A/D flag (access dirty)

要想模拟的像, 就要保证在GUEST在访问GVA时, 上面的这些信息在GUEST看起来是对的.

举个例子来说, 如果GUEST做了如下动作:
```
1. clear dirty flag of PTE_a
2. write access a page that PTE_a point(though PTE_a pgtable entry)
```

如果guest 再次读取PTE_a, 其dirty flag一定是置位的.
> NOTE
>
> 不考虑stale tlb的情况
{: .prompt-info}

### VMM 各个组建协作

我们以QEMU, KVM为例, QEMU负责控制各个资源规划,而KVM 则是分配维护某些资源,
其中就包括内存, 我们来看下 QEMU 将划定内存资源传递给KVM 的接口:

该接口有两个版本:
* ioctl(KVM_SET_MEMORY_REGION, struct kvm_memory_region) -- 被弃用

  <details markdown=1 open>
  <summary>struct kvm_memory_region</summary>

  ```cpp
  /* for KVM_CREATE_MEMORY_REGION */
  struct kvm_memory_region {
          __u32 slot;
          __u32 flags;
          __u64 guest_phys_addr;
          __u64 memory_size; /* bytes */
  };
  ```
  </details>
* ioctl(KVM_SET_USER_MEMORY_REGION, struct kvm_userspace_memory_region)

  <details markdown=1 open>
  <summary>struct kvm_userspace_memory_region</summary>

  ```cpp
  /* for KVM_SET_USER_MEMORY_REGION */
  struct kvm_userspace_memory_region {
          __u32 slot;
          __u32 flags;
          __u64 guest_phys_addr;
          __u64 memory_size; /* bytes */
          __u64 userspace_addr; /* start of the userspace allocated memory */
  };
  ```
  </details>

该接口作用是:

QEMU 定义了一些物理内存空间, 有一些物理地址空间是memory, 需要KVM 管理.

`kvm_userspace_memory_region`和`kvm_memory_region`不同的是, `kvm_userspace_memory_region`
多了一个成员:`userspace_addr`, 该成员表示是QEMU VA, 这也就是说明, GUEST内存, 是
QEMU 进程虚拟内存空间的一部分, 这样做的好处是, 可以内存管理的其他组建可以管理
到guest memory, 例如 thp, ksm, vmscan等

那么在该接口下, GPA 不仅和HPA有映射关系, GPA和 HVA(qemu VA) 也有了映射关系. 如下图:

![GPA_HVA_HPA](pic/GPA_HVA_HPA.png)

KVM需要建立, 维护上述关系.

## SOFT MMU && Hard MMU

KVM mmu virtualization 有两种实现方式, 早期的CPU 不支持 EPT, KVM 通过纯软件的方式实现.
称为 shadow page table(影子页表), 而后续的CPU 支持了EPT, KVM 则实现了利用硬件辅助的方式

关于两种实现, 我们在

* [soft mmu virtualization][software_mmu_virt]
* [hard mmu virtualization][hardware_mmu_virt]

中讲述.

## 参考链接

{% include link/kvm_link.md %}

[xiaoguangrong KVM MMU virtualization PPT 1][KVM_MMU_Virtualization_xiaoguangrong1]

[xiaoguangrong KVM MMU virtualization PPT 2][KVM_MMU_Virtualization_xiaoguangrong2]

