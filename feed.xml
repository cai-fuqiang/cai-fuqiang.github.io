<feed xmlns="http://www.w3.org/2005/Atom"> <id>/</id><title>Chirpy</title><subtitle>A minimal, responsive and feature-rich Jekyll theme for technical writing.</subtitle> <updated>2026-01-05T22:59:31+08:00</updated> <author> <name>your_full_name</name> <uri>/</uri> </author><link rel="self" type="application/atom+xml" href="/feed.xml"/><link rel="alternate" type="text/html" hreflang="en" href="/"/> <generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator> <rights> © 2026 your_full_name </rights> <icon>/assets/img/favicons/favicon.ico</icon> <logo>/assets/img/favicons/favicon-96x96.png</logo> <entry><title>rcu - classic</title><link href="/posts/rcu-classic/" rel="alternate" type="text/html" title="rcu - classic" /><published>2026-01-05T10:00:00+08:00</published> <updated>2026-01-05T10:00:00+08:00</updated> <id>/posts/rcu-classic/</id> <content type="text/html" src="/posts/rcu-classic/" /> <author> <name>fuqiang</name> </author> <category term="os" /> <category term="synchronization" /> <summary>本文主要讲解 经典rcu (classical rcu) 历史. 在介绍具体实现之前, 我们先明确几个概 念: quiescent state: 该CPU 上运行的所有 RCU 读取端临界区都已完成1 grace period: rcu 删除分为三部分, emoval ,Grace Period, and Reclamation. 宽限期 结束以所有cpu rcu 读临界区完成, 即所有cpu 都经历一次 quiescent state rcu callback: 某些rcu writer将释放动作封装为一个rcu_head, 通过调用 call_rcu()注册回调，允许异步执行释放动作。 rcu处理流程的关键点是: 如何发现新的rcu callback, 发起一个新的宽限期 如何判定该宽限期结束, 调用相关rcu callback 如下图所示...</summary> </entry> <entry><title>intel tdx (spec)</title><link href="/posts/tdx-spec/" rel="alternate" type="text/html" title="intel tdx (spec)" /><published>2025-12-30T14:00:00+08:00</published> <updated>2025-12-30T14:00:00+08:00</updated> <id>/posts/tdx-spec/</id> <content type="text/html" src="/posts/tdx-spec/" /> <author> <name>fuqiang</name> </author> <category term="tee" /> <category term="arch_intel" /> <summary>overflow add new operation mode Secure Arbitration Mode (SEAM) 是对于VMX 架构的扩展。在 vmx root/non-root operation(我们只有称为 legacy vmx XXX operation)下新增了两组模式: SEAM VMX root operation SEAM VMX non-root operation SEAM VMX root operation 中托管了成为 Intel Trust Domain Extensions(Intel TDX) 模块, 用于管理 TD虚拟机(可以理解为机密虚拟机). Intel TDX 模块实现了对TD虚拟机的: operation build tear down start execut...</summary> </entry> <entry><title>rcu - overflow</title><link href="/posts/rcu-overflow/" rel="alternate" type="text/html" title="rcu - overflow" /><published>2025-12-29T20:26:00+08:00</published> <updated>2025-12-29T20:26:00+08:00</updated> <id>/posts/rcu-overflow/</id> <content type="text/html" src="/posts/rcu-overflow/" /> <author> <name>fuqiang</name> </author> <category term="os" /> <category term="synchronization" /> <summary>background 本章节主要参考9 在介绍RCU之前，我们先来思考下，如何提升程序的性能? 一个最直接的方法是, 提升 并发量, 但是并发程序往往会造成多个线程(cpu) 访问同一个资源, 我们暂时先不考虑, 假设一个程序只有读者，每个读者都会去访问一个read-only list, 那么thread 数量和 吞吐关系图如下: 程序的性能会随着线程数量线性增长，这可真是简单粗暴的性能提升方法，但是生活并 不总是真么美好, read-only 场景很少，通常出现在科学计算中，更多的场景是 almost read-only。 于是我们希望, 在写入很少的场景下, 读者性能不受影响。 首先我们来看几种方案: lock-free lock-free(list with atomic shared pointers) 虽然是一种比较通用的方案, 其允许 多...</summary> </entry> <entry><title>intel memory encryption technologies</title><link href="/posts/intel-memory-encryption/" rel="alternate" type="text/html" title="intel memory encryption technologies" /><published>2025-12-29T16:10:00+08:00</published> <updated>2025-12-29T16:10:00+08:00</updated> <id>/posts/intel-memory-encryption/</id> <content type="text/html" src="/posts/intel-memory-encryption/" /> <author> <name>fuqiang</name> </author> <category term="tee" /> <category term="arch_intel" /> <summary>introduction TME Total Memory Encryption (TME) – the capability to encrypt the entirety of physical memory of a system. This capability is typically enabled in the very early stages of the boot process with a small change to BIOS and once configured and locked, will encrypt all the data on external memory buses of an SoC using the NIST standard AES-XTS algorithm with 128-bit keys or 256-bit k...</summary> </entry> <entry><title>non-scalable VS scalable spinlock</title><link href="/posts/non-scalable-vs-scalable-spinlock/" rel="alternate" type="text/html" title="non-scalable VS scalable spinlock" /><published>2025-12-26T11:00:00+08:00</published> <updated>2025-12-26T11:00:00+08:00</updated> <id>/posts/non-scalable-vs-scalable-spinlock/</id> <content type="text/html" src="/posts/non-scalable-vs-scalable-spinlock/" /> <author> <name>fuqiang</name> </author> <category term="synchronization" /> <summary>自旋锁是一种会让尝试获取它的线程陷入循环 （“自旋”）并不断检查锁是否可用的锁 1。 和mutex 不同，mutex 可以睡眠，将cpu让渡给其他的程序，而自旋锁则是占据着cpu资源忙 等。忙等最主要的优点是，避免了调度所带来的上下文开销, 可以提升等锁进程获得锁的延 迟。另外，如果加锁的临界区很小，自旋锁忙等所带来的开销，可能会小于上下文切换的开 销，自旋锁的收益就会非常大。所以，自旋锁适用于临界区小的场景。 overflow 本文主要是来讲述, spinlock 的可伸缩性(scalable). 可扩展性是指系统处理不断增长的 工作量的能力。软件系统的可扩展性定义之一是，可以通过向系统添加资源来实现 2. 而对于spinlock而言, 如何增加其工作量呢？ 增加并行调用spinlock的cpu数量 在介绍之前我们先思考下，自旋锁和 “smp”, “up” 关系3。首先按...</summary> </entry> </feed>
